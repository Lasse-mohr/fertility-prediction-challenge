{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import polars as pl     # requires installing polars first\n",
    "import pyarrow          # requires installing pyarrow first\n",
    "import re\n",
    "\n",
    "from data_processing.tabnet_utils import CodeBookFilter\n",
    "\n",
    "# Model\n",
    "import numpy as np\n",
    "import torch_frame as tf\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf = CodeBookFilter(path = \"data/codebooks/PreFer_codebook.csv\", accept_missing_rate=0.02, column_appeared_times=8)\n",
    "PID_col = \"nomem_encr\"\n",
    "df = pl.read_csv(\"data/training_data/PreFer_train_data.csv\",\n",
    "                     infer_schema_length=7418, columns=[PID_col, \"outcome_available\"]+ cbf.return_valid_column_names()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>var_label</th>\n",
       "      <th>values_cat</th>\n",
       "      <th>labels_cat</th>\n",
       "      <th>unique_values_n</th>\n",
       "      <th>n_missing</th>\n",
       "      <th>prop_missing</th>\n",
       "      <th>type_var</th>\n",
       "      <th>note</th>\n",
       "      <th>year</th>\n",
       "      <th>survey</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nomem_encr</td>\n",
       "      <td>Number of household member encrypted</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>All surveys</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cf08a_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cf09b_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf10c_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cf11d_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_name                             var_label values_cat labels_cat  \\\n",
       "0  nomem_encr  Number of household member encrypted                         \n",
       "2     cf08a_m   Year and month of field work period                         \n",
       "3     cf09b_m   Year and month of field work period                         \n",
       "4     cf10c_m   Year and month of field work period                         \n",
       "5     cf11d_m   Year and month of field work period                         \n",
       "\n",
       "   unique_values_n  n_missing  prop_missing type_var note    year  \\\n",
       "0              NaN          0           0.0  numeric          NaN   \n",
       "2              2.0          0           0.0  numeric       2008.0   \n",
       "3              2.0          0           0.0  numeric       2009.0   \n",
       "4              1.0          0           0.0  numeric       2010.0   \n",
       "5              2.0          0           0.0  numeric       2011.0   \n",
       "\n",
       "               survey                dataset  \n",
       "0         All surveys  PreFer_train_data.csv  \n",
       "2  Family & Household  PreFer_train_data.csv  \n",
       "3  Family & Household  PreFer_train_data.csv  \n",
       "4  Family & Household  PreFer_train_data.csv  \n",
       "5  Family & Household  PreFer_train_data.csv  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbf.codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomem_encr</th>\n",
       "      <th>ch004</th>\n",
       "      <th>ch005</th>\n",
       "      <th>ch011</th>\n",
       "      <th>ch012</th>\n",
       "      <th>ch013</th>\n",
       "      <th>ch014</th>\n",
       "      <th>ch015</th>\n",
       "      <th>ch016</th>\n",
       "      <th>ch017</th>\n",
       "      <th>...</th>\n",
       "      <th>cw098</th>\n",
       "      <th>cw099</th>\n",
       "      <th>cw100</th>\n",
       "      <th>cw101</th>\n",
       "      <th>cw102</th>\n",
       "      <th>cr120</th>\n",
       "      <th>cw522</th>\n",
       "      <th>cw523</th>\n",
       "      <th>cw525</th>\n",
       "      <th>cf432</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14138</th>\n",
       "      <td>733171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.369999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>733171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14140</th>\n",
       "      <td>733176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14141</th>\n",
       "      <td>733176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>733176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.730000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14143 rows × 430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nomem_encr  ch004  ch005  ch011  ch012  ch013  ch014  ch015  ch016  \\\n",
       "0          700008    3.0    4.0    2.0    1.0    4.0    2.0    5.0  174.0   \n",
       "1          700008    3.0    3.0    2.0    3.0    6.0    2.0    5.0  174.0   \n",
       "2          700025    3.0    3.0    2.0    1.0    5.0    2.0    5.0  171.0   \n",
       "3          700025    3.0    3.0    3.0    1.0    4.0    1.0    5.0  171.0   \n",
       "4          700025    3.0    3.0    3.0    1.0    4.0    1.0    5.0  173.0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "14138      733171    3.0    4.0    3.0    1.0    5.0    1.0    5.0  183.0   \n",
       "14139      733171    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "14140      733176    5.0    3.0    1.0    1.0    5.0    1.0    6.0  190.0   \n",
       "14141      733176    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "14142      733176    5.0    3.0    2.0    1.0    5.0    1.0    5.0  189.0   \n",
       "\n",
       "       ch017  ...  cw098  cw099  cw100  cw101  cw102       cr120  cw522  \\\n",
       "0       70.0  ...    0.0    0.0    0.0    0.0    0.0  299.000000    0.0   \n",
       "1       64.0  ...    NaN    NaN    NaN    NaN    NaN         NaN    NaN   \n",
       "2       61.0  ...    0.0    0.0    0.0    1.0    0.0  439.000000    0.0   \n",
       "3       63.0  ...    0.0    0.0    0.0    1.0    0.0  275.000000    0.0   \n",
       "4       64.0  ...    0.0    0.0    0.0    0.0    0.0   96.000000    0.0   \n",
       "...      ...  ...    ...    ...    ...    ...    ...         ...    ...   \n",
       "14138   74.0  ...    0.0    0.0    0.0    0.0    0.0  197.369999    0.0   \n",
       "14139    NaN  ...    0.0    0.0    0.0    0.0    0.0  131.000000    0.0   \n",
       "14140   95.0  ...    0.0    0.0    0.0    0.0    0.0  250.000000    0.0   \n",
       "14141    NaN  ...    0.0    0.0    0.0    0.0    0.0         NaN    0.0   \n",
       "14142   91.0  ...    0.0    0.0    0.0    0.0    0.0  246.730000    0.0   \n",
       "\n",
       "       cw523  cw525  cf432  \n",
       "0        0.0    NaN    NaN  \n",
       "1        NaN    NaN    NaN  \n",
       "2        0.0    7.0    5.0  \n",
       "3        0.0    7.0    4.0  \n",
       "4        0.0   11.0    5.0  \n",
       "...      ...    ...    ...  \n",
       "14138    1.0    7.0    4.0  \n",
       "14139    1.0    NaN    4.0  \n",
       "14140    0.0    1.0    4.0  \n",
       "14141    0.0    NaN    4.0  \n",
       "14142    0.0    1.0    5.0  \n",
       "\n",
       "[14143 rows x 430 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create data table \n",
    "dfs = []\n",
    "for year in range(2007,2020):\n",
    "    tempdf = df[[PID_col] + cbf.year2col[year]]\n",
    "    tempdf[\"year\"] = year\n",
    "    tempdf = tempdf[tempdf.isna().sum(axis=1) < 80]\n",
    "    new_names = dict()\n",
    "    for _c in tempdf.columns:\n",
    "        try:\n",
    "            new_names[_c] = cbf.col2id[_c]\n",
    "        except:\n",
    "            pass\n",
    "    tempdf = tempdf.rename(new_names, axis=1)\n",
    "    dfs.append(tempdf)\n",
    "result = pd.concat(dfs, axis=0, join='outer', ignore_index=True).sort_values(PID_col).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset(df=result, target_col=PID_col, col_to_stype=cbf.get_dtype(result.columns))\n",
    "data.materialize()\n",
    "train_data, test_data = data[:0.7], data[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class CustomSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size=4, seed=None):\n",
    "        self.data_source = data_source.df.set_index(PID_col)\n",
    "        self.batch_size = batch_size\n",
    "        self.unique_indices = list(set(self.data_source.index))\n",
    "        self.num_batches = len(self.unique_indices) // batch_size\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffle the unique indices\n",
    "        shuffled_indices = np.random.permutation(self.unique_indices)\n",
    "        for i in range(self.num_batches):\n",
    "            batch_unique_indices = shuffled_indices[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            # Convert unique index values to row indices\n",
    "            row_indices = []\n",
    "            for unique_index in batch_unique_indices:\n",
    "                loc = self.data_source.index.get_loc(unique_index)\n",
    "                if isinstance(loc, slice):\n",
    "                    row_indices.extend(range(loc.start, loc.stop))\n",
    "                elif isinstance(loc, np.ndarray):\n",
    "                    row_indices.extend(loc.tolist())\n",
    "                else:\n",
    "                    row_indices.append(loc)\n",
    "            yield row_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.DataLoader(dataset=data, batch_sampler=CustomSampler(data, batch_size=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, Module, ModuleList\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_frame.nn.conv import TabTransformerConv\n",
    "from torch_frame.nn.encoder import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    StypeWiseFeatureEncoder,\n",
    ")\n",
    "\n",
    "\n",
    "class TabEncoder(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        col_stats: Dict[str, Dict[StatType, Any]],\n",
    "        col_names_dict: Dict[torch_frame.stype, List[str]],\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=hidden_size,\n",
    "            col_stats=col_stats,\n",
    "            col_names_dict=col_names_dict,\n",
    "            stype_encoder_dict={\n",
    "                stype.categorical: EmbeddingEncoder(),\n",
    "                stype.numerical: LinearEncoder()\n",
    "            },\n",
    "        )\n",
    "        self.tab_transformer_convs = ModuleList([\n",
    "            TabTransformerConv(\n",
    "                channels=hidden_size,\n",
    "                num_heads=num_heads,\n",
    "                ffn_dropout=dropout,\n",
    "                attn_dropout= dropout / 3.0,\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.aggregator = Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, tf: TensorFrame) -> Tensor:\n",
    "        x, _ = self.encoder(tf)\n",
    "        for tab_transformer_conv in self.tab_transformer_convs:\n",
    "            x = tab_transformer_conv(x)\n",
    "        out = self.aggregator(x.mean(dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabEncoder(\n",
    "    hidden_size=256,\n",
    "    output_size=64,\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    col_stats=train_data.col_stats,\n",
    "    col_names_dict=train_data.tensor_frame.col_names_dict,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = next(iter(train_loader))\n",
    "y = model(xx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2008.],\n",
       "        [2007.],\n",
       "        [2008.],\n",
       "        [2007.],\n",
       "        [2014.],\n",
       "        [2016.],\n",
       "        [2015.],\n",
       "        [2013.],\n",
       "        [2012.],\n",
       "        [2014.],\n",
       "        [2012.],\n",
       "        [2015.],\n",
       "        [2016.],\n",
       "        [2009.],\n",
       "        [2011.],\n",
       "        [2008.],\n",
       "        [2017.],\n",
       "        [2010.],\n",
       "        [2007.],\n",
       "        [2013.],\n",
       "        [2013.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.get_col_feat(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0022,  0.0496, -0.0217,  ..., -0.0172, -0.0736,  0.0259],\n",
       "        [ 0.0190,  0.0168,  0.0391,  ..., -0.0509, -0.0722,  0.1620],\n",
       "        [-0.0015,  0.0532, -0.0146,  ..., -0.0252, -0.0716,  0.0398],\n",
       "        ...,\n",
       "        [ 0.0153,  0.0193,  0.0372,  ..., -0.0508, -0.0717,  0.1598],\n",
       "        [-0.0042,  0.0496, -0.0185,  ..., -0.0262, -0.0756,  0.0321],\n",
       "        [-0.0031,  0.0564, -0.0154,  ..., -0.0227, -0.0760,  0.0416]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([718795., 718795., 714323., 714323., 725563., 711529., 711529., 711529.,\n",
       "        711529., 711529., 730280., 730280., 730280., 730280., 730280., 730280.,\n",
       "        730280., 730280., 730280., 730280., 716709.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
