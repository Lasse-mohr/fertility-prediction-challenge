{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import polars as pl     # requires installing polars first\n",
    "import pyarrow          # requires installing pyarrow first\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Model\n",
    "import numpy as np\n",
    "import torch_frame as tf\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeBookFilter:\n",
    "    def __init__(self, path: str, accept_missing_rate: float = 0.05, column_appeared_times: int = 8) -> None:\n",
    "        assert accept_missing_rate >= 0 and accept_missing_rate <=1.0\n",
    "        assert column_appeared_times > 0\n",
    "        self.column_appeared_times = column_appeared_times\n",
    "        self.accept_missing_rate = accept_missing_rate\n",
    "\n",
    "\n",
    "        codebook = pl.read_csv(path).to_pandas()\n",
    "\n",
    "        self.column_appeared_times = column_appeared_times\n",
    "        self.codebook = self._filter_codebook(codebook=codebook) # CodeBook Filtered\n",
    "        self.valid_columns = self._return_valid_columns()\n",
    "        self._create_column_dict()\n",
    "    \n",
    "    def _filter_codebook(self, codebook):\n",
    "            codebook = codebook[codebook[\"prop_missing\"] < self.accept_missing_rate]\n",
    "            codebook = codebook[codebook[\"type_var\"].isin([\"numeric\", \"categorical\"])]\n",
    "            return codebook\n",
    "    def _return_valid_columns(self):\n",
    "        column_appeared = defaultdict(int)\n",
    "        for year in range(2007,2020):\n",
    "            _cols = self.codebook[self.codebook[\"year\"] == year][\"var_name\"].values\n",
    "            _cols = [self._match(x) for x in _cols]\n",
    "            for _c in _cols:\n",
    "                if _c != None:\n",
    "                    column_appeared[_c] += 1\n",
    "        return set([k for k,v in column_appeared.items() if v>self.column_appeared_times])\n",
    "    \n",
    "    def _create_column_dict(self):\n",
    "        self.col2id = dict()\n",
    "        self.year2col = dict()\n",
    "        self.col2dtype = dict()\n",
    "        for year in range(2007,2020):\n",
    "            _cols = self.codebook[self.codebook[\"year\"] == year][\"var_name\"].values\n",
    "            _matched_cols = list()\n",
    "            for _c in _cols:\n",
    "                if self._match(_c) in self.valid_columns:\n",
    "                    self.col2id[_c] = self._match(_c)\n",
    "                    self.col2dtype[_c] = self.codebook[self.codebook[\"var_name\"] == _c][\"type_var\"].values[0]\n",
    "                    self.col2dtype[self._match(_c)] = self.codebook[self.codebook[\"var_name\"] == _c][\"type_var\"].values[0]\n",
    "                    _matched_cols.append(_c)\n",
    "            self.year2col[year] = _matched_cols\n",
    "\n",
    "\n",
    "    def _match(self, x):\n",
    "        \"\"\"\n",
    "        Returns standardized name of the column if possible: XXNNN\"\"\"\n",
    "        pattern = re.compile(r'^([a-zA-Z]{2}).*([0-9]{3})$')\n",
    "        m = pattern.match(x)\n",
    "        if m:\n",
    "            return(\"%s%s\"%(m.group(1), m.group(2)))\n",
    "        return None\n",
    "\n",
    "    def return_valid_column_names(self):\n",
    "        return list(self.col2id.keys())\n",
    "    def return_valid_column_transformed_names(self):\n",
    "        return list(set([i for i in self.col2id.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf = CodeBookFilter(path = \"data/codebooks/PreFer_codebook.csv\", accept_missing_rate=0.02, column_appeared_times=8)\n",
    "PID_col = \"nomem_encr\"\n",
    "df = pl.read_csv(\"data/training_data/PreFer_train_data.csv\",\n",
    "                     infer_schema_length=7418, columns=[PID_col, \"outcome_available\"]+ cbf.return_valid_column_names()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>var_label</th>\n",
       "      <th>values_cat</th>\n",
       "      <th>labels_cat</th>\n",
       "      <th>unique_values_n</th>\n",
       "      <th>n_missing</th>\n",
       "      <th>prop_missing</th>\n",
       "      <th>type_var</th>\n",
       "      <th>note</th>\n",
       "      <th>year</th>\n",
       "      <th>survey</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nomem_encr</td>\n",
       "      <td>Number of household member encrypted</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>All surveys</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cf08a_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cf09b_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf10c_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cf11d_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_name                             var_label values_cat labels_cat  \\\n",
       "0  nomem_encr  Number of household member encrypted                         \n",
       "2     cf08a_m   Year and month of field work period                         \n",
       "3     cf09b_m   Year and month of field work period                         \n",
       "4     cf10c_m   Year and month of field work period                         \n",
       "5     cf11d_m   Year and month of field work period                         \n",
       "\n",
       "   unique_values_n  n_missing  prop_missing type_var note    year  \\\n",
       "0              NaN          0           0.0  numeric          NaN   \n",
       "2              2.0          0           0.0  numeric       2008.0   \n",
       "3              2.0          0           0.0  numeric       2009.0   \n",
       "4              1.0          0           0.0  numeric       2010.0   \n",
       "5              2.0          0           0.0  numeric       2011.0   \n",
       "\n",
       "               survey                dataset  \n",
       "0         All surveys  PreFer_train_data.csv  \n",
       "2  Family & Household  PreFer_train_data.csv  \n",
       "3  Family & Household  PreFer_train_data.csv  \n",
       "4  Family & Household  PreFer_train_data.csv  \n",
       "5  Family & Household  PreFer_train_data.csv  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbf.codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_5110/2432590946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch004</th>\n",
       "      <th>ch005</th>\n",
       "      <th>ch011</th>\n",
       "      <th>ch012</th>\n",
       "      <th>ch013</th>\n",
       "      <th>ch014</th>\n",
       "      <th>ch015</th>\n",
       "      <th>ch016</th>\n",
       "      <th>ch017</th>\n",
       "      <th>ch018</th>\n",
       "      <th>...</th>\n",
       "      <th>cw098</th>\n",
       "      <th>cw099</th>\n",
       "      <th>cw100</th>\n",
       "      <th>cw101</th>\n",
       "      <th>cw102</th>\n",
       "      <th>cr120</th>\n",
       "      <th>cw522</th>\n",
       "      <th>cw523</th>\n",
       "      <th>cw525</th>\n",
       "      <th>cf432</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomem_encr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700008</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700008</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700025</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700025</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700025</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733171</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.369995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733171</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733176</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733176</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.729996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14143 rows × 429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ch004  ch005  ch011  ch012  ch013  ch014  ch015  ch016  ch017  \\\n",
       "nomem_encr                                                                  \n",
       "700008        3.0    4.0    2.0    1.0    4.0    2.0    5.0  174.0   70.0   \n",
       "700008        3.0    3.0    2.0    3.0    6.0    2.0    5.0  174.0   64.0   \n",
       "700025        3.0    3.0    2.0    1.0    5.0    2.0    5.0  171.0   61.0   \n",
       "700025        3.0    3.0    3.0    1.0    4.0    1.0    5.0  171.0   63.0   \n",
       "700025        3.0    3.0    3.0    1.0    4.0    1.0    5.0  173.0   64.0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "733171        3.0    4.0    3.0    1.0    5.0    1.0    5.0  183.0   74.0   \n",
       "733171        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "733176        5.0    3.0    1.0    1.0    5.0    1.0    6.0  190.0   95.0   \n",
       "733176        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "733176        5.0    3.0    2.0    1.0    5.0    1.0    5.0  189.0   91.0   \n",
       "\n",
       "            ch018  ...  cw098  cw099  cw100  cw101  cw102       cr120  cw522  \\\n",
       "nomem_encr         ...                                                         \n",
       "700008        2.0  ...    0.0    0.0    0.0    0.0    0.0  299.000000    0.0   \n",
       "700008        2.0  ...    NaN    NaN    NaN    NaN    NaN         NaN    NaN   \n",
       "700025        1.0  ...    0.0    0.0    0.0    1.0    0.0  439.000000    0.0   \n",
       "700025        1.0  ...    0.0    0.0    0.0    1.0    0.0  275.000000    0.0   \n",
       "700025        1.0  ...    0.0    0.0    0.0    0.0    0.0   96.000000    0.0   \n",
       "...           ...  ...    ...    ...    ...    ...    ...         ...    ...   \n",
       "733171        2.0  ...    0.0    0.0    0.0    0.0    0.0  197.369995    0.0   \n",
       "733171        NaN  ...    0.0    0.0    0.0    0.0    0.0  131.000000    0.0   \n",
       "733176        2.0  ...    0.0    0.0    0.0    0.0    0.0  250.000000    0.0   \n",
       "733176        NaN  ...    0.0    0.0    0.0    0.0    0.0         NaN    0.0   \n",
       "733176        2.0  ...    0.0    0.0    0.0    0.0    0.0  246.729996    0.0   \n",
       "\n",
       "            cw523  cw525  cf432  \n",
       "nomem_encr                       \n",
       "700008        0.0    NaN    NaN  \n",
       "700008        NaN    NaN    NaN  \n",
       "700025        0.0    7.0    5.0  \n",
       "700025        0.0    7.0    4.0  \n",
       "700025        0.0   11.0    5.0  \n",
       "...           ...    ...    ...  \n",
       "733171        1.0    7.0    4.0  \n",
       "733171        1.0    NaN    4.0  \n",
       "733176        0.0    1.0    4.0  \n",
       "733176        0.0    NaN    4.0  \n",
       "733176        0.0    1.0    5.0  \n",
       "\n",
       "[14143 rows x 429 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create data table \n",
    "dfs = []\n",
    "for year in range(2007,2020):\n",
    "    tempdf = df[[PID_col] + cbf.year2col[year]]\n",
    "    tempdf[\"year\"] = year\n",
    "    tempdf = tempdf[tempdf.isna().sum(axis=1) < 80]\n",
    "    new_names = dict()\n",
    "    for _c in tempdf.columns:\n",
    "        try:\n",
    "            new_names[_c] = cbf.col2id[_c]\n",
    "        except:\n",
    "            pass\n",
    "    tempdf = tempdf.rename(new_names, axis=1)\n",
    "    dfs.append(tempdf)\n",
    "result = pd.concat(dfs, axis=0, join='outer', ignore_index=True).sort_values(PID_col).reset_index(drop=True).set_index(PID_col)\n",
    "\n",
    "# Get unique indices\n",
    "#unique_indices = result.index.unique()\n",
    "\n",
    "# Randomly assign each unique index to 0 (train) or 1 (validation)\n",
    "#np.random.seed(42)  # For reproducibility\n",
    "#index_split = pd.Series(np.random.choice([0, 1], size=len(unique_indices), p=[0.7, 0.3]), index=unique_indices)\n",
    "\n",
    "# Map the index_split to the original DataFrame\n",
    "#result['data_split'] = result.index.map(index_split)\n",
    "# Select columns with 'float64' dtype  \n",
    "float64_cols = list(result.select_dtypes(include='float64'))\n",
    "\n",
    "# The same code again calling the columns\n",
    "result = result.astype(\"float32\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical',\n",
       " 'character [almost exclusively empty strings]',\n",
       " 'date or time',\n",
       " 'numeric',\n",
       " 'response to open-ended question'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cbf.col2dtype.values())\n",
    "{'categorical',\n",
    " 'character [almost exclusively empty strings]',\n",
    " 'date or time',\n",
    " 'numeric',\n",
    " 'response to open-ended question'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(cols):\n",
    "    result = dict()\n",
    "    for _c in cols:\n",
    "        try:\n",
    "            col_type = cbf.col2dtype[_c]\n",
    "        except:\n",
    "            col_type = None\n",
    "        if col_type == \"categorical\":\n",
    "            result[_c] = tf.categorical\n",
    "        elif col_type ==\"numerical\":\n",
    "            result[_c] = tf.numerical\n",
    "        else:\n",
    "            result[_c] = tf.numerical\n",
    "\n",
    "    try:\n",
    "        del result[\"data_split\"]\n",
    "    except:\n",
    "        pass\n",
    "    return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ch004    float32\n",
       "ch005    float32\n",
       "ch011    float32\n",
       "ch012    float32\n",
       "ch013    float32\n",
       "          ...   \n",
       "cr120    float32\n",
       "cw522    float32\n",
       "cw523    float32\n",
       "cw525    float32\n",
       "cf432    float32\n",
       "Length: 429, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset(df=result, col_to_stype=get_dtype(result.columns))\n",
    "data.materialize()\n",
    "train_data, test_data = data[:0.7], data[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_frame/data/loader.py:46\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_frame: TensorFrame \u001b[38;5;241m=\u001b[39m dataset\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "train_loader = tf.data.DataLoader(dataset=train_data.tensor_frame, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=429,\n",
       "  num_rows=3,\n",
       "  categorical (391): ['cd002', 'cd003', 'cd035', 'cd038', 'cd041', 'cd042', 'cd043', 'cd044', 'cd045', 'cd046', 'cd047', 'cd048', 'cd049', 'cd050', 'cd051', 'cd052', 'cd053', 'cd054', 'cd055', 'cd058', 'cd073', 'cd074', 'cd075', 'cd076', 'cd077', 'cf001', 'cf003', 'cf024', 'cf388', 'cf389', 'cf390', 'cf391', 'cf392', 'cf432', 'ch004', 'ch005', 'ch011', 'ch012', 'ch013', 'ch014', 'ch015', 'ch018', 'ch020', 'ch021', 'ch022', 'ch023', 'ch024', 'ch025', 'ch026', 'ch027', 'ch028', 'ch029', 'ch030', 'ch031', 'ch032', 'ch033', 'ch034', 'ch035', 'ch036', 'ch037', 'ch038', 'ch039', 'ch040', 'ch041', 'ch042', 'ch043', 'ch044', 'ch045', 'ch070', 'ch071', 'ch072', 'ch073', 'ch074', 'ch075', 'ch076', 'ch077', 'ch078', 'ch079', 'ch099', 'ch125', 'ch133', 'ch159', 'ch160', 'ch161', 'ch162', 'ch163', 'ch169', 'ch170', 'ch171', 'ch172', 'ch173', 'ch174', 'ch175', 'ch176', 'ch177', 'ch178', 'ch179', 'ch180', 'ch181', 'ch182', 'ch183', 'ch184', 'ch196', 'ch197', 'ch198', 'ch199', 'ch200', 'ch202', 'ch203', 'ch218', 'ch219', 'ch220', 'ch221', 'ch222', 'ch223', 'ch224', 'ch225', 'ch226', 'ch227', 'ch228', 'ch229', 'ch232', 'ch233', 'ch234', 'ch235', 'ch250', 'ch251', 'ch252', 'ch253', 'ch254', 'ci001', 'ci003', 'ci005', 'ci008', 'ci037', 'ci038', 'ci039', 'ci040', 'ci041', 'ci042', 'ci043', 'ci044', 'ci045', 'cp001', 'cp002', 'cp003', 'cp004', 'cp005', 'cp006', 'cp007', 'cp008', 'cp009', 'cp011', 'cp012', 'cp013', 'cp014', 'cp015', 'cp016', 'cp017', 'cp018', 'cp135', 'cp184', 'cp185', 'cp186', 'cp187', 'cp188', 'cr002', 'cr011', 'cr012', 'cr030', 'cr041', 'cr042', 'cr079', 'cr080', 'cr081', 'cr082', 'cr083', 'cr084', 'cr085', 'cr086', 'cr087', 'cr089', 'cr092', 'cr093', 'cr094', 'cr095', 'cr097', 'cr098', 'cr109', 'cr110', 'cr111', 'cr112', 'cr113', 'cs002', 'cs003', 'cs004', 'cs005', 'cs006', 'cs007', 'cs008', 'cs009', 'cs010', 'cs011', 'cs012', 'cs013', 'cs014', 'cs015', 'cs016', 'cs017', 'cs018', 'cs019', 'cs020', 'cs021', 'cs022', 'cs023', 'cs024', 'cs025', 'cs026', 'cs027', 'cs028', 'cs029', 'cs030', 'cs031', 'cs032', 'cs033', 'cs034', 'cs035', 'cs036', 'cs037', 'cs038', 'cs039', 'cs040', 'cs041', 'cs042', 'cs043', 'cs044', 'cs045', 'cs046', 'cs047', 'cs048', 'cs049', 'cs050', 'cs051', 'cs052', 'cs053', 'cs054', 'cs055', 'cs056', 'cs057', 'cs058', 'cs059', 'cs060', 'cs061', 'cs062', 'cs063', 'cs070', 'cs077', 'cs082', 'cs083', 'cs087', 'cs088', 'cs089', 'cs090', 'cs102', 'cs103', 'cs104', 'cs130', 'cs132', 'cs133', 'cs134', 'cs135', 'cs136', 'cs137', 'cs138', 'cs139', 'cs141', 'cs142', 'cs143', 'cs144', 'cs145', 'cs146', 'cs147', 'cs148', 'cs149', 'cs150', 'cs151', 'cs152', 'cs153', 'cs154', 'cs155', 'cs156', 'cs157', 'cs158', 'cs159', 'cs284', 'cs285', 'cs286', 'cs287', 'cs288', 'cs289', 'cs294', 'cs295', 'cs296', 'cs297', 'cs298', 'cv001', 'cv002', 'cv003', 'cv004', 'cv006', 'cv007', 'cv008', 'cv010', 'cv012', 'cv024', 'cv047', 'cv048', 'cv049', 'cv050', 'cv051', 'cv052', 'cv065', 'cv066', 'cv067', 'cv068', 'cv069', 'cv070', 'cv071', 'cv072', 'cv073', 'cv074', 'cv098', 'cv106', 'cv107', 'cv108', 'cv109', 'cv110', 'cv111', 'cv112', 'cv113', 'cv114', 'cv115', 'cv116', 'cv117', 'cv118', 'cv119', 'cv120', 'cv121', 'cv122', 'cv123', 'cw000', 'cw001', 'cw004', 'cw005', 'cw008', 'cw011', 'cw012', 'cw013', 'cw014', 'cw015', 'cw016', 'cw017', 'cw018', 'cw019', 'cw020', 'cw021', 'cw022', 'cw023', 'cw024', 'cw025', 'cw026', 'cw027', 'cw028', 'cw088', 'cw089', 'cw090', 'cw091', 'cw092', 'cw093', 'cw094', 'cw095', 'cw096', 'cw097', 'cw098', 'cw099', 'cw100', 'cw101', 'cw102', 'cw522', 'cw523', 'cw525'],\n",
       "  numerical (38): ['cd034', 'cd036', 'cd037', 'cd039', 'cd040', 'cd082', 'cf004', 'cf397', 'ch001', 'ch002', 'ch003', 'ch016', 'ch017', 'ch185', 'ch188', 'ch191', 'ch201', 'ch206', 'ch207', 'ch208', 'ch209', 'ch210', 'ch211', 'ch212', 'ch213', 'ch214', 'ch215', 'ch216', 'ch217', 'ch259', 'ci002', 'cp193', 'cr120', 'cs124', 'cs127', 'cw002', 'cw003', 'year'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index_select([1,2,3]).tensor_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=429,\n",
       "  num_rows=2,\n",
       "  categorical (391): ['cd002', 'cd003', 'cd035', 'cd038', 'cd041', 'cd042', 'cd043', 'cd044', 'cd045', 'cd046', 'cd047', 'cd048', 'cd049', 'cd050', 'cd051', 'cd052', 'cd053', 'cd054', 'cd055', 'cd058', 'cd073', 'cd074', 'cd075', 'cd076', 'cd077', 'cf001', 'cf003', 'cf024', 'cf388', 'cf389', 'cf390', 'cf391', 'cf392', 'cf432', 'ch004', 'ch005', 'ch011', 'ch012', 'ch013', 'ch014', 'ch015', 'ch018', 'ch020', 'ch021', 'ch022', 'ch023', 'ch024', 'ch025', 'ch026', 'ch027', 'ch028', 'ch029', 'ch030', 'ch031', 'ch032', 'ch033', 'ch034', 'ch035', 'ch036', 'ch037', 'ch038', 'ch039', 'ch040', 'ch041', 'ch042', 'ch043', 'ch044', 'ch045', 'ch070', 'ch071', 'ch072', 'ch073', 'ch074', 'ch075', 'ch076', 'ch077', 'ch078', 'ch079', 'ch099', 'ch125', 'ch133', 'ch159', 'ch160', 'ch161', 'ch162', 'ch163', 'ch169', 'ch170', 'ch171', 'ch172', 'ch173', 'ch174', 'ch175', 'ch176', 'ch177', 'ch178', 'ch179', 'ch180', 'ch181', 'ch182', 'ch183', 'ch184', 'ch196', 'ch197', 'ch198', 'ch199', 'ch200', 'ch202', 'ch203', 'ch218', 'ch219', 'ch220', 'ch221', 'ch222', 'ch223', 'ch224', 'ch225', 'ch226', 'ch227', 'ch228', 'ch229', 'ch232', 'ch233', 'ch234', 'ch235', 'ch250', 'ch251', 'ch252', 'ch253', 'ch254', 'ci001', 'ci003', 'ci005', 'ci008', 'ci037', 'ci038', 'ci039', 'ci040', 'ci041', 'ci042', 'ci043', 'ci044', 'ci045', 'cp001', 'cp002', 'cp003', 'cp004', 'cp005', 'cp006', 'cp007', 'cp008', 'cp009', 'cp011', 'cp012', 'cp013', 'cp014', 'cp015', 'cp016', 'cp017', 'cp018', 'cp135', 'cp184', 'cp185', 'cp186', 'cp187', 'cp188', 'cr002', 'cr011', 'cr012', 'cr030', 'cr041', 'cr042', 'cr079', 'cr080', 'cr081', 'cr082', 'cr083', 'cr084', 'cr085', 'cr086', 'cr087', 'cr089', 'cr092', 'cr093', 'cr094', 'cr095', 'cr097', 'cr098', 'cr109', 'cr110', 'cr111', 'cr112', 'cr113', 'cs002', 'cs003', 'cs004', 'cs005', 'cs006', 'cs007', 'cs008', 'cs009', 'cs010', 'cs011', 'cs012', 'cs013', 'cs014', 'cs015', 'cs016', 'cs017', 'cs018', 'cs019', 'cs020', 'cs021', 'cs022', 'cs023', 'cs024', 'cs025', 'cs026', 'cs027', 'cs028', 'cs029', 'cs030', 'cs031', 'cs032', 'cs033', 'cs034', 'cs035', 'cs036', 'cs037', 'cs038', 'cs039', 'cs040', 'cs041', 'cs042', 'cs043', 'cs044', 'cs045', 'cs046', 'cs047', 'cs048', 'cs049', 'cs050', 'cs051', 'cs052', 'cs053', 'cs054', 'cs055', 'cs056', 'cs057', 'cs058', 'cs059', 'cs060', 'cs061', 'cs062', 'cs063', 'cs070', 'cs077', 'cs082', 'cs083', 'cs087', 'cs088', 'cs089', 'cs090', 'cs102', 'cs103', 'cs104', 'cs130', 'cs132', 'cs133', 'cs134', 'cs135', 'cs136', 'cs137', 'cs138', 'cs139', 'cs141', 'cs142', 'cs143', 'cs144', 'cs145', 'cs146', 'cs147', 'cs148', 'cs149', 'cs150', 'cs151', 'cs152', 'cs153', 'cs154', 'cs155', 'cs156', 'cs157', 'cs158', 'cs159', 'cs284', 'cs285', 'cs286', 'cs287', 'cs288', 'cs289', 'cs294', 'cs295', 'cs296', 'cs297', 'cs298', 'cv001', 'cv002', 'cv003', 'cv004', 'cv006', 'cv007', 'cv008', 'cv010', 'cv012', 'cv024', 'cv047', 'cv048', 'cv049', 'cv050', 'cv051', 'cv052', 'cv065', 'cv066', 'cv067', 'cv068', 'cv069', 'cv070', 'cv071', 'cv072', 'cv073', 'cv074', 'cv098', 'cv106', 'cv107', 'cv108', 'cv109', 'cv110', 'cv111', 'cv112', 'cv113', 'cv114', 'cv115', 'cv116', 'cv117', 'cv118', 'cv119', 'cv120', 'cv121', 'cv122', 'cv123', 'cw000', 'cw001', 'cw004', 'cw005', 'cw008', 'cw011', 'cw012', 'cw013', 'cw014', 'cw015', 'cw016', 'cw017', 'cw018', 'cw019', 'cw020', 'cw021', 'cw022', 'cw023', 'cw024', 'cw025', 'cw026', 'cw027', 'cw028', 'cw088', 'cw089', 'cw090', 'cw091', 'cw092', 'cw093', 'cw094', 'cw095', 'cw096', 'cw097', 'cw098', 'cw099', 'cw100', 'cw101', 'cw102', 'cw522', 'cw523', 'cw525'],\n",
       "  numerical (38): ['cd034', 'cd036', 'cd037', 'cd039', 'cd040', 'cd082', 'cf004', 'cf397', 'ch001', 'ch002', 'ch003', 'ch016', 'ch017', 'ch185', 'ch188', 'ch191', 'ch201', 'ch206', 'ch207', 'ch208', 'ch209', 'ch210', 'ch211', 'ch212', 'ch213', 'ch214', 'ch215', 'ch216', 'ch217', 'ch259', 'ci002', 'cp193', 'cr120', 'cs124', 'cs127', 'cw002', 'cw003', 'year'],\n",
       "  has_target=False,\n",
       "  device='mps:0',\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, Module, ModuleList\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_frame.nn.conv import TabTransformerConv\n",
    "from torch_frame.nn.encoder import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    StypeWiseFeatureEncoder,\n",
    ")\n",
    "\n",
    "\n",
    "class TabEncoder(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        col_stats: Dict[str, Dict[StatType, Any]],\n",
    "        col_names_dict: Dict[torch_frame.stype, List[str]],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=hidden_size,\n",
    "            col_stats=col_stats,\n",
    "            col_names_dict=col_names_dict,\n",
    "            stype_encoder_dict={\n",
    "                stype.categorical: EmbeddingEncoder(),\n",
    "                stype.numerical: LinearEncoder()\n",
    "            },\n",
    "        )\n",
    "        self.tab_transformer_convs = ModuleList([\n",
    "            TabTransformerConv(\n",
    "                channels=hidden_size,\n",
    "                num_heads=num_heads,\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.aggregator = Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, tf: TensorFrame) -> Tensor:\n",
    "        x, _ = self.encoder(tf)\n",
    "        for tab_transformer_conv in self.tab_transformer_convs:\n",
    "            x = tab_transformer_conv(x)\n",
    "        out = self.aggregator(x.mean(dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabEncoder(\n",
    "    hidden_size=256,\n",
    "    output_size=64,\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    col_stats=train_data.col_stats,\n",
    "    col_names_dict=train_data.tensor_frame.col_names_dict,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = next(iter(train_loader))\n",
    "y = model(xx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0304, -0.0303, -0.0299, -0.0375, -0.0466, -0.0027, -0.0418, -0.0426,\n",
       "         -0.0293, -0.0646, -0.0043,  0.0447,  0.0745, -0.0342, -0.0002,  0.0457,\n",
       "         -0.0242,  0.0316, -0.0397, -0.0048,  0.0160, -0.0299, -0.0487, -0.0344,\n",
       "          0.0129,  0.0260,  0.0072, -0.0262, -0.0710,  0.0639, -0.0516,  0.0242,\n",
       "          0.0102, -0.0139,  0.0007,  0.0206, -0.0117,  0.0280, -0.0086,  0.0528,\n",
       "         -0.0283, -0.0374,  0.0257, -0.0641, -0.0070,  0.0590, -0.0139, -0.0026,\n",
       "         -0.0180,  0.0847, -0.0059,  0.0022, -0.0314, -0.0223, -0.0384, -0.0639,\n",
       "          0.0187, -0.0420, -0.0032, -0.0059,  0.0532,  0.0212, -0.0022,  0.0221],\n",
       "        [-0.0011,  0.0002, -0.0214, -0.1086, -0.0510, -0.0578, -0.0719, -0.0463,\n",
       "         -0.0784, -0.1176, -0.0196,  0.0210,  0.0928, -0.0345,  0.0223,  0.0399,\n",
       "         -0.0217,  0.0710, -0.0673,  0.0362,  0.0064,  0.0209, -0.0907, -0.1350,\n",
       "          0.0236,  0.0436, -0.0450, -0.0370, -0.0704,  0.0712, -0.0547, -0.0465,\n",
       "          0.0079, -0.0185, -0.0171,  0.0625, -0.0319,  0.0423, -0.0494,  0.0938,\n",
       "         -0.1029, -0.0252,  0.0044, -0.0741, -0.0032,  0.1090,  0.0207, -0.0075,\n",
       "          0.0722,  0.1011,  0.0331, -0.0351,  0.0265, -0.0200, -0.0599, -0.1196,\n",
       "          0.0018, -0.0264, -0.0025, -0.0227, -0.0002,  0.0296,  0.0369, -0.0175]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
