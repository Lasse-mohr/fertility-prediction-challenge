{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import TabularEncoder\n",
    "from data_processing.pipeline import encoding_pipeline, get_generic_name\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b651aa-752a-4c71-990a-332ff4099791",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "Right now the notebook is set to work with fake data. This can be changed once the pipeline works.\n",
    "\n",
    "The data is stored as a Dict[person_id, Sequences] where Sequences is a Dict[year, survery_wave_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c3f871-21e8-418c-9aa7-31ad09283a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and prepare transformations\n",
    "data = pd.read_csv(\"data/training_data/PreFer_train_data.csv\")\n",
    "targets = pd.read_csv('data/training_data/PreFer_train_outcome.csv')\n",
    "codebook = pd.read_csv('data/codebooks/PreFer_codebook.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39d171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.read_csv('features_importance_1000.csv')\n",
    "custom_pairs = importance.iloc[:50].feature.map(lambda x: get_generic_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d165d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n",
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.fillna(101)\n"
     ]
    }
   ],
   "source": [
    "# check if sequences have been preprocessed (saves time)\n",
    "if False:# os.path.exists('data/processed_data/sequences.pt'):\n",
    "    sequences = torch.load('data/processed_data/sequences.pt')\n",
    "else:\n",
    "    sequences = encoding_pipeline(data, codebook, custom_pairs=custom_pairs)\n",
    "    #torch.save(sequences, 'data/processed_data/sequences.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d46110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import PretrainingDataset\n",
    "pretrain_dataset = PretrainingDataset(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddb66e-cba5-4bb9-854d-811d49599b93",
   "metadata": {},
   "source": [
    "# Experimental Encoder (Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8018b-7ebc-4db4-aadf-191b214b1470",
   "metadata": {},
   "source": [
    "# Train the RNN\n",
    "\n",
    "First we need to create Dataset class that can hold both the target (stored in a pd.DataFrame) and the sequences.\n",
    "\n",
    "The sequences will be of dimension 14 x encoding_dimension, because we have 14 years of surveys.\n",
    "\n",
    "I have created some code for getting the data into the right format, but it might not be useful.\n",
    "\n",
    "## Regarding masks\n",
    "Right now the masking is done already in the encoding. I haven't found exactly where Mikkel implemented this.\n",
    "So for now, assume that nothing is padded, and then we'll figure it out with Mikkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1786da-d2b5-4e1f-81f6-1db7bca5515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its not everyone we have a target for, so we do restrict the data to \n",
    "# the ones with known outcomes\n",
    "targets = targets[targets.new_child.notna()]\n",
    "train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754d624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data = {person_id: (\n",
    "        torch.tensor([year-2007 for year, _ in wave_responses.items()]).to(device),\n",
    "        torch.tensor([ wave_response for _, wave_response in wave_responses.items()]).to(device)\n",
    "        )\n",
    "        for person_id, wave_responses in sequences.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eaadc01-1e81-4727-b7f4-f14823463fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the splits made for the target\n",
    "train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d85edc9-8457-439f-8fe9-fbd94eb9b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import FinetuningDataset\n",
    "train_dataset = FinetuningDataset(train_data, targets = targets)\n",
    "test_dataset = FinetuningDataset(test_data, targets = targets)\n",
    "\n",
    "rnn_batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=rnn_batch_size, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=rnn_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf49964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "# ft - fine-tuning\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "ENCODING_SIZE = 64\n",
    "NUM_COLS = 44\n",
    "\n",
    "SEQ_LEN = pretrain_dataset.get_seq_len()\n",
    "VOCAB_SIZE = pretrain_dataset.get_vocab_size()\n",
    "\n",
    "num_epochs_ft = 10\n",
    "learning_rate_ft = 1e-3\n",
    "\n",
    "encoder = TabularEncoder(vocab_size=VOCAB_SIZE, \n",
    "                         embedding_size=HIDDEN_SIZE, \n",
    "                         output_size=ENCODING_SIZE, \n",
    "                         num_layers=2, \n",
    "                         sequence_len=SEQ_LEN, \n",
    "                         layer_type = \"excel\",\n",
    "                         num_cols=NUM_COLS).to(device)\n",
    "\n",
    "decoder = GRUDecoder(\n",
    "    input_size=ENCODING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=2,\n",
    "    max_seq_len=14,\n",
    "    dropout=0.15,\n",
    "    bidirectional=False,\n",
    "    with_attention = True\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer for RNN\n",
    "ft_loss = nn.BCELoss()\n",
    "ft_optimizer = torch.optim.NAdam(list(decoder.parameters()) + list(encoder.parameters()) , lr=learning_rate_ft, weight_decay=1e-2, decoupled_weight_decay=True)\n",
    "ft_scheduler = optim.lr_scheduler.CosineAnnealingLR(ft_optimizer, T_max = num_epochs_ft, eta_min = 1e-6, last_epoch = -1)\n",
    "\n",
    "# Training loop\n",
    "decoder.train()\n",
    "encoder.train()\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82cf1777-49e7-462d-ae51-549ea6c8305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:05, 13.38it/s, mean loss: 0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1: 79it [00:04, 16.50it/s, mean loss: 0.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 2: 79it [00:04, 16.82it/s, mean loss: 0.300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 3: 79it [00:04, 16.84it/s, mean loss: 0.232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 4: 79it [00:04, 16.76it/s, mean loss: 0.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 5: 79it [00:04, 16.18it/s, mean loss: 0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 6: 79it [00:04, 16.80it/s, mean loss: 0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 7: 79it [00:04, 16.63it/s, mean loss: 0.076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 8: 79it [00:04, 16.33it/s, mean loss: 0.059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 9: 79it [00:04, 16.57it/s, mean loss: 0.053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_per_epoch = []\n",
    "for epoch in range(num_epochs_ft):\n",
    "    # print(epoch)\n",
    "    loss_per_step = []\n",
    "    loop_object  = tqdm(enumerate(train_dataloader), desc=f\"Epochs {epoch}\")\n",
    "    for i, batch in loop_object :        \n",
    "        ft_optimizer.zero_grad() \n",
    "        inputs, labels = batch\n",
    "        labels = labels.to(torch.float).to(device)\n",
    "\n",
    "        input_year, input_seq = inputs\n",
    "        bs, ss = labels.size(0), 14\n",
    "        input_year = input_year.reshape(-1).to(device)\n",
    "        input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "        encodings = encoder(input_year, input_seq).view(bs,ss, -1)\n",
    "        mask = ~((input_seq == 101).sum(-1) == NUM_COLS).view(bs,ss).detach()\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = nn.functional.sigmoid(decoder(encodings, mask=mask))\n",
    "\n",
    "        loss = ft_loss(torch.flatten(outputs), labels)  \n",
    "        loss_per_step.append(loss.detach().cpu().numpy())\n",
    "        loop_object.set_postfix_str(\"mean loss: %.3f\"%np.mean(loss_per_step[-100:]))\n",
    "\n",
    "        #loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        ft_optimizer.step()\n",
    "    # On epoch end\n",
    "    loss_per_epoch.append(np.mean(loss_per_step))\n",
    "    ft_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_ft}, Loss: {loss_per_epoch[-1]:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649bc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loss = []\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "## Set both models into the eval mode.=\n",
    "decoder.eval()\n",
    "encoder.eval()\n",
    "for batch in test_dataloader:\n",
    "    inputs, labels = batch\n",
    "    labels = labels.to(torch.float).to(device)\n",
    "\n",
    "    input_year, input_seq = inputs\n",
    "    bs, ss = labels.size(0), 14\n",
    "    input_year = input_year.reshape(-1).to(device)\n",
    "    input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "    encodings = encoder(input_year, input_seq).view(bs,ss, -1)\n",
    "    mask = ~((input_seq == 101).sum(-1) == NUM_COLS).view(bs,ss).detach()\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    xx = decoder(encodings, mask)\n",
    "    outputs = torch.nn.functional.sigmoid(xx).flatten()\n",
    "    loss = ft_loss(outputs, labels)  \n",
    "    val_loss.append(loss.detach().cpu().numpy())\n",
    "    preds.extend(outputs.detach().cpu().numpy().tolist())\n",
    "    targets.extend(labels.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d2fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8636\n",
      "Recall: 0.7600\n",
      "F1 Score: 0.8085\n",
      "-- mAP Score: 0.7170 --\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the batches\n",
    "predictions = (torch.tensor(preds) > 0.5).float()\n",
    "probs = F.sigmoid(predictions)\n",
    "actuals = torch.tensor(targets).flatten()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(actuals.cpu().numpy(), predictions.cpu().numpy(), average='binary')\n",
    "map_roc = average_precision_score(actuals.numpy(), probs.numpy())\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"-- mAP Score: {map_roc:.4f} --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b8e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
