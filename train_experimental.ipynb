{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import AutoEncoder, SimpleAutoEncoder\n",
    "from model.layers import ConvEncoderLayer, ConvDecoderLayer, Norm\n",
    "from data_processing.pipeline import encoding_pipeline, get_generic_name\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_frame.nn.conv import TabTransformerConv, ExcelFormerConv\n",
    "from torch_frame.nn.decoder import ExcelFormerDecoder\n",
    "from model.embeddings import SurveyEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b651aa-752a-4c71-990a-332ff4099791",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "Right now the notebook is set to work with fake data. This can be changed once the pipeline works.\n",
    "\n",
    "The data is stored as a Dict[person_id, Sequences] where Sequences is a Dict[year, survery_wave_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c3f871-21e8-418c-9aa7-31ad09283a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_11838/1529815470.py:2: DtypeWarning: Columns (2583,2584,2585,2586,2587,2588,2589,4358,4359,4360,4361,4362,4363,4364,4365,4366,4367,4368,4369,4370,4371,4372,4373,4374,4375,4379,4380,4381,4382,4383,4384,4385,4386,4387,4388,4389,4390,4391,4392,4393,4394,4395,4396,4397,4398,4399,4400,4401,4405,4406,4407,4408,4409,5215,5216,5219,5220,5613,5614,5615,5616,5617,5618,5619,5620,5621,5622,5624,5625,5626,5627,5628,5629,5630,5631,5632,5633,5634,5635,5636,5638,5639,5640,5787,5788,5789,5790,5791,5792,5793,5794,5795,5796,6393,6394,6395,6396,6397,6398,6399,6400,6401,6402,6403,6619,6620,6621,6622,6623,6624,6625,6626,6627,6628,6629,6630,6631,6632,6633,6634,6635,6638,6640,6641,6642,6643,6644,6645,6646,6647,6648,6649,6650,6651,6652,6653,6654,6655,6656,6657,6658,6659,6660,6661,6664,6666,6667,6668,6669,6670,6965,6966,6967,6968,6969,6970,6971,6972,6973,6974,6975,7064,7065,7066,7067,7068,7069,7070,7071,7072,7073,7074,7163,7164,7165,7166,7167,7168,7169,7170,7171,7172,7408,7409,7410,7411,7412,7413,7414,7415,7416,7417,7418,7419,7420,8818,8819,8820,8821,8822,8823,8824,8825,8826,8827,8828,9989,9990,9991,9992,9993,9994,9995,9996,9997,9998,9999,10065,10066,10067,10068,10069,10070,10071,10072,10073,10074,10075,10076,10077,10078,10079,10080,10081,10082,10083,10085,10086,10087,10088,10089,10090,10091,10092,10093,10094,10095,10096,10097,10098,10099,10100,10101,10102,10103,10104,10105,10106,10107,10108,10109,10111,10112,10113,10114,10115,10116,10340,10341,10342,10343,10344,10736,10737,10738,10739,10740,10741,10742,10743,10744,10745,10746,10747,10748,11896,11897,11898,11899,11900,11901,11902,11903,11904,11905,11906,11907,12168,12169,12170,12171,12172,12173,12174,12175,12176,12177,12178,12179,12180,12181,12182,12183,12184,12185,12186,12187,12188,12189,12190,12191,12192,12193,13339,13340,13341,13342,13343,13344,13345,13346,13347,13348,13349,13488,13489,13490,13491,13492,13493,13494,13495,13496,13497,13498,13499,13500,13501,13502,13506,13507,13510,13511,13512,13513,13514,13515,13516,13517,13518,13519,13520,13521,13522,13523,13524,13525,13526,13530,13531,13534,13535,15787,15788,15789,15790,15791,15792,15793,15794,15795,15796,15797,15798,15799,15800,15801,15802,15805,15808,15809,15810,15811,15812,15813,15814,15815,15816,15817,15818,15819,15820,15821,15822,15823,15824,15825,15826,15829,15832,15833,15834,15951,15952,16600,16601,16602,16606,16607,16608,16612,16613,16754,16755,16756,16757,16758,16759,16760,16761,16762,16763,16764,16765,16848,17490,17491,17492,17493,17494,17495,17496,17497,17498,17499,17500,17501,17505,17506,17507,17508,17509,17510,17511,17512,17513,17514,17515,17516,17517,17521,17548,17549,17550,17551,17552,17553,17554,17555,17556,17559,17560,17563,17564,17605,17608,17628,17630,17644,17645,17646,17647,17648,17649,17650,17654,17655,17656,17657,17658,17659,17660,17797,17798,17799,17800,17801,17802,17807,17808,17809,17810,17811,17812,17813,17820,17821,17824,17914,17915,17916,17917,17980,17981,17982,17983,17984,17985,17986,17987,17988,17989,17990,17991,17992,17993,17994,17995,17996,17997,17998,17999,18000,18001,18002,18003,18004,18005,18006,18007,18008,18009,18010,18011,18012,18013,18014,18015,18055,18056,18057,18058,18059,18060,18061,18062,18063,18064,18065,18066,18067,18068,18069,18070,18071,18072,18073,18074,18075,18076,18077,18078,18079,18080,18081,18082,18083,18084,18085,18086,18087,18088,18089,18090,18091,18092,18093,18094,18095,18096,18097,18098,18099,18100,18101,18102,18103,18104,18105,18106,18107,18108,18109,18110,18111,18112,18197,18198,18199,18200,18201,18202,18204,18205,18206,18207,18208,18209,18210,18211,18212,18213,18215,18216,18217,18218,18219,18220,18221,18222,18223,18224,18225,18226,18227,18228,18229,18239,18241,18242,18243,18244,18245,18246,18247,18248,18249,18250,18251,18311,18317,18318,18319,18320,18322,18324,18329,18330,18331,18332,18333,18334,18335,18336,18337,18338,18339,18340,18341,18345,18347,18349,18351,18352,18353,18354,18355,18356,18357,18358,18359,18360,18361,18407,18409,18414,18416,18428,18429,18430,18431,18432,18433,18434,18435,18436,18437,18438,18441,18450,18451,18452,18453,18454,18455,18456,18457,18458,18459,18460,18744,18745,18746,18747,18748,18749,18750,18751,18752,18753,18754,18755,18756,18783,18784,18785,18786,18787,18788,18789,18790,18791,18792,18793,18794,18795,19062,19063,19064,19065,19066,19067,19068,19069,19070,19071,19072,19073,19074,19075,19076,19077,19078,19082,19083,19084,19085,19086,19087,19088,19089,19090,19091,19092,19093,19094,19095,19096,19097,19098,19099,19100,19101,19102,19103,19104,19108,19109,19110,19111,19112,19113,19141,19142,19143,19144,19145,19146,19147,19148,19149,19150,19160,19161,19162,19163,19164,19165,19166,19167,19168,19169,19170,19189,19190,19227,19228,20075,20076,20077,20078,20079,20080,20081,20082,20083,20084,20085,20086,20087,20165,20166,20167,20168,20169,20170,20171,20172,20173,20174,20175,20176,20177,20241,20242,20243,20244,20245,20246,20247,20248,20249,20250,20251,20252,20757,20758,20759,20760,20761,20762,20763,20764,20765,20766,20767,20768,20769,23130,23131,23132,23133,23134,23135,23136,23137,23138,23139,23140,23141,23142,23272,23273,23274,23275,23276,23277,23278,23279,23280,23281,23282,23283,23284,23414,23415,23416,23417,23418,23419,23420,23421,23422,23423,23424,23425,23426,23556,23557,23558,23559,23560,23561,23562,23563,23564,23565,23566,23567,23568,23698,23699,23700,23701,23702,23703,23704,23705,23706,23707,23708,23709,23710,23814,23815,23816,23817,23818,23819,23820,23821,23822,23823,23824,23825,23826,23827,23828,23829,23830,23835,23836,23837,23838,23839,23840,23841,23842,23843,23844,23845,23846,23847,23848,23849,23850,23851,23852,23853,23854,23855,23856,23861,23862,23863,23864,23865,24683,24684,24685,24686,24687,24688,24746,24747,24748,24749,24750,24751,24752,24974,24975,24976,24977,24978,24979,24980,24981,24982,24983,24984,24985,24986,24995,25003,25153,25154,25155,25156,25157,25158,25159,25160,25161,25162,25163,25190,25191,25192,25193,25194,25195,25196,25197,25198,25199,25200,25434,25435,25436,25437,25438,25439,25440,25441,25442,25443,25444,25445,25446,25530,25531,25532,25533,25534,25535,25536,25537,25538,25539,25540,25575,25576,25577,25578,25579,25580,25581,25582,25583,25584,25585,25658,25659,25660,25661,25662,25663,25664,25665,25666,25667,25668,25693,25694,25695,25696,25697,25698,25699,25700,25701,25702,25703,25728,25729,25730,25731,25732,25733,25734,25735,25736,25737,25738,25772,25773,25774,25775,25776,25777,25778,25779,25780,25781,25782,25849,25850,25851,25852,25853,25854,25855,25856,25857,25858,25859,25882,25883,25884,25886,25887,25888,25889,25890,25891,25892,25915,25916,25917,25918,25919,25920,25921,25922,25923,25924,25925,25959,25960,25961,25962,25963,25964,25965,25966,25967,25968,25969,26036,26037,26038,26039,26040,26041,26042,26044,26045,26046,26069,26070,26071,26072,26074,26075,26076,26077,26078,26079,26413,26414,26415,26416,26417,26418,26419,26420,26421,26422,26423,26424,26425,26865,26866,26867,26868,26869,26870,26871,26872,26873,26874,26875,26876,26877,26914,26915,26916,26917,26918,26919,26920,26921,26922,26923,26924,26925,26926,26963,26964,26965,26966,26967,26968,26969,26970,26971,26972,26973,26974,26975,27012,27015,27017,27018,27019,27020,27022,27023,27024,27061,27066,27068,27069,27070,27071,27073,27115,27118,27119,27120,27122,27164,27167,27168,27169,27171,27213,27216,27217,27218,27265,27266,27314,27810,27811,27812,27813,27814,27815,27816,27817,27818,27819,27820,27821,27822,27823,27824,27825,27826,27827,27828,27829,27830,27831,27832,27833,27834,27835,27839,27842,27844,27845,27846,27847,27848,27859,27861,27872,30979,30980,30981,30982,30983,30984,30985,30986,30987,30988,30989,30990,30991,30992,30993,30994,30995,30996,30999,31000,31001,31002,31003,31004,31005,31006,31007,31008,31009,31010,31011,31012,31013,31014,31015,31016,31017,31018,31019,31020,31021,31022,31025,31026,31027,31028,31029,31030) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/training_data/PreFer_train_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "# read in data and prepare transformations\n",
    "data = pd.read_csv(\"data/training_data/PreFer_train_data.csv\")\n",
    "targets = pd.read_csv('data/training_data/PreFer_train_outcome.csv')\n",
    "codebook = pd.read_csv('data/codebooks/PreFer_codebook.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39d171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.read_csv('features_importance_1000.csv')\n",
    "custom_pairs = importance.iloc[:50].feature.map(lambda x: get_generic_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d165d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    }
   ],
   "source": [
    "# check if sequences have been preprocessed (saves time)\n",
    "if False:# os.path.exists('data/processed_data/sequences.pt'):\n",
    "    sequences = torch.load('data/processed_data/sequences.pt')\n",
    "else:\n",
    "    sequences = encoding_pipeline(data, codebook, custom_pairs=custom_pairs)\n",
    "    #torch.save(sequences, 'data/processed_data/sequences.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d46110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import PretrainingDataset\n",
    "pretrain_dataset = PretrainingDataset(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddb66e-cba5-4bb9-854d-811d49599b93",
   "metadata": {},
   "source": [
    "# Experimental Encoder (Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d16002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ExpEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_len: int, embedding_size: int, output_size: int, num_cols: int, num_layers: int = 3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = SurveyEmbeddings(\n",
    "            vocab_size, sequence_len, n_years=14, embedding_dim=embedding_size)\n",
    "\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                ExcelFormerConv(channels=embedding_size, num_cols=num_cols, num_heads=4),\n",
    "                nn.LayerNorm(embedding_size))\n",
    "                 for _ in range(num_layers)])\n",
    "        \n",
    "        self.flatten = ExcelFormerDecoder(in_channels = embedding_size, \n",
    "                                          out_channels=output_size, \n",
    "                                          num_cols= num_cols)\n",
    "        \n",
    "\n",
    "    def forward(self, year, seq):\n",
    "        \"\"\"\n",
    "        Method that returns full encoding-decoding\n",
    "        \"\"\"\n",
    "        x = self.embedding(year, seq)\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8018b-7ebc-4db4-aadf-191b214b1470",
   "metadata": {},
   "source": [
    "# Train the RNN\n",
    "\n",
    "First we need to create Dataset class that can hold both the target (stored in a pd.DataFrame) and the sequences.\n",
    "\n",
    "The sequences will be of dimension 14 x encoding_dimension, because we have 14 years of surveys.\n",
    "\n",
    "I have created some code for getting the data into the right format, but it might not be useful.\n",
    "\n",
    "## Regarding masks\n",
    "Right now the masking is done already in the encoding. I haven't found exactly where Mikkel implemented this.\n",
    "So for now, assume that nothing is padded, and then we'll figure it out with Mikkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1786da-d2b5-4e1f-81f6-1db7bca5515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its not everyone we have a target for, so we do restrict the data to \n",
    "# the ones with known outcomes\n",
    "targets = targets[targets.new_child.notna()]\n",
    "train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "754d624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data = {person_id: (\n",
    "        torch.tensor([year-2007 for year, _ in wave_responses.items()]).to(device),\n",
    "        torch.tensor([ wave_response for _, wave_response in wave_responses.items()]).to(device)\n",
    "        )\n",
    "        for person_id, wave_responses in sequences.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eaadc01-1e81-4727-b7f4-f14823463fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the splits made for the target\n",
    "train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d85edc9-8457-439f-8fe9-fbd94eb9b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import FinetuningDataset\n",
    "train_dataset = FinetuningDataset(train_data, targets = targets)\n",
    "test_dataset = FinetuningDataset(test_data, targets = targets)\n",
    "\n",
    "rnn_batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=rnn_batch_size, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=rnn_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caf49964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is going to set all input MASK to None\n",
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "# ft - fine-tuning\n",
    "\n",
    "HIDDEN_SIZE = 128\n",
    "ENCODING_SIZE = 128\n",
    "NUM_COLS = 44\n",
    "#ENCODING_SIZE = 64\n",
    "learning_rate_autoencoder = 1e-3\n",
    "\n",
    "SEQ_LEN = pretrain_dataset.get_seq_len()\n",
    "VOCAB_SIZE = pretrain_dataset.get_vocab_size()\n",
    "\n",
    "num_epochs_ft = 40\n",
    "learning_rate_ft = 5e-3\n",
    "\n",
    "encoder = ExpEncoder(vocab_size=VOCAB_SIZE, sequence_len=SEQ_LEN, embedding_size=HIDDEN_SIZE, output_size=ENCODING_SIZE, num_cols=NUM_COLS).to(device)\n",
    "\n",
    "rnn_model = GRUDecoder(\n",
    "    input_size=ENCODING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    max_seq_len=14\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer for RNN\n",
    "ft_loss = nn.BCEWithLogitsLoss()\n",
    "ft_optimizer = torch.optim.NAdam(list(rnn_model.parameters()) + list(encoder.parameters()) , lr=learning_rate_ft, weight_decay=1e-2, decoupled_weight_decay=True)\n",
    "ft_scheduler = optim.lr_scheduler.CosineAnnealingLR(ft_optimizer, T_max = num_epochs_ft, eta_min = 1e-6, last_epoch = -1)\n",
    "\n",
    "# Training loop\n",
    "rnn_model.train()\n",
    "encoder.train()\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82cf1777-49e7-462d-ae51-549ea6c8305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 198it [00:23,  8.61it/s, mean loss: 0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1: 198it [00:20,  9.74it/s, mean loss: 0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Loss: 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 2: 198it [00:20,  9.83it/s, mean loss: 0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40, Loss: 0.5266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 3: 198it [00:20,  9.82it/s, mean loss: 0.524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40, Loss: 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 4: 198it [00:20,  9.78it/s, mean loss: 0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40, Loss: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 5: 198it [00:20,  9.87it/s, mean loss: 0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40, Loss: 0.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 6: 198it [00:20,  9.78it/s, mean loss: 0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40, Loss: 0.5152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 7: 198it [00:20,  9.82it/s, mean loss: 0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40, Loss: 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 8: 198it [00:20,  9.72it/s, mean loss: 0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40, Loss: 0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 9: 198it [00:21,  9.41it/s, mean loss: 0.512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40, Loss: 0.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 10: 198it [00:20,  9.55it/s, mean loss: 0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40, Loss: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 11: 198it [00:21,  9.35it/s, mean loss: 0.515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40, Loss: 0.5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 12: 198it [00:21,  9.33it/s, mean loss: 0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40, Loss: 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 13: 198it [00:21,  9.36it/s, mean loss: 0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40, Loss: 0.5113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 14: 198it [00:20,  9.64it/s, mean loss: 0.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40, Loss: 0.5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 15: 132it [00:13,  9.35it/s, mean loss: 0.548]"
     ]
    }
   ],
   "source": [
    "loss_per_epoch = []\n",
    "for epoch in range(num_epochs_ft):\n",
    "    # print(epoch)\n",
    "    loss_per_step = []\n",
    "    loop_object  = tqdm(enumerate(train_dataloader), desc=f\"Epochs {epoch}\")\n",
    "    for i, batch in loop_object :        \n",
    "        ft_optimizer.zero_grad() \n",
    "        inputs, labels = batch\n",
    "        labels = labels.to(torch.float).to(device)\n",
    "\n",
    "        input_year, input_seq = inputs\n",
    "        bs, ss = labels.size(0), input_year.size(1)\n",
    "        input_year = input_year.reshape(-1).to(device)\n",
    "        input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "        encodings = encoder(input_year, input_seq).view(bs,ss, -1)\n",
    "        mask = ((input_seq == 101).sum(-1) == NUM_COLS).view(bs,ss).detach()\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = rnn_model(encodings, mask=~mask)\n",
    "\n",
    "        loss = ft_loss(torch.flatten(outputs), labels)  \n",
    "        loss_per_step.append(loss.detach().cpu().numpy())\n",
    "        loop_object.set_postfix_str(\"mean loss: %.3f\"%np.mean(loss_per_step[-100:]))\n",
    "\n",
    "        #loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        ft_optimizer.step()\n",
    "    # On epoch end\n",
    "    loss_per_epoch.append(np.mean(loss_per_step))\n",
    "    ft_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_ft}, Loss: {loss_per_epoch[-1]:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d5ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False], device='mps:0'),\n",
       " tensor([[101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 181,\n",
       "            0,   0],\n",
       "         [  0, 101, 101, 101, 105,  75, 116, 101, 101,  28,   5,   6, 101, 101,\n",
       "          101,   4,   4, 101, 101,  50, 126, 134, 131, 134, 141, 104, 145,   0,\n",
       "          101, 104, 108, 159,   0,  60, 110, 104, 160, 165,  14, 101, 101, 181,\n",
       "            0,   0],\n",
       "         [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "          101, 101]], device='mps:0'),\n",
       " tensor([[[ 0.4397, -1.2762,  0.7745,  ..., -0.0781,  0.7378, -0.4163],\n",
       "          [ 0.5693, -1.0808,  0.7961,  ..., -0.1096,  0.6795, -0.4693],\n",
       "          [ 0.2827, -0.8925,  0.3476,  ..., -0.1480,  0.3893, -0.2526],\n",
       "          ...,\n",
       "          [ 0.3319, -0.7532,  0.5635,  ..., -0.1441,  0.4237, -0.2261],\n",
       "          [ 0.5409, -0.8473,  0.5373,  ..., -0.0181,  0.5090, -0.2353],\n",
       "          [ 0.5945, -1.2416,  0.7945,  ..., -0.1076,  0.6839, -0.3413]],\n",
       " \n",
       "         [[ 0.2270, -1.4888,  0.7229,  ..., -0.1005,  0.5514, -0.3854],\n",
       "          [ 0.5907, -1.1000,  0.7625,  ..., -0.0454,  0.6965, -0.3631],\n",
       "          [ 0.2766, -0.8921,  0.4031,  ..., -0.0643,  0.4540, -0.1320],\n",
       "          ...,\n",
       "          [ 0.2880, -0.5685,  0.4687,  ..., -0.1558,  0.3049, -0.3378],\n",
       "          [ 0.3072, -0.7637,  0.5813,  ..., -0.1103,  0.2434, -0.2609],\n",
       "          [ 0.5945, -1.2416,  0.7945,  ..., -0.1076,  0.6839, -0.3413]],\n",
       " \n",
       "         [[ 0.5567, -1.2706,  0.7586,  ..., -0.1094,  0.7873, -0.3202],\n",
       "          [ 0.5270, -1.0885,  0.7366,  ..., -0.1044,  0.7247, -0.3864],\n",
       "          [ 0.3102, -0.8267,  0.4110,  ..., -0.0849,  0.5286, -0.1547],\n",
       "          ...,\n",
       "          [ 0.2332, -0.6925,  0.4602,  ..., -0.0838,  0.3691, -0.2324],\n",
       "          [ 0.5132, -0.8212,  0.5369,  ..., -0.0474,  0.6194, -0.2736],\n",
       "          [ 0.5470, -1.2236,  0.7846,  ..., -0.1536,  0.7256, -0.3666]],\n",
       " \n",
       "         [[ 0.6267, -1.2917,  0.7840,  ..., -0.0603,  0.7460, -0.3221],\n",
       "          [ 0.6463, -1.1098,  0.7735,  ..., -0.0125,  0.6876, -0.3787],\n",
       "          [ 0.3789, -0.8566,  0.4346,  ..., -0.0322,  0.4800, -0.1451],\n",
       "          ...,\n",
       "          [ 0.4801, -0.8574,  0.5269,  ...,  0.0916,  0.4183, -0.1372],\n",
       "          [ 0.6279, -0.8415,  0.5074,  ..., -0.0073,  0.4234, -0.3436],\n",
       "          [ 0.5945, -1.2416,  0.7945,  ..., -0.1076,  0.6839, -0.3413]]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0], input_seq[0:14], encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "val_loss = []\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "## Set both models into the eval mode.=\n",
    "rnn_model.eval()\n",
    "autoencoder.eval()\n",
    "for batch in test_dataloader:\n",
    "    inputs, labels = batch\n",
    "    labels = labels.to(torch.float).to(device)\n",
    "\n",
    "    input_year, input_seq = inputs\n",
    "    bs, ss = labels.size(0), 14\n",
    "    input_year = input_year.reshape(-1).to(device)\n",
    "    input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "    encodings = autoencoder.get_encoding(input_year, input_seq).view(bs,ss, -1)\n",
    "    survey_emb = aggregator(encodings)\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    xx = rnn_model(survey_emb)\n",
    "    outputs = torch.nn.functional.sigmoid(xx).flatten()\n",
    "    loss = ft_loss(outputs, labels)  \n",
    "    val_loss.append(loss.detach().cpu().numpy())\n",
    "    preds.extend(outputs.detach().cpu().numpy().tolist())\n",
    "    targets.extend(labels.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  79.6868,  529.0562,  122.7735,  ...,   74.3379, -556.9098,\n",
       "          -675.4937],\n",
       "         [  86.1495,  570.1829,  132.3874,  ...,   80.2999, -599.9509,\n",
       "          -728.2538],\n",
       "         [  85.2354,  566.8043,  131.5119,  ...,   79.5485, -596.7887,\n",
       "          -723.5583],\n",
       "         ...,\n",
       "         [  74.5646,  494.1296,  114.7229,  ...,   69.4697, -520.0018,\n",
       "          -631.0103],\n",
       "         [  71.2082,  481.3701,  111.2558,  ...,   66.8464, -507.5799,\n",
       "          -613.6431],\n",
       "         [  73.0651,  484.0807,  112.4068,  ...,   68.0308, -509.4069,\n",
       "          -618.1808]],\n",
       "\n",
       "        [[  79.6868,  529.0562,  122.7735,  ...,   74.3379, -556.9098,\n",
       "          -675.4937],\n",
       "         [  86.1495,  570.1829,  132.3874,  ...,   80.2999, -599.9509,\n",
       "          -728.2538],\n",
       "         [  85.2354,  566.8043,  131.5119,  ...,   79.5485, -596.7887,\n",
       "          -723.5583],\n",
       "         ...,\n",
       "         [  70.9823,  480.2695,  110.9016,  ...,   66.5088, -506.5378,\n",
       "          -612.0607],\n",
       "         [  70.6130,  477.2684,  110.3055,  ...,   66.3020, -503.4794,\n",
       "          -608.4363],\n",
       "         [  73.0651,  484.0807,  112.4068,  ...,   68.0308, -509.4069,\n",
       "          -618.1808]],\n",
       "\n",
       "        [[  79.6868,  529.0562,  122.7735,  ...,   74.3379, -556.9098,\n",
       "          -675.4937],\n",
       "         [  86.1495,  570.1829,  132.3874,  ...,   80.2999, -599.9509,\n",
       "          -728.2538],\n",
       "         [  85.2354,  566.8043,  131.5119,  ...,   79.5485, -596.7887,\n",
       "          -723.5583],\n",
       "         ...,\n",
       "         [  73.9173,  490.8226,  113.8849,  ...,   68.7612, -516.7307,\n",
       "          -626.2256],\n",
       "         [  70.6890,  477.5433,  110.4356,  ...,   66.4720, -503.6695,\n",
       "          -608.7874],\n",
       "         [  73.0651,  484.0807,  112.4068,  ...,   68.0308, -509.4069,\n",
       "          -618.1808]],\n",
       "\n",
       "        [[  79.6868,  529.0562,  122.7735,  ...,   74.3379, -556.9098,\n",
       "          -675.4937],\n",
       "         [  86.1495,  570.1829,  132.3874,  ...,   80.2999, -599.9509,\n",
       "          -728.2538],\n",
       "         [  85.2354,  566.8043,  131.5119,  ...,   79.5485, -596.7887,\n",
       "          -723.5583],\n",
       "         ...,\n",
       "         [  71.2171,  482.4148,  111.3239,  ...,   66.9074, -508.7547,\n",
       "          -615.1065],\n",
       "         [  70.9905,  479.6180,  110.9440,  ...,   66.7092, -505.9494,\n",
       "          -611.4521],\n",
       "         [  73.0651,  484.0807,  112.4068,  ...,   68.0308, -509.4069,\n",
       "          -618.1808]],\n",
       "\n",
       "        [[  79.6868,  529.0562,  122.7735,  ...,   74.3379, -556.9098,\n",
       "          -675.4937],\n",
       "         [  86.1495,  570.1829,  132.3874,  ...,   80.2999, -599.9509,\n",
       "          -728.2538],\n",
       "         [  85.2354,  566.8043,  131.5119,  ...,   79.5485, -596.7887,\n",
       "          -723.5583],\n",
       "         ...,\n",
       "         [  73.6565,  490.2852,  113.7386,  ...,   68.6368, -516.2197,\n",
       "          -625.7897],\n",
       "         [  71.5382,  482.3287,  111.5556,  ...,   67.1952, -508.6533,\n",
       "          -614.9871],\n",
       "         [  73.0651,  484.0807,  112.4068,  ...,   68.0308, -509.4069,\n",
       "          -618.1808]],\n",
       "\n",
       "        [[  79.0040,  526.4259,  122.0159,  ...,   73.7268, -554.3860,\n",
       "          -671.9166],\n",
       "         [  85.5962,  568.1911,  131.7757,  ...,   79.8111, -598.0932,\n",
       "          -725.5089],\n",
       "         [  84.4399,  563.6042,  130.6028,  ...,   78.8324, -593.6830,\n",
       "          -719.2241],\n",
       "         ...,\n",
       "         [  70.3743,  478.0109,  110.4024,  ...,   65.9838, -504.2960,\n",
       "          -609.0482],\n",
       "         [  70.7388,  478.0050,  110.5828,  ...,   66.4405, -504.2365,\n",
       "          -609.3152],\n",
       "         [  72.7871,  483.3293,  112.2083,  ...,   67.7824, -508.7613,\n",
       "          -617.1013]]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1364\n",
      "Recall: 0.0600\n",
      "F1 Score: 0.0833\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the batches\n",
    "predictions = (torch.tensor(preds) > 0.5).float()\n",
    "actuals = torch.tensor(targets).flatten()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(actuals.cpu().numpy(), predictions.cpu().numpy(), average='binary')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0]],\n",
       "         device='mps:0'),\n",
       "  tensor([[[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [  0,  27,  34,  ..., 171,  76,  73],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [  0,  72, 101,  ..., 177,  30,  32],\n",
       "           [  0, 101, 101,  ..., 177,  91,  97],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 177,  24, 101],\n",
       "           [  0, 101, 101,  ..., 177,   0,   0],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [  0, 101,   3,  ..., 177,  86,  90],\n",
       "           [  0, 101,   3,  ..., 177,  83,  88],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 170,  60,  59],\n",
       "           [  0, 101, 101,  ..., 170,  56,  53],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 181,   0,   0],\n",
       "           [101, 101, 101,  ..., 181,   0,   0],\n",
       "           [101, 101, 101,  ..., 181,   0,   0],\n",
       "           ...,\n",
       "           [  0, 101, 101,  ..., 170,  48,  55],\n",
       "           [  0, 101, 101,  ..., 170,  50,  53],\n",
       "           [101, 101, 101,  ..., 181, 101, 101]]], device='mps:0')],\n",
       " tensor([0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207f1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
