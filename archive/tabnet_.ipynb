{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import polars as pl     # requires installing polars first\n",
    "import pyarrow          # requires installing pyarrow first\n",
    "import re\n",
    "\n",
    "from data_processing.tabnet_utils import CodeBookFilter\n",
    "\n",
    "# Model\n",
    "import numpy as np\n",
    "import torch_frame as tf\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf = CodeBookFilter(path = \"data/codebooks/PreFer_codebook.csv\", accept_missing_rate=0.02, column_appeared_times=8)\n",
    "PID_col = \"nomem_encr\"\n",
    "df = pl.read_csv(\"data/training_data/PreFer_train_data.csv\",\n",
    "                     infer_schema_length=7418, columns=[PID_col, \"outcome_available\"]+ cbf.return_valid_column_names()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>var_label</th>\n",
       "      <th>values_cat</th>\n",
       "      <th>labels_cat</th>\n",
       "      <th>unique_values_n</th>\n",
       "      <th>n_missing</th>\n",
       "      <th>prop_missing</th>\n",
       "      <th>type_var</th>\n",
       "      <th>note</th>\n",
       "      <th>year</th>\n",
       "      <th>survey</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nomem_encr</td>\n",
       "      <td>Number of household member encrypted</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>All surveys</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cf08a_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cf09b_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf10c_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cf11d_m</td>\n",
       "      <td>Year and month of field work period</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td></td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Family &amp; Household</td>\n",
       "      <td>PreFer_train_data.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_name                             var_label values_cat labels_cat  \\\n",
       "0  nomem_encr  Number of household member encrypted                         \n",
       "2     cf08a_m   Year and month of field work period                         \n",
       "3     cf09b_m   Year and month of field work period                         \n",
       "4     cf10c_m   Year and month of field work period                         \n",
       "5     cf11d_m   Year and month of field work period                         \n",
       "\n",
       "   unique_values_n  n_missing  prop_missing type_var note    year  \\\n",
       "0              NaN          0           0.0  numeric          NaN   \n",
       "2              2.0          0           0.0  numeric       2008.0   \n",
       "3              2.0          0           0.0  numeric       2009.0   \n",
       "4              1.0          0           0.0  numeric       2010.0   \n",
       "5              2.0          0           0.0  numeric       2011.0   \n",
       "\n",
       "               survey                dataset  \n",
       "0         All surveys  PreFer_train_data.csv  \n",
       "2  Family & Household  PreFer_train_data.csv  \n",
       "3  Family & Household  PreFer_train_data.csv  \n",
       "4  Family & Household  PreFer_train_data.csv  \n",
       "5  Family & Household  PreFer_train_data.csv  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbf.codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n",
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_6093/1758219417.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tempdf[\"year\"] = year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomem_encr</th>\n",
       "      <th>ch004</th>\n",
       "      <th>ch005</th>\n",
       "      <th>ch011</th>\n",
       "      <th>ch012</th>\n",
       "      <th>ch013</th>\n",
       "      <th>ch014</th>\n",
       "      <th>ch015</th>\n",
       "      <th>ch016</th>\n",
       "      <th>ch017</th>\n",
       "      <th>...</th>\n",
       "      <th>cw098</th>\n",
       "      <th>cw099</th>\n",
       "      <th>cw100</th>\n",
       "      <th>cw101</th>\n",
       "      <th>cw102</th>\n",
       "      <th>cr120</th>\n",
       "      <th>cw522</th>\n",
       "      <th>cw523</th>\n",
       "      <th>cw525</th>\n",
       "      <th>cf432</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14138</th>\n",
       "      <td>733171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.369999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>733171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14140</th>\n",
       "      <td>733176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14141</th>\n",
       "      <td>733176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>733176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.730000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14143 rows × 430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nomem_encr  ch004  ch005  ch011  ch012  ch013  ch014  ch015  ch016  \\\n",
       "0          700008    3.0    4.0    2.0    1.0    4.0    2.0    5.0  174.0   \n",
       "1          700008    3.0    3.0    2.0    3.0    6.0    2.0    5.0  174.0   \n",
       "2          700025    3.0    3.0    2.0    1.0    5.0    2.0    5.0  171.0   \n",
       "3          700025    3.0    3.0    3.0    1.0    4.0    1.0    5.0  171.0   \n",
       "4          700025    3.0    3.0    3.0    1.0    4.0    1.0    5.0  173.0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "14138      733171    3.0    4.0    3.0    1.0    5.0    1.0    5.0  183.0   \n",
       "14139      733171    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "14140      733176    5.0    3.0    1.0    1.0    5.0    1.0    6.0  190.0   \n",
       "14141      733176    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "14142      733176    5.0    3.0    2.0    1.0    5.0    1.0    5.0  189.0   \n",
       "\n",
       "       ch017  ...  cw098  cw099  cw100  cw101  cw102       cr120  cw522  \\\n",
       "0       70.0  ...    0.0    0.0    0.0    0.0    0.0  299.000000    0.0   \n",
       "1       64.0  ...    NaN    NaN    NaN    NaN    NaN         NaN    NaN   \n",
       "2       61.0  ...    0.0    0.0    0.0    1.0    0.0  439.000000    0.0   \n",
       "3       63.0  ...    0.0    0.0    0.0    1.0    0.0  275.000000    0.0   \n",
       "4       64.0  ...    0.0    0.0    0.0    0.0    0.0   96.000000    0.0   \n",
       "...      ...  ...    ...    ...    ...    ...    ...         ...    ...   \n",
       "14138   74.0  ...    0.0    0.0    0.0    0.0    0.0  197.369999    0.0   \n",
       "14139    NaN  ...    0.0    0.0    0.0    0.0    0.0  131.000000    0.0   \n",
       "14140   95.0  ...    0.0    0.0    0.0    0.0    0.0  250.000000    0.0   \n",
       "14141    NaN  ...    0.0    0.0    0.0    0.0    0.0         NaN    0.0   \n",
       "14142   91.0  ...    0.0    0.0    0.0    0.0    0.0  246.730000    0.0   \n",
       "\n",
       "       cw523  cw525  cf432  \n",
       "0        0.0    NaN    NaN  \n",
       "1        NaN    NaN    NaN  \n",
       "2        0.0    7.0    5.0  \n",
       "3        0.0    7.0    4.0  \n",
       "4        0.0   11.0    5.0  \n",
       "...      ...    ...    ...  \n",
       "14138    1.0    7.0    4.0  \n",
       "14139    1.0    NaN    4.0  \n",
       "14140    0.0    1.0    4.0  \n",
       "14141    0.0    NaN    4.0  \n",
       "14142    0.0    1.0    5.0  \n",
       "\n",
       "[14143 rows x 430 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create data table \n",
    "dfs = []\n",
    "for year in range(2007,2020):\n",
    "    tempdf = df[[PID_col] + cbf.year2col[year]]\n",
    "    tempdf[\"year\"] = year\n",
    "    tempdf = tempdf[tempdf.isna().sum(axis=1) < 80]\n",
    "    new_names = dict()\n",
    "    for _c in tempdf.columns:\n",
    "        try:\n",
    "            new_names[_c] = cbf.col2id[_c]\n",
    "        except:\n",
    "            pass\n",
    "    tempdf = tempdf.rename(new_names, axis=1)\n",
    "    dfs.append(tempdf)\n",
    "result = pd.concat(dfs, axis=0, join='outer', ignore_index=True).sort_values(PID_col).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset(df=result, target_col=PID_col, col_to_stype=cbf.get_dtype(result.columns))\n",
    "data.materialize()\n",
    "train_data, test_data = data[:0.7], data[0.7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class CustomSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size=4, seed=None):\n",
    "        self.data_source = data_source.df.set_index(PID_col)\n",
    "        self.batch_size = batch_size\n",
    "        self.unique_indices = list(set(self.data_source.index))\n",
    "        self.num_batches = len(self.unique_indices) // batch_size\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffle the unique indices\n",
    "        shuffled_indices = np.random.permutation(self.unique_indices)\n",
    "        for i in range(self.num_batches):\n",
    "            batch_unique_indices = shuffled_indices[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            # Convert unique index values to row indices\n",
    "            row_indices = []\n",
    "            for unique_index in batch_unique_indices:\n",
    "                loc = self.data_source.index.get_loc(unique_index)\n",
    "                if isinstance(loc, slice):\n",
    "                    row_indices.extend(range(loc.start, loc.stop))\n",
    "                elif isinstance(loc, np.ndarray):\n",
    "                    row_indices.extend(loc.tolist())\n",
    "                else:\n",
    "                    row_indices.append(loc)\n",
    "            yield row_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.DataLoader(dataset=data, batch_sampler=CustomSampler(data, batch_size=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, Module, ModuleList\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_frame.nn.conv import TabTransformerConv\n",
    "from torch_frame.nn.decoder import ExcelFormerDecoder\n",
    "\n",
    "from torch_frame.nn.encoder import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    StypeWiseFeatureEncoder,\n",
    ")\n",
    "\n",
    "\n",
    "class TabEncoder(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        num_cols: int,\n",
    "        col_stats: Dict[str, Dict[StatType, Any]],\n",
    "        col_names_dict: Dict[torch_frame.stype, List[str]],\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=hidden_size,\n",
    "            col_stats=col_stats,\n",
    "            col_names_dict=col_names_dict,\n",
    "            stype_encoder_dict={\n",
    "                stype.categorical: EmbeddingEncoder(),\n",
    "                stype.numerical: LinearEncoder()\n",
    "            },\n",
    "        )\n",
    "        self.tab_transformer_convs = ModuleList([\n",
    "            TabTransformerConv(\n",
    "                channels=hidden_size,\n",
    "                num_heads=num_heads,\n",
    "                ffn_dropout=dropout,\n",
    "                attn_dropout= dropout / 3.0,\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        #self.aggregator = Linear(hidden_size, output_size)\n",
    "        self.norm = torch.nn.LayerNorm(hidden_size)\n",
    "        self.aggregator = ExcelFormerDecoder(in_channels=hidden_size, out_channels=output_size, num_cols=num_cols)\n",
    "\n",
    "    def forward(self, tf: TensorFrame) -> Tensor:\n",
    "        x, _ = self.encoder(tf)\n",
    "        for tab_transformer_conv in self.tab_transformer_convs:\n",
    "            x = tab_transformer_conv(x)\n",
    "        out = self.aggregator(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabEncoder(\n",
    "    hidden_size=256,\n",
    "    output_size=32,\n",
    "    num_cols=429,\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    col_stats=train_data.col_stats,\n",
    "    col_names_dict=train_data.tensor_frame.col_names_dict,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = next(iter(train_loader))\n",
    "y = model(xx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6252e-02, -4.6947e-02, -7.7023e-02, -6.0085e-02, -3.1129e-02,\n",
       "         -5.3647e-02, -8.7403e-02, -6.8112e-02, -1.7283e-02, -3.0689e-02,\n",
       "         -1.5013e-02, -3.6461e-02, -1.6170e-02, -2.6299e-02,  1.6068e-02,\n",
       "         -9.9421e-02, -2.9579e-02, -4.3630e-02, -1.1460e-01, -9.0588e-02,\n",
       "         -1.0174e-01, -5.5973e-03, -6.4619e-02, -2.4721e-02, -4.7826e-02,\n",
       "         -5.9996e-02, -4.8672e-02, -3.0717e-02, -8.5568e-02, -4.4220e-02,\n",
       "         -6.7584e-02, -6.9223e-02],\n",
       "        [-7.8907e-02, -3.6700e-02, -4.6518e-02, -6.2875e-03, -4.8517e-02,\n",
       "         -9.5982e-02, -5.7317e-02, -6.3849e-02, -5.3177e-02,  9.5596e-03,\n",
       "         -7.9327e-04, -6.2242e-02, -3.9515e-02, -2.5262e-02,  4.2245e-03,\n",
       "         -9.4060e-02, -3.4260e-02, -5.7771e-02, -2.6479e-02, -8.8618e-02,\n",
       "         -6.5816e-02,  2.2451e-02, -8.5282e-02, -3.5081e-02, -3.4729e-02,\n",
       "         -6.7824e-02, -3.5838e-02, -3.3604e-02, -2.7031e-02, -3.6856e-02,\n",
       "          5.6459e-03, -4.3361e-02],\n",
       "        [-6.6066e-02,  9.0571e-04, -1.0659e-01, -4.1366e-02, -8.2080e-02,\n",
       "         -5.6424e-02, -5.2286e-02, -5.4268e-02, -6.9135e-02, -2.1269e-02,\n",
       "         -1.8710e-02, -6.3855e-02, -6.7098e-02, -4.5184e-03, -4.1549e-04,\n",
       "         -7.2116e-02, -3.0019e-02, -4.1043e-02, -4.8689e-02, -9.1117e-02,\n",
       "         -8.4192e-02, -2.5276e-02, -9.7807e-02,  2.3270e-02, -2.8098e-02,\n",
       "         -7.8756e-02, -7.0565e-02,  4.8412e-03, -7.6529e-02, -3.7791e-02,\n",
       "         -2.5117e-02, -7.2489e-02],\n",
       "        [-8.5791e-02, -3.8419e-02, -4.8326e-02, -3.9102e-02, -9.1815e-02,\n",
       "         -9.4520e-02, -3.0208e-02, -1.0031e-01, -5.6799e-02, -1.2431e-02,\n",
       "         -3.6196e-02, -5.0869e-02, -5.2288e-02, -3.0655e-02, -2.1200e-02,\n",
       "         -8.9068e-02, -1.7577e-02, -5.1923e-02, -8.5069e-02, -8.1937e-02,\n",
       "         -7.9167e-02, -3.5193e-02, -7.3351e-02, -3.7239e-02, -7.7873e-02,\n",
       "         -5.2245e-02, -8.3557e-02, -7.2227e-02, -7.5879e-02, -5.3449e-02,\n",
       "         -5.0133e-02, -2.8658e-02],\n",
       "        [ 2.3080e-03, -1.7108e-02, -5.8593e-02, -5.9714e-02, -1.4627e-03,\n",
       "         -7.3275e-02, -4.8621e-02, -2.9047e-02, -6.0343e-02, -5.2986e-02,\n",
       "         -3.3818e-02, -3.8016e-02, -3.1458e-02,  2.7860e-02,  2.2477e-02,\n",
       "         -2.3229e-02, -1.1474e-02, -4.9811e-02, -5.6296e-02, -9.3679e-02,\n",
       "         -8.1670e-02, -9.0075e-03, -1.1473e-01, -3.8488e-02, -7.1561e-02,\n",
       "         -3.6894e-02, -7.1319e-02, -4.7400e-02, -9.1343e-02, -8.6018e-02,\n",
       "         -1.7185e-02, -5.1338e-02],\n",
       "        [-4.0242e-02, -5.7233e-03, -1.3529e-02, -6.2595e-02, -9.2358e-03,\n",
       "         -5.8024e-02, -4.8811e-02, -6.6387e-02, -5.4147e-02,  1.8344e-02,\n",
       "         -3.0221e-02, -6.4865e-02, -8.3788e-02,  2.5924e-02,  1.4422e-02,\n",
       "         -7.0884e-02,  2.8011e-03, -5.4324e-02, -9.2056e-02, -6.5953e-02,\n",
       "         -6.4307e-02,  1.5402e-03, -8.0096e-02, -2.7961e-02, -4.4312e-02,\n",
       "         -7.0566e-02, -6.8220e-02, -3.8889e-02, -7.4344e-02, -6.2133e-02,\n",
       "         -1.4062e-02, -6.1382e-02],\n",
       "        [-9.7062e-03, -4.8172e-02, -7.1600e-02, -4.2941e-02, -6.0530e-02,\n",
       "         -8.0205e-02, -6.8204e-02, -5.8900e-02, -5.0499e-02, -4.7380e-02,\n",
       "         -1.3915e-02, -4.1004e-02, -6.9980e-02, -2.9810e-02, -6.0987e-02,\n",
       "         -7.5014e-02, -9.9296e-04, -4.9084e-02, -5.3922e-02, -1.2308e-01,\n",
       "         -5.3331e-02, -1.8110e-02, -8.7497e-02, -4.2979e-02, -2.8150e-02,\n",
       "         -9.9950e-02, -6.9315e-02, -1.3608e-02, -6.2362e-02, -1.6637e-02,\n",
       "          5.7850e-04, -9.5135e-02],\n",
       "        [-3.9794e-02, -2.4952e-02, -2.3051e-03, -6.7520e-02, -5.1774e-02,\n",
       "         -3.7732e-02, -3.3588e-02, -8.7724e-02, -4.1764e-02, -1.2149e-02,\n",
       "         -3.0782e-02, -6.2850e-02,  4.6912e-02,  1.0521e-02, -3.3152e-02,\n",
       "         -7.1266e-02, -5.9462e-02, -8.3432e-02, -8.2324e-02, -8.4274e-02,\n",
       "         -1.1362e-01, -3.3003e-02, -5.6884e-02, -1.9236e-02, -1.1014e-01,\n",
       "         -7.0700e-02, -5.6889e-02, -3.4693e-02, -7.4828e-02, -5.2571e-02,\n",
       "         -3.0836e-02, -3.4810e-02],\n",
       "        [ 5.1649e-02, -2.9400e-02, -2.4492e-02, -8.0311e-02, -4.1296e-02,\n",
       "         -5.4507e-02, -1.0413e-01, -8.0439e-02, -1.2158e-02, -4.5670e-02,\n",
       "         -4.8669e-02, -5.5125e-02, -8.5051e-03,  3.5531e-02, -1.8952e-02,\n",
       "         -1.2447e-02, -4.1398e-02, -4.8518e-02, -9.2697e-02, -1.1482e-01,\n",
       "         -9.8194e-02, -3.7069e-02, -6.4147e-02,  3.8735e-02, -8.5676e-02,\n",
       "         -6.1328e-02,  1.4433e-02, -6.1350e-02, -1.3034e-02,  2.3163e-02,\n",
       "         -2.4952e-02, -8.3835e-02],\n",
       "        [-1.4742e-02, -8.6465e-03, -7.0006e-02, -9.5029e-02, -4.5374e-02,\n",
       "         -6.9360e-02, -5.8248e-02, -1.1065e-01, -4.5037e-02, -3.0107e-02,\n",
       "         -3.2959e-02, -3.5262e-02, -8.8241e-02, -1.1335e-02,  4.9907e-03,\n",
       "         -9.4373e-02, -2.0107e-03, -7.6466e-02, -4.8569e-02, -6.4938e-02,\n",
       "         -7.0004e-02,  9.5989e-03, -6.3784e-02, -4.7173e-02, -2.5747e-02,\n",
       "         -7.9659e-02, -4.1002e-02, -4.7938e-02, -5.1705e-02, -3.7654e-02,\n",
       "         -1.0253e-02, -3.9855e-02],\n",
       "        [-3.8497e-02, -5.4849e-02, -7.8905e-02, -6.6639e-02, -1.0351e-01,\n",
       "         -3.6480e-02, -4.1299e-02, -8.8169e-02, -6.0834e-02, -3.0537e-02,\n",
       "         -3.8714e-02, -2.0418e-02, -5.3856e-02,  2.6263e-03, -3.9551e-03,\n",
       "         -9.4642e-02, -1.9437e-02, -5.0735e-02, -9.8049e-02, -1.2141e-01,\n",
       "         -6.6518e-02, -7.1458e-03, -7.4048e-02,  1.0326e-03, -4.8690e-05,\n",
       "         -3.4135e-02, -6.5168e-02, -1.2240e-02, -1.0541e-01, -2.6496e-02,\n",
       "         -6.7422e-02, -2.3127e-02],\n",
       "        [-4.1856e-02, -9.0950e-02, -6.5521e-02, -7.1876e-02, -4.7636e-02,\n",
       "         -4.6092e-02, -8.8965e-02, -4.0270e-02, -6.4200e-02, -3.0720e-02,\n",
       "         -3.2439e-02, -3.0685e-02, -1.2092e-02,  1.7371e-02, -2.9935e-02,\n",
       "         -8.8567e-02, -6.3532e-02, -3.0367e-02, -6.2834e-02, -1.1826e-01,\n",
       "         -6.9231e-02, -2.1738e-02, -8.0225e-02, -5.3274e-02, -2.8234e-02,\n",
       "         -7.5990e-02, -9.2694e-02, -7.4008e-02, -3.2739e-02, -5.4192e-02,\n",
       "         -1.2593e-02, -3.4205e-02],\n",
       "        [-2.3545e-03, -5.7169e-02, -4.1462e-02, -4.5172e-02, -8.3359e-02,\n",
       "         -6.4447e-02, -1.0103e-01, -1.0055e-01, -5.9587e-02, -1.8126e-02,\n",
       "          1.8725e-03, -5.1597e-02, -4.0462e-02,  7.1527e-03, -1.5581e-02,\n",
       "         -9.7249e-02, -2.8951e-02, -3.7246e-02, -7.9878e-02, -5.6344e-02,\n",
       "         -7.7934e-02, -2.2322e-02, -6.2453e-02,  1.3009e-02, -2.1647e-02,\n",
       "         -4.0861e-02, -5.8474e-02, -5.4228e-02, -4.1921e-02, -7.5970e-02,\n",
       "         -5.7306e-02, -6.7680e-02],\n",
       "        [-2.8402e-02, -3.7396e-02, -5.3885e-02, -4.0690e-02, -7.3045e-02,\n",
       "         -4.3833e-02, -9.9861e-02, -5.4816e-02, -2.9948e-02, -3.7704e-02,\n",
       "         -4.5538e-02, -5.5533e-02, -4.4813e-02,  2.0398e-02, -6.4819e-02,\n",
       "         -4.5223e-02,  1.4825e-03, -1.3553e-02, -5.1472e-02, -7.6216e-02,\n",
       "         -8.4451e-02,  2.2230e-03, -9.1235e-02, -1.6998e-02, -1.6966e-02,\n",
       "         -2.6866e-02, -5.5462e-02, -4.9541e-02, -7.7492e-02, -7.5522e-02,\n",
       "         -4.4711e-02, -7.3308e-02],\n",
       "        [ 3.1111e-02, -4.3087e-02, -5.1074e-02, -6.7890e-02, -3.5409e-02,\n",
       "         -7.8899e-02, -3.8751e-02, -4.9853e-02, -2.0564e-02, -6.1895e-02,\n",
       "         -4.4091e-02, -4.8671e-02, -7.5636e-02,  1.0952e-02, -2.4752e-03,\n",
       "         -3.9317e-02, -2.7232e-02, -7.4108e-02, -1.1455e-01, -1.1137e-01,\n",
       "         -1.0589e-01, -4.9617e-02, -7.5629e-02,  3.2337e-02, -1.0150e-01,\n",
       "         -6.0609e-02,  5.3882e-03, -5.3200e-02, -3.5289e-02, -2.8188e-02,\n",
       "         -5.0240e-02, -3.9864e-02],\n",
       "        [-4.2502e-02, -1.0095e-02, -6.1744e-02, -4.8159e-02, -2.0984e-03,\n",
       "         -6.7588e-02, -6.8373e-02, -3.1929e-02, -6.0569e-02, -2.2446e-02,\n",
       "         -1.2655e-01, -4.9133e-02, -9.8909e-02,  1.0573e-02, -1.9047e-02,\n",
       "         -3.0347e-02, -3.8991e-02, -1.9709e-02, -4.4180e-02, -5.7315e-02,\n",
       "         -8.7516e-02,  2.7901e-02, -7.6632e-02, -1.4019e-02, -1.0531e-01,\n",
       "         -7.2367e-02, -6.1773e-02, -4.7811e-02, -5.7702e-02, -1.0042e-01,\n",
       "         -5.8859e-02, -2.2357e-02]], device='mps:0',\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2008.],\n",
       "        [2007.],\n",
       "        [2008.],\n",
       "        [2007.],\n",
       "        [2014.],\n",
       "        [2016.],\n",
       "        [2015.],\n",
       "        [2013.],\n",
       "        [2012.],\n",
       "        [2014.],\n",
       "        [2012.],\n",
       "        [2015.],\n",
       "        [2016.],\n",
       "        [2009.],\n",
       "        [2011.],\n",
       "        [2008.],\n",
       "        [2017.],\n",
       "        [2010.],\n",
       "        [2007.],\n",
       "        [2013.],\n",
       "        [2013.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.get_col_feat(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0022,  0.0496, -0.0217,  ..., -0.0172, -0.0736,  0.0259],\n",
       "        [ 0.0190,  0.0168,  0.0391,  ..., -0.0509, -0.0722,  0.1620],\n",
       "        [-0.0015,  0.0532, -0.0146,  ..., -0.0252, -0.0716,  0.0398],\n",
       "        ...,\n",
       "        [ 0.0153,  0.0193,  0.0372,  ..., -0.0508, -0.0717,  0.1598],\n",
       "        [-0.0042,  0.0496, -0.0185,  ..., -0.0262, -0.0756,  0.0321],\n",
       "        [-0.0031,  0.0564, -0.0154,  ..., -0.0227, -0.0760,  0.0416]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([718795., 718795., 714323., 714323., 725563., 711529., 711529., 711529.,\n",
       "        711529., 711529., 730280., 730280., 730280., 730280., 730280., 730280.,\n",
       "        730280., 730280., 730280., 730280., 716709.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
