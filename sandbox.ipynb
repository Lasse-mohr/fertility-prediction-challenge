{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import AutoEncoder\n",
    "import torch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "### Initialization of the Autoencoder \n",
    "SEQ_LEN = 3000\n",
    "HIDDEN_DIM = 512\n",
    "ENCODING_SIZE = 64\n",
    "model = AutoEncoder(vocab_size=100, embedding_size=HIDDEN_DIM, encoding_size=ENCODING_SIZE, sequence_len=SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assume we have a batch of 2 people\n",
    "x = torch.randint(1,99, size=(2,SEQ_LEN))\n",
    "y = model(x) \n",
    "## returns the original shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only to use the encoder part \n",
    "y = model.encode(x) # here y contains embedding of a survey per row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze - Excite Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3000, 1])\n",
      "torch.Size([2, 3000])\n",
      "torch.Size([2, 3000])\n",
      "torch.Size([2, 3000, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, num_columns, hidden_size, reduction_ratio=16):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        # Assuming the reduction happens across the hidden_size\n",
    "        self.num_columns = num_columns\n",
    "        self.reduced_size = max(1, hidden_size // reduction_ratio)\n",
    "        \n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)  # Squeezes hidden_size to 1\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(num_columns, self.reduced_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.reduced_size, num_columns),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_columns, hidden_size]\n",
    "        # Squeeze operation\n",
    "        z = self.squeeze(x.permute(0, 1,2))  # Change to [batch_size, hidden_size, num_columns] for pooling\n",
    "        # z shape: [batch_size, hidden_size, 1]\n",
    "        print(z.shape)\n",
    "        # Excitation operation\n",
    "        z = z.view(z.size(0), -1)  # Flatten [batch_size, hidden_size]\n",
    "        print(z.shape)\n",
    "        s = self.excitation(z)  # [batch_size, num_columns]\n",
    "        print(s.shape)\n",
    "        s = s.view(s.size(0), s.size(1), 1)  # Reshape to [batch_size, num_columns, 1] to match original dimensions\n",
    "        \n",
    "        return x * s  # Apply recalibration weights to the original input\n",
    "\n",
    "# Example usage\n",
    "se_block = SqueezeExcitation(SEQ_LEN, HIDDEN_DIM)\n",
    "\n",
    "# Example input\n",
    "output_tensor = se_block(model.embedding(x))\n",
    "print(output_tensor.shape)  # Should be [5, 10, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0140, 1.0544, 0.5745, 1.1459, 1.0752, 1.0970, 1.2246, 1.0905, 1.1810,\n",
       "         0.9075, 1.1066, 1.1111, 1.1480, 1.1564, 1.1017, 0.9926, 1.2691, 1.0983,\n",
       "         1.1192, 1.1829, 1.0128, 1.0408, 1.0886, 1.1149, 1.1851, 1.1490, 1.2068,\n",
       "         1.0217, 1.2480, 1.1243, 1.0000, 1.2659, 1.3011, 0.9569, 1.0429, 0.9876,\n",
       "         1.0209, 1.1997, 1.1960, 1.1143, 1.1687, 1.1109, 1.0508, 1.0933, 1.0979,\n",
       "         1.0760, 1.0780, 1.0757, 1.0974, 1.0552, 1.1843, 1.2101, 1.2528, 0.9350,\n",
       "         1.0819, 1.0984, 1.1817, 1.1034, 0.9914, 1.0035, 1.0155, 1.2748, 1.1062,\n",
       "         1.0720],\n",
       "        [1.0825, 0.9838, 1.0101, 1.0756, 1.1222, 1.0585, 1.1174, 1.0644, 1.2160,\n",
       "         0.9252, 1.1620, 1.0311, 1.0257, 0.9350, 1.0261, 1.0525, 1.1357, 0.9460,\n",
       "         1.0744, 1.0142, 1.0255, 1.0425, 1.0415, 1.1484, 0.9303, 1.1661, 1.1607,\n",
       "         1.0992, 1.0364, 1.2988, 1.0403, 1.0203, 1.1082, 1.1639, 1.1419, 0.6739,\n",
       "         1.1018, 0.8879, 1.0156, 1.0770, 1.0094, 1.0933, 0.9685, 0.7231, 0.9469,\n",
       "         0.9810, 1.1650, 1.0156, 1.1488, 1.0952, 1.1496, 1.0634, 1.0947, 1.1574,\n",
       "         0.9613, 1.1667, 1.0232, 0.8817, 0.8768, 1.1880, 1.3240, 1.0308, 1.1354,\n",
       "         1.0993]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is going to set all input MASK to None\n",
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "# input_size -> the size of the embedding of the autoencoder model\n",
    "# hidden_size -> the size of the RNN to use in the decoder (the input_size and hidden_size can be different)\n",
    "model = GRUDecoder(input_size=6, hidden_size=10, max_seq_len=4).to(get_device())\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "solver = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n",
      "Using MPS (Metal Performance Shaders) device\n",
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "# This is just an example\n",
    "\n",
    "MAX_SEQ_LEN = 4 # max number of surveyas a person (in our dataset can have)\n",
    "INPUT_SIZE = 6 # hidden dimmensions of autoencodder.\n",
    "\n",
    "# let's say we have a person who only have 3 surveys\n",
    "x0 = torch.rand(INPUT_SIZE) # embedding for the 1st survey \n",
    "x1 = torch.rand(INPUT_SIZE) # embedding for the 2nd survey\n",
    "x2 = torch.rand(INPUT_SIZE)\n",
    "x3 = torch.rand(INPUT_SIZE)\n",
    "# the tensor for the person should be on the shape [MAX_SEQ_LEN, INPUT_SIZE]\n",
    "\n",
    "e = torch.zeros(MAX_SEQ_LEN, INPUT_SIZE)\n",
    "e[0] = x0\n",
    "e[1] = x1\n",
    "e[2] = x2\n",
    "e = e.to(get_device()) # so this is a tensor for the person\n",
    "#we also need to specify that the sequence has 'empty' embeddings\n",
    "#mask = torch.BoolTensor([True, True, False, False]).to(get_device()) # the last two dimensions are empty\n",
    "## it is important that you append existing survey embeddings right next to each other (even if the year is missign between them, they should be still appended one after another)\n",
    "\n",
    "## let assume we have a batch of people, I am reusing the same person, but in the pipeline is should be different people\n",
    "# the batch size is 3 here \n",
    "\n",
    "x = torch.stack([e,e,e])\n",
    "y = torch.tensor([1.,1,1.]).to(get_device())\n",
    "#mask = torch.stack([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    solver.zero_grad()\n",
    "    #xx = torch.nn.functional.sigmoid(model(x, mask))\n",
    "    xx = model(x, None)\n",
    "\n",
    "    loss = loss_f(xx.view(-1), y.view(-1))\n",
    "    loss.backward()\n",
    "    solver.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2001, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
