{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import AutoEncoder\n",
    "import torch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "### Initialization of the Autoencoder \n",
    "SEQ_LEN = 3000\n",
    "HIDDEN_DIM = 512\n",
    "ENCODING_SIZE = 64\n",
    "model = AutoEncoder(vocab_size=100, embedding_size=HIDDEN_DIM, encoding_size=ENCODING_SIZE, sequence_len=SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assume we have a batch of 2 people\n",
    "x = torch.randint(1,99, size=(2,SEQ_LEN))\n",
    "y = model(x) \n",
    "## returns the original shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only to use the encoder part \n",
    "y = model.encode(x) # here y contains embedding of a survey per row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze - Excite Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3000, 1])\n",
      "torch.Size([2, 3000])\n",
      "torch.Size([2, 3000])\n",
      "torch.Size([2, 3000, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, num_columns, hidden_size, reduction_ratio=16):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        # Assuming the reduction happens across the hidden_size\n",
    "        self.num_columns = num_columns\n",
    "        self.reduced_size = max(1, hidden_size // reduction_ratio)\n",
    "        \n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)  # Squeezes hidden_size to 1\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(num_columns, self.reduced_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.reduced_size, num_columns),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_columns, hidden_size]\n",
    "        # Squeeze operation\n",
    "        z = self.squeeze(x.permute(0, 1,2))  # Change to [batch_size, hidden_size, num_columns] for pooling\n",
    "        # z shape: [batch_size, hidden_size, 1]\n",
    "        print(z.shape)\n",
    "        # Excitation operation\n",
    "        z = z.view(z.size(0), -1)  # Flatten [batch_size, hidden_size]\n",
    "        print(z.shape)\n",
    "        s = self.excitation(z)  # [batch_size, num_columns]\n",
    "        print(s.shape)\n",
    "        s = s.view(s.size(0), s.size(1), 1)  # Reshape to [batch_size, num_columns, 1] to match original dimensions\n",
    "        \n",
    "        return x * s  # Apply recalibration weights to the original input\n",
    "\n",
    "# Example usage\n",
    "se_block = SqueezeExcitation(SEQ_LEN, HIDDEN_DIM)\n",
    "\n",
    "# Example input\n",
    "output_tensor = se_block(model.embedding(x))\n",
    "print(output_tensor.shape)  # Should be [5, 10, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0531, 1.0730, 1.2044, 1.0634, 1.0802, 1.0725, 1.0801, 1.0112, 1.0577,\n",
       "         1.1093, 1.1426, 0.8842, 1.0742, 1.2163, 1.2270, 1.1978, 1.1072, 0.9584,\n",
       "         1.1679, 1.1188, 1.1647, 1.1729, 1.2542, 1.1120, 0.9967, 1.0776, 1.0980,\n",
       "         1.1687, 1.1266, 0.9934, 0.9679, 1.1616, 1.0662, 0.9413, 1.0701, 1.0496,\n",
       "         1.0380, 1.1257, 0.9062, 1.0719, 1.1047, 0.9403, 1.2135, 1.0926, 1.1796,\n",
       "         1.0396, 0.9750, 1.1150, 0.8920, 1.0043, 1.0607, 1.0112, 0.9216, 1.0439,\n",
       "         1.0199, 1.0194, 1.0808, 1.2047, 1.1377, 1.0877, 1.1994, 1.2468, 1.1343,\n",
       "         1.1176],\n",
       "        [1.3957, 1.2013, 1.2500, 1.0567, 1.0101, 1.1571, 1.0866, 1.0422, 1.1510,\n",
       "         1.0925, 1.1267, 1.1172, 1.0557, 1.0159, 1.1122, 1.1162, 1.1513, 1.0397,\n",
       "         0.8504, 0.9791, 1.0505, 1.0290, 0.9558, 1.1525, 1.0346, 1.0656, 1.0625,\n",
       "         1.1594, 1.1062, 1.0022, 1.0685, 1.1871, 1.0504, 1.0977, 0.9951, 1.0144,\n",
       "         0.9501, 1.1131, 1.0390, 1.1674, 1.1038, 1.0137, 1.1603, 1.0050, 1.1031,\n",
       "         1.0132, 1.0106, 1.0271, 0.8613, 1.0402, 1.0108, 1.0281, 0.8692, 0.9845,\n",
       "         1.1092, 0.9058, 1.0941, 1.1311, 1.0967, 0.9887, 1.1182, 1.0259, 1.0578,\n",
       "         1.0013]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "# input_size -> the size of the embedding of the autoencoder model\n",
    "# hidden_size -> the size of the RNN to use in the decoder (the input_size and hidden_size can be different)\n",
    "model = GRUDecoder(input_size=6, hidden_size=10, max_seq_len=4).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n",
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "# This is just an example\n",
    "\n",
    "MAX_SEQ_LEN = 4 # max number of surveyas a person (in our dataset can have)\n",
    "INPUT_SIZE = 6 # hidden dimmensions of autoencodder.\n",
    "\n",
    "# let's say we have a person who only have 2 surveys\n",
    "x0 = torch.rand(INPUT_SIZE) # embedding for the 1st survey \n",
    "x1 = torch.rand(INPUT_SIZE) # embedding for the 2nd survey\n",
    "\n",
    "# the tensor for the person should be on the shape [MAX_SEQ_LEN, INPUT_SIZE]\n",
    "\n",
    "e = torch.zeros(MAX_SEQ_LEN, INPUT_SIZE)\n",
    "e[0] = x0\n",
    "e[1] = x1\n",
    "e = e.to(get_device()) # so this is a tensor for the person\n",
    "#we also need to specify that the sequence has 'empty' embeddings\n",
    "mask = torch.BoolTensor([True, True, False, False]).to(get_device()) # the last two dimensions are empty\n",
    "## it is important that you append existing survey embeddings right next to each other (even if the year is missign between them, they should be still appended one after another)\n",
    "\n",
    "## let assume we have a batch of people, I am reusing the same person, but in the pipeline is should be different people\n",
    "# the batch size is 3 here \n",
    "\n",
    "x = torch.stack([e,e,e])\n",
    "mask = torch.stack([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = model(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6218],\n",
       "        [0.4513],\n",
       "        [0.4098]], device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.sigmoid(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
