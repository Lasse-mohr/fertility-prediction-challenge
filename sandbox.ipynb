{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rnn import GRUDecoder\n",
    "import torch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "model = GRUDecoder(input_size=12, hidden_size=10).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,10,12).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2743],\n",
       "        [-0.2173],\n",
       "        [-0.2639],\n",
       "        [-0.2543]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, _ = model.gru(x)\n",
    "xx = model.post_gru(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0596, -0.0882,  0.0289, -0.2966, -0.1535,  0.0709,  0.1236,  0.0680,\n",
       "          0.2359,  0.1787],\n",
       "        [-0.1526, -0.0519,  0.0643, -0.2133, -0.1781,  0.0261,  0.1416, -0.2112,\n",
       "          0.1317,  0.1871],\n",
       "        [-0.0015, -0.1295, -0.1343, -0.1155, -0.0357, -0.1870,  0.2212, -0.1039,\n",
       "          0.2096,  0.1106],\n",
       "        [-0.1767,  0.1607,  0.1776, -0.0506, -0.0305, -0.0209, -0.0028, -0.0815,\n",
       "          0.0192,  0.2910]], device='mps:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.softmax(torch.einsum(\"bij, j -> bi\", xx, model.attention.context), dim=1)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0596, -0.0882,  0.0289, -0.2966, -0.1535,  0.0709,  0.1236,  0.0680,\n",
       "          0.2359,  0.1787],\n",
       "        [-0.1526, -0.0519,  0.0643, -0.2133, -0.1781,  0.0261,  0.1416, -0.2112,\n",
       "          0.1317,  0.1871],\n",
       "        [-0.0015, -0.1295, -0.1343, -0.1155, -0.0357, -0.1870,  0.2212, -0.1039,\n",
       "          0.2096,  0.1106],\n",
       "        [-0.1767,  0.1607,  0.1776, -0.0506, -0.0305, -0.0209, -0.0028, -0.0815,\n",
       "          0.0192,  0.2910]], device='mps:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"bij, bi -> bj\", xx, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
