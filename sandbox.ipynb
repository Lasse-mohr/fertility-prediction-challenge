{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import AutoEncoder\n",
    "import torch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization of the Autoencoder \n",
    "SEQ_LEN = 3000\n",
    "HIDDEN_DIM = 512\n",
    "ENCODING_SIZE = 64\n",
    "model = AutoEncoder(vocab_size=100, embedding_size=HIDDEN_DIM, encoding_size=ENCODING_SIZE, sequence_len=SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 13,  7,  ..., 88, 94, 60],\n",
       "        [63, 68, 82,  ..., 25, 66, 91]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assume we have a batch of 2 people\n",
    "x = torch.randint(1,99, size=(2,SEQ_LEN))\n",
    "y = model(x) \n",
    "## returns the original shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only to use the encoder part \n",
    "y = model.encode(x) # here y contains embedding of a survey per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0181, 1.2055, 1.1069, 1.0573, 1.2489, 1.1327, 1.1476, 0.9988, 1.1303,\n",
       "         1.1413, 1.2062, 1.1750, 1.1332, 1.1358, 1.2791, 1.2234, 0.9566, 1.2678,\n",
       "         1.0647, 1.0055, 1.0363, 1.1205, 0.9869, 1.1123, 1.0870, 1.1040, 0.9812,\n",
       "         1.0783, 1.0984, 1.1495, 1.0597, 1.0109, 1.0734, 1.0487, 1.2017, 0.9716,\n",
       "         1.0674, 1.0515, 1.1291, 1.1136, 1.1051, 1.0814, 1.1689, 1.1321, 1.1260,\n",
       "         1.0802, 1.1869, 1.0064, 1.0912, 1.1110, 1.2514, 1.1012, 1.0839, 1.1723,\n",
       "         1.1688, 1.1562, 1.1463, 1.1324, 1.1117, 1.2091, 1.0689, 0.9981, 1.1680,\n",
       "         1.2049],\n",
       "        [0.9981, 1.1551, 0.9326, 1.1216, 1.1961, 1.0981, 1.0040, 1.0683, 1.1093,\n",
       "         0.9739, 1.0427, 0.9508, 1.1087, 1.0366, 1.0619, 1.1540, 1.1945, 1.0816,\n",
       "         1.2376, 1.0524, 1.2920, 1.0100, 1.0800, 1.0678, 1.0836, 1.0298, 1.0424,\n",
       "         1.1119, 1.1505, 1.0366, 1.1331, 0.9942, 1.0213, 1.1918, 1.0771, 1.0476,\n",
       "         1.1519, 1.0659, 1.0433, 1.0261, 1.0559, 1.0329, 1.1963, 1.0541, 0.9515,\n",
       "         0.9779, 1.2215, 0.8934, 1.2123, 1.2393, 1.1611, 1.0241, 1.0159, 0.9952,\n",
       "         1.0205, 1.1552, 1.0684, 1.0392, 1.0587, 1.1094, 1.0082, 1.0312, 0.9494,\n",
       "         1.0746]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "# input_size -> the size of the embedding of the autoencoder model\n",
    "# hidden_size -> the size of the RNN to use in the decoder (the input_size and hidden_size can be different)\n",
    "model = GRUDecoder(input_size=6, hidden_size=10, max_seq_len=4).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n",
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "# This is just an example\n",
    "\n",
    "MAX_SEQ_LEN = 4 # max number of surveyas a person (in our dataset can have)\n",
    "INPUT_SIZE = 6 # hidden dimmensions of autoencodder.\n",
    "\n",
    "# let's say we have a person who only have 2 surveys\n",
    "x0 = torch.rand(INPUT_SIZE) # embedding for the 1st survey \n",
    "x1 = torch.rand(INPUT_SIZE) # embedding for the 2nd survey\n",
    "\n",
    "# the tensor for the person should be on the shape [MAX_SEQ_LEN, INPUT_SIZE]\n",
    "\n",
    "e = torch.zeros(MAX_SEQ_LEN, INPUT_SIZE)\n",
    "e[0] = x0\n",
    "e[1] = x1\n",
    "e = e.to(get_device()) # so this is a tensor for the person\n",
    "#we also need to specify that the sequence has 'empty' embeddings\n",
    "mask = torch.BoolTensor([True, True, False, False]).to(get_device()) # the last two dimensions are empty\n",
    "## it is important that you append existing survey embeddings right next to each other (even if the year is missign between them, they should be still appended one after another)\n",
    "\n",
    "## let assume we have a batch of people, I am reusing the same person, but in the pipeline is should be different people\n",
    "# the batch size is 3 here \n",
    "\n",
    "x = torch.stack([e,e,e])\n",
    "mask = torch.stack([mask, mask, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmmi/fertility-prediction-challenge/model/rnn.py:89: UserWarning: MPS: no support for int64 for sort_stable_out, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Sort.mm:30.)\n",
      "  lengths, sorted_idx = lengths.sort(0, descending=True)\n",
      "/Users/lmmi/fertility-prediction-challenge/model/rnn.py:89: UserWarning: torch.sort is supported by MPS on MacOS 13+, please upgrade. Falling back to CPU (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Sort.mm:45.)\n",
      "  lengths, sorted_idx = lengths.sort(0, descending=True)\n"
     ]
    }
   ],
   "source": [
    "xx = model(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/_tensor_str.py:137: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:283.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5298],\n",
       "        [0.5026],\n",
       "        [0.4558]], device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.sigmoid(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
