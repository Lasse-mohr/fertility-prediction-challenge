{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563531c8-25db-4856-b11e-c8a99ce5c2ed",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_processing.encoding.categorical import CategoricalTransformer\n",
    "from data_processing.encoding.numeric_and_date import ToQuantileTransformer\n",
    "from data_processing.encoding.text2vec import TextTransform\n",
    "from data_processing.sequences.sequencing import to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c3f871-21e8-418c-9aa7-31ad09283a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmmi/fertility-prediction-challenge/data_processing/encoding/categorical.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  core_cat_df['values_cat'] = core_cat_df['values_cat'].str.split(\"; \").apply(lambda x: [e.strip() for e in x])\n",
      "/Users/lmmi/fertility-prediction-challenge/data_processing/encoding/categorical.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  core_cat_df['labels_cat'] = core_cat_df['labels_cat'].str.split(\"; \").apply(lambda x: [e.strip() for e in x])\n"
     ]
    }
   ],
   "source": [
    "# read in data and prepare transformations\n",
    "data = pd.read_csv('data/other_data/PreFer_fake_data.csv')\n",
    "targets = pd.read_csv('data/other_data/PreFer_fake_outcome.csv')\n",
    "codebook = pd.read_csv('data/codebooks/PreFer_codebook.csv')\n",
    "summary = pd.read_csv('data/codebooks/PreFer_codebook_summary.csv')\n",
    "\n",
    "categorical_columns = codebook[(codebook.var_name.str.startswith('c')) & (codebook.type_var == 'categorical')].var_name.tolist()\n",
    "quantile_columns = codebook[(codebook.var_name.str.startswith('c')) & ((codebook.type_var == 'numeric') | (codebook.type_var == 'date or time'))].var_name.tolist()\n",
    "\n",
    "cat_transform = CategoricalTransformer()\n",
    "cat_transform.fit(codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10fe311-0b4d-4f88-851e-50327041814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/j9fbqcvx6lb5l99614n30y4c0000gn/T/ipykernel_6228/2027597144.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data2['nomem_encr'] = data['nomem_encr']\n",
      "/var/folders/y6/j9fbqcvx6lb5l99614n30y4c0000gn/T/ipykernel_6228/2027597144.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['nomem_encr'] = data['nomem_encr']\n"
     ]
    }
   ],
   "source": [
    "# tokenize and store as sequences\n",
    "for col in categorical_columns:\n",
    "    data[col] = cat_transform.transform(data[col])\n",
    "    \n",
    "quantile_transform = ToQuantileTransformer(quantile_columns)\n",
    "quantile_transform.fit(data)\n",
    "data = quantile_transform.transform(data)\n",
    "\n",
    "data.fillna(101, inplace=True)\n",
    "data[quantile_columns] = data[quantile_columns].astype(int)\n",
    "\n",
    "data2 = data[data.columns[data.columns.str.startswith('c')]]\n",
    "data2['nomem_encr'] = data['nomem_encr']\n",
    "\n",
    "sequences = to_sequences(data2, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = 'cpu' #get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a3693f-ce37-4b9d-a2f0-c259c8811507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['long answer', 'answer', 'answ', 'answ', 'answer', 'answer',\n",
       "       'answer', 'answ', 'long answer', 'answ', 'answer', 'answer',\n",
       "       'answ', 'answer', 'answ', 'answer', 'answ', 'answ', 'answer',\n",
       "       'answer', 'answ', 'answ', 'answer', 'answ', 'answ', 'answer',\n",
       "       'even longer answer', 'answer', 'answer', 'answer', 'answ',\n",
       "       'answer', 'answ', 'answer', 'answer', 'answer', 'long answer',\n",
       "       'answ', 'answer', 'long answer', 'answ', 'answ', 'answ', 'answer',\n",
       "       'even longer answer', 'answ', 'answer', 'answer', 'answer',\n",
       "       'even longer answer', 'answer', 'answer', 'answ', 'answer', 'answ',\n",
       "       'answer', 'answer', 'long answer', 'answer', 'answ',\n",
       "       'even longer answer', 'answer', 'answ', 'answer', 'answer',\n",
       "       'answer', 'long answer', 'answer', 'answ', 'answ', 'answ',\n",
       "       'answer', 'even longer answer', 'answer', 'answer'], dtype='<U32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "index = np.array([isinstance(x, str) for x in sequences[700001]['08']])\n",
    "np.array(sequences[700001]['08'])[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1704f8ed-5b81-49db-b19c-6970db7d04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings in sequences with 101 for nan\n",
    "for _, wave_responses in sequences.items():\n",
    "    for year, wave_response in wave_responses.items():\n",
    "        \n",
    "        not_int = np.array([not isinstance(x, int) for x in wave_response], dtype = bool)\n",
    "        wave_responses[year] = [\n",
    "            item if not _bool else 101 for (item, _bool) in zip(wave_response, not_int)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d585bb-2414-4cec-954c-511d78015560",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_data = torch.tensor([\n",
    "                                wave_response\n",
    "                                for _, wave_responses in sequences.items()\n",
    "                                for _, wave_response in wave_responses.items()\n",
    "                        ]).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc1c1cd5-e88d-4af3-b526-026268bd591e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_people' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m targets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m----> 2\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnomem_encr\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[43mn_people\u001b[49m),\n\u001b[1;32m      3\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(low \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, size \u001b[38;5;241m=\u001b[39m n_people)\n\u001b[1;32m      4\u001b[0m     }\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_people' is not defined"
     ]
    }
   ],
   "source": [
    "targets = pd.DataFrame(\n",
    "    {'nomem_encr':np.arange(n_people),\n",
    "     'target':np.random.randint(low = 0, high = 2, size = n_people)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00723f19-0422-41cd-80fc-1e1dc736e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5cd7a17e-51c8-421e-a025-c1227be34864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Makes the main denoising auto\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_shape [int] : input shape\n",
    "    enc_shape [int] : desired encoded shape\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_shape, enc_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(in_shape, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, enc_shape),\n",
    "        )\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.BatchNorm1d(enc_shape),\n",
    "            nn.Linear(enc_shape, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, in_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740cde0c-38b9-47d2-9e89-bb89e910b9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([420, 3121])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49df20d-5dfb-4237-854a-415987bd45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa220af4-5eb6-47f1-b4e1-5814be3228c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "\n",
    "train_dataloader = DataLoader(autoencoder_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs_autoencoder = 10\n",
    "learning_rate_autoencoder = 0.001\n",
    "embedding_dim = 128\n",
    "\n",
    "n_questions = autoencoder_data.shape[1] \n",
    "\n",
    "error = nn.MSELoss()\n",
    "\n",
    "autoencoder = AutoEncoder(num_embeddings=n_questions * embedding_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam( autoencoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be77146-e5b0-4a06-9d9e-d651c88d32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t Loss: 0.988\n",
      "epoch 0 \t Loss: 0.9875\n",
      "epoch 0 \t Loss: 0.9781\n",
      "epoch 0 \t Loss: 0.9675\n",
      "epoch 1 \t Loss: 0.9597\n",
      "epoch 1 \t Loss: 0.9476\n",
      "epoch 1 \t Loss: 0.8431\n",
      "epoch 1 \t Loss: 0.932\n",
      "epoch 2 \t Loss: 0.9188\n",
      "epoch 2 \t Loss: 0.8882\n",
      "epoch 2 \t Loss: 0.8687\n",
      "epoch 2 \t Loss: 0.8422\n",
      "epoch 3 \t Loss: 0.801\n",
      "epoch 3 \t Loss: 0.5053\n",
      "epoch 3 \t Loss: 0.7267\n",
      "epoch 3 \t Loss: 0.6643\n",
      "epoch 4 \t Loss: 0.6573\n",
      "epoch 4 \t Loss: 0.6777\n",
      "epoch 4 \t Loss: 0.7135\n",
      "epoch 4 \t Loss: 0.661\n",
      "epoch 5 \t Loss: 0.6305\n",
      "epoch 5 \t Loss: 0.5739\n",
      "epoch 5 \t Loss: 0.5615\n",
      "epoch 5 \t Loss: 0.5967\n",
      "epoch 6 \t Loss: 0.1169\n",
      "epoch 6 \t Loss: 0.5343\n",
      "epoch 6 \t Loss: 0.5719\n",
      "epoch 6 \t Loss: 0.5871\n",
      "epoch 7 \t Loss: 0.6107\n",
      "epoch 7 \t Loss: 0.543\n",
      "epoch 7 \t Loss: 0.5394\n",
      "epoch 7 \t Loss: 0.5457\n",
      "epoch 8 \t Loss: 0.5665\n",
      "epoch 8 \t Loss: 0.5623\n",
      "epoch 8 \t Loss: 0.5492\n",
      "epoch 8 \t Loss: 0.5083\n",
      "epoch 9 \t Loss: 0.555\n",
      "epoch 9 \t Loss: 0.5297\n",
      "epoch 9 \t Loss: 0.5317\n",
      "epoch 9 \t Loss: 0.5136\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train()\n",
    "for epoch in range(num_epochs_autoencoder):\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = autoencoder.get_loss(batch[0].to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if epoch % int(0.01*num_epochs_autoencoder) == 0:\n",
    "            print(f'epoch {epoch} \\t Loss: {loss.item():.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28bfe0-cc99-480d-a416-1b1f8f48e08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f72b065e-b686-4232-b091-b8973fa18367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{700001: 1,\n",
       " 700002: 0,\n",
       " 700003: 0,\n",
       " 700004: 0,\n",
       " 700005: 0,\n",
       " 700006: 0,\n",
       " 700007: 0,\n",
       " 700008: 0,\n",
       " 700009: 0,\n",
       " 700010: 1,\n",
       " 700011: 0,\n",
       " 700012: 0,\n",
       " 700013: 0,\n",
       " 700014: 0,\n",
       " 700015: 1,\n",
       " 700016: 0,\n",
       " 700017: 0,\n",
       " 700018: 1,\n",
       " 700019: 0,\n",
       " 700020: 1,\n",
       " 700021: 1,\n",
       " 700022: 0,\n",
       " 700023: 1,\n",
       " 700024: 0,\n",
       " 700025: 0,\n",
       " 700026: 0,\n",
       " 700027: 0,\n",
       " 700028: 0,\n",
       " 700029: 0,\n",
       " 700030: 0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.set_index(keys = 'nomem_encr').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dbcbcdf5-45ca-429d-ae6d-e9a6008b8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesWithTarget(Dataset):\n",
    "    def __init__(self, sequences:dict, target: pd.DataFrame):\n",
    "        self.sequences = sequences \n",
    "        self.target = targets.set_index(keys = 'nomem_encr').squeeze().to_dict()\n",
    "        self.keys = list(sequences.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        person_id = self.keys[index]\n",
    "        \n",
    "        sequence = self.sequences[person_id]\n",
    "        target = self.target[person_id]\n",
    "        return target, sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3eaadc01-1e81-4727-b7f4-f14823463fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=0.2, random_state=42)\n",
    "train_person_ids, val_person_ids = train_test_split(train_person_ids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_data = {person_id: sequences[person_id] for person_id in train_person_ids}\n",
    "val_data = {person_id: sequences[person_id] for person_id in val_person_ids}\n",
    "test_data = {person_id: sequences[person_id] for person_id in test_person_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6d85edc9-8457-439f-8fe9-fbd94eb9b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequencesWithTarget(train_data, target = targets)\n",
    "val_dataset = SequencesWithTarget(val_data, target = targets)\n",
    "test_dataset = SequencesWithTarget(test_data, target = targets)\n",
    "\n",
    "rnn_batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=rnn_batch_size, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset,   batch_size=rnn_batch_size)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=rnn_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f58f129-a2af-4cc9-8cc9-0d187fbbe5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.rnn(x)\n",
    "        \n",
    "        output_flat = output.contiguous().view(-1, output.size(2))\n",
    "        \n",
    "        logits = self.fc(output_flat)\n",
    "        \n",
    "        probabilities = self.sigmoid(logits)\n",
    "        \n",
    "        return probabilities.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96e220b8-17b1-4a26-9c02-b4ac3de853af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "n_layers = 3\n",
    "\n",
    "# Initialize the RNN model\n",
    "rnn_model = CustomRNN(\n",
    "    input_size=n_questions,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=n_layers,\n",
    ")\n",
    "\n",
    "num_epochs_rnn = 10\n",
    "learning_rate_rnn = 0.001\n",
    "\n",
    "# Define loss function and optimizer for RNN\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "82cf1777-49e7-462d-ae51-549ea6c8305e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "RNN: Expected input to be 2D or 3D, got 1D tensor instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the parameter gradients\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels)  \u001b[38;5;66;03m# Assuming outputs are logits\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[125], line 9\u001b[0m, in \u001b[0;36mCustomRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     output_flat \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     13\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output_flat)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/nn/modules/rnn.py:523\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    521\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    524\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    525\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: RNN: Expected input to be 2D or 3D, got 1D tensor instead"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "\n",
    "rnn_model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _ = rnn_model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Assuming outputs are logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# After training, you can evaluate the model on the validation set and test set using similar loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed990c-00f9-4428-b62a-774cae507297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc96e46-1932-49ac-921f-6d2dff2f697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the RNN model\n",
    "for epoch in range(num_epochs_rnn):\n",
    "    # Forward pass\n",
    "    outputs = rnn_model(rnn_input)\n",
    "    loss = criterion(outputs, rnn_targets)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs_rnn}] | Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PreFer data expl)",
   "language": "python",
   "name": "prefer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
