{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model.rnn import GRUDecoder\n",
    "from model.autoencoder import AutoEncoder\n",
    "from data_processing.pipeline import encoding_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b651aa-752a-4c71-990a-332ff4099791",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "Right now the notebook is set to work with fake data. This can be changed once the pipeline works.\n",
    "\n",
    "The data is stored as a Dict[person_id, Sequences] where Sequences is a Dict[year, survery_wave_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c3f871-21e8-418c-9aa7-31ad09283a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and prepare transformations\n",
    "data = pd.read_csv('data/other_data/PreFer_fake_data.csv')\n",
    "targets = pd.read_csv('data/other_data/PreFer_fake_outcome.csv')\n",
    "codebook = pd.read_csv('data/codebooks/PreFer_codebook.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d165d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = encoding_pipeline(data, codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddb66e-cba5-4bb9-854d-811d49599b93",
   "metadata": {},
   "source": [
    "# Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9275bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import PretrainingDataset\n",
    "\n",
    "pretrain_dataset = PretrainingDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8544475-54af-4874-9e83-7f39193eb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "### Initialization of the Autoencoder \n",
    "HIDDEN_DIM = 512\n",
    "ENCODING_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "num_epochs_autoencoder = 10\n",
    "learning_rate_autoencoder = 0.001\n",
    "\n",
    "SEQ_LEN = pretrain_dataset.get_seq_len()\n",
    "vocab_size = pretrain_dataset.get_vocab_size()\n",
    "\n",
    "train_dataloader = DataLoader(pretrain_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "autoencoder = AutoEncoder(vocab_size=vocab_size, embedding_size=HIDDEN_DIM, encoding_size=ENCODING_SIZE, sequence_len=SEQ_LEN).to(device)\n",
    "\n",
    "error = nn.MSELoss()\n",
    "optimizer = optim.Adam( autoencoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be77146-e5b0-4a06-9d9e-d651c88d32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t Loss: 2.576\n",
      "epoch 1 \t Loss: 2.435\n",
      "epoch 2 \t Loss: 2.312\n",
      "epoch 3 \t Loss: 2.229\n",
      "epoch 4 \t Loss: 2.139\n",
      "epoch 5 \t Loss: 2.053\n",
      "epoch 6 \t Loss: 1.875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m seq \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m xx \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(xx, autoencoder\u001b[38;5;241m.\u001b[39membedding(year, seq))\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/fertility-prediction-challenge/model/autoencoder.py:63\u001b[0m, in \u001b[0;36mAutoEncoder.forward\u001b[0;34m(self, year, seq)\u001b[0m\n\u001b[1;32m     60\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Decoding\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Reshape to match the expected input for ConvTranspose1d\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Switch dimensions back to [batch_size, seq_len, embedding_size]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/fertility-prediction-challenge/model/layers.py:64\u001b[0m, in \u001b[0;36mConvDecoderLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:801\u001b[0m, in \u001b[0;36mConvTranspose1d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    797\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    798\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    800\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.train()\n",
    "device = torch.device(\"cpu\") # mps is not working for Me (Mikkel)\n",
    "autoencoder.to(device)\n",
    "for epoch in range(num_epochs_autoencoder):\n",
    "    for year, seq in train_dataloader:\n",
    "        year = year.to(device)\n",
    "        seq = seq.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        xx = autoencoder(year, seq)\n",
    "        loss = nn.functional.mse_loss(xx, autoencoder.embedding(year, seq))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    print(f'epoch {epoch} \\t Loss: {loss.item():.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8018b-7ebc-4db4-aadf-191b214b1470",
   "metadata": {},
   "source": [
    "# Train the RNN\n",
    "\n",
    "First we need to create Dataset class that can hold both the target (stored in a pd.DataFrame) and the sequences.\n",
    "\n",
    "The sequences will be of dimension 14 x encoding_dimension, because we have 14 years of surveys.\n",
    "\n",
    "I have created some code for getting the data into the right format, but it might not be useful.\n",
    "\n",
    "## Regarding masks\n",
    "Right now the masking is done already in the encoding. I haven't found exactly where Mikkel implemented this.\n",
    "So for now, assume that nothing is padded, and then we'll figure it out with Mikkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9af9fd88-99ca-49cc-a078-7706dafd4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesWithTarget(Dataset):\n",
    "    def __init__(self, sequences:dict, target: pd.DataFrame):\n",
    "        self.sequences = sequences \n",
    "        self.target = targets.set_index(keys = 'nomem_encr').squeeze().to_dict()\n",
    "        self.keys = list(sequences.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        person_id = self.keys[index]\n",
    "        \n",
    "        target = self.target[person_id]\n",
    "        sequence = self.sequences[person_id]\n",
    "\n",
    "        return target, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af1786da-d2b5-4e1f-81f6-1db7bca5515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its not everyone we have a target for, so we do restrict the data to \n",
    "# the ones with known outcomes\n",
    "\n",
    "train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b25c3ca7-2806-4d23-a21b-80f548720eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.BoolTensor([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "317ed83d-0d05-4404-92cb-16889c744519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the data as a Dict[person_id, survey_embedding_sequence] \n",
    "# where survey_embedding_sequence is a tensor of size 14 x embedding_dimension\n",
    "rnn_data = {person_id:\n",
    "                autoencoder.encode(\n",
    "                    torch.tensor(\n",
    "                        [ wave_response for _, wave_response in wave_responses.items()]\n",
    "                    ).to(device)\n",
    "                )\n",
    "            for person_id, wave_responses in sequences.items()\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eaadc01-1e81-4727-b7f4-f14823463fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the splits made for the target\n",
    "train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d85edc9-8457-439f-8fe9-fbd94eb9b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequencesWithTarget(train_data, target = targets)\n",
    "test_dataset = SequencesWithTarget(test_data, target = targets)\n",
    "\n",
    "rnn_batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=rnn_batch_size, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=rnn_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82cf1777-49e7-462d-ae51-549ea6c8305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m rnn_loss(torch\u001b[38;5;241m.\u001b[39mflatten(outputs), labels)  \n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#loss.backward(retain_graph=True)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m rnn_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "\n",
    "num_epochs_rnn = 2\n",
    "learning_rate_rnn = 0.001\n",
    "\n",
    "rnn_model = GRUDecoder(\n",
    "    input_size=ENCODING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    max_seq_len=14\n",
    ").to(device)\n",
    "\n",
    "# assume that all 14 years are observed for everyone\n",
    "single_mask = torch.BoolTensor([True]*14).to(device) \n",
    "\n",
    "# Define loss function and optimizer for RNN\n",
    "rnn_loss = torch.nn.BCELoss()\n",
    "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate_rnn)\n",
    "# Training loop\n",
    "\n",
    "rnn_model.train()\n",
    "for epoch in range(num_epochs_rnn):\n",
    "    print(epoch)\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        labels, inputs = batch\n",
    "        labels, inputs = labels.to(torch.float).to(device), inputs.to(device)\n",
    "\n",
    "        rnn_optimizer.zero_grad() \n",
    "\n",
    "        # Forward pass\n",
    "        mask = torch.stack([single_mask]*len(labels) ) #  not correct masking\n",
    "\n",
    "        xx = rnn_model(inputs, mask)\n",
    "        outputs = torch.nn.functional.sigmoid(xx)\n",
    "\n",
    "        loss = rnn_loss(torch.flatten(outputs), labels)  \n",
    "\n",
    "        #loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        rnn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_rnn}, Loss: {epoch_loss:.4f}\")j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7189352-db53-419f-a6e2-60c517ba587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, dataloader, single_mask):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            labels, inputs = batch\n",
    "            labels, inputs = labels.to(torch.float).to(device), inputs.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            mask = torch.stack([single_mask]*len(labels))\n",
    "            outputs = model(inputs, mask)\n",
    "            outputs = torch.nn.functional.sigmoid(outputs)\n",
    "            \n",
    "            # Convert outputs to binary predictions\n",
    "            predicted_labels = (outputs > 0.5).float()  # Threshold predictions\n",
    "            print(labels)\n",
    "            print(predicted_labels.flatten())\n",
    "            print('')\n",
    "            \n",
    "            # Store predictions and actual labels\n",
    "            predictions.append(predicted_labels.flatten())\n",
    "            actuals.append(labels.flatten())\n",
    "    \n",
    "    # Concatenate all the batches\n",
    "    predictions = torch.cat(predictions)\n",
    "    actuals = torch.cat(actuals)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(actuals.cpu().numpy(), predictions.cpu().numpy(), average='binary')\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ac372ff-89b4-49e4-b634-be5d6d8c356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 1.], device='mps:0')\n",
      "tensor([0., 0., 0., 0., 0., 0.], device='mps:0')\n",
      "\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PreFer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate_model(rnn_model, test_dataloader, single_mask)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18cbb7-5f65-4aa6-a30a-f28fb3afc4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
