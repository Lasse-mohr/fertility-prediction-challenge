{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model.rnn import GRUDecoder, SimpleDecoder\n",
    "from model.autoencoder import AutoEncoder, SimpleAutoEncoder\n",
    "from data_processing.pipeline import encoding_pipeline, get_generic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # If CUDA is available, select the first CUDA device\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    # Check for MPS availability on supported macOS devices (requires PyTorch 1.12 or newer)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # If MPS is available, use MPS device\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    else:\n",
    "        # Fallback to CPU if neither CUDA nor MPS is available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b651aa-752a-4c71-990a-332ff4099791",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "Right now the notebook is set to work with fake data. This can be changed once the pipeline works.\n",
    "\n",
    "The data is stored as a Dict[person_id, Sequences] where Sequences is a Dict[year, survery_wave_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c3f871-21e8-418c-9aa7-31ad09283a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_8125/1529815470.py:2: DtypeWarning: Columns (2583,2584,2585,2586,2587,2588,2589,4358,4359,4360,4361,4362,4363,4364,4365,4366,4367,4368,4369,4370,4371,4372,4373,4374,4375,4379,4380,4381,4382,4383,4384,4385,4386,4387,4388,4389,4390,4391,4392,4393,4394,4395,4396,4397,4398,4399,4400,4401,4405,4406,4407,4408,4409,5215,5216,5219,5220,5613,5614,5615,5616,5617,5618,5619,5620,5621,5622,5624,5625,5626,5627,5628,5629,5630,5631,5632,5633,5634,5635,5636,5638,5639,5640,5787,5788,5789,5790,5791,5792,5793,5794,5795,5796,6393,6394,6395,6396,6397,6398,6399,6400,6401,6402,6403,6619,6620,6621,6622,6623,6624,6625,6626,6627,6628,6629,6630,6631,6632,6633,6634,6635,6638,6640,6641,6642,6643,6644,6645,6646,6647,6648,6649,6650,6651,6652,6653,6654,6655,6656,6657,6658,6659,6660,6661,6664,6666,6667,6668,6669,6670,6965,6966,6967,6968,6969,6970,6971,6972,6973,6974,6975,7064,7065,7066,7067,7068,7069,7070,7071,7072,7073,7074,7163,7164,7165,7166,7167,7168,7169,7170,7171,7172,7408,7409,7410,7411,7412,7413,7414,7415,7416,7417,7418,7419,7420,8818,8819,8820,8821,8822,8823,8824,8825,8826,8827,8828,9989,9990,9991,9992,9993,9994,9995,9996,9997,9998,9999,10065,10066,10067,10068,10069,10070,10071,10072,10073,10074,10075,10076,10077,10078,10079,10080,10081,10082,10083,10085,10086,10087,10088,10089,10090,10091,10092,10093,10094,10095,10096,10097,10098,10099,10100,10101,10102,10103,10104,10105,10106,10107,10108,10109,10111,10112,10113,10114,10115,10116,10340,10341,10342,10343,10344,10736,10737,10738,10739,10740,10741,10742,10743,10744,10745,10746,10747,10748,11896,11897,11898,11899,11900,11901,11902,11903,11904,11905,11906,11907,12168,12169,12170,12171,12172,12173,12174,12175,12176,12177,12178,12179,12180,12181,12182,12183,12184,12185,12186,12187,12188,12189,12190,12191,12192,12193,13339,13340,13341,13342,13343,13344,13345,13346,13347,13348,13349,13488,13489,13490,13491,13492,13493,13494,13495,13496,13497,13498,13499,13500,13501,13502,13506,13507,13510,13511,13512,13513,13514,13515,13516,13517,13518,13519,13520,13521,13522,13523,13524,13525,13526,13530,13531,13534,13535,15787,15788,15789,15790,15791,15792,15793,15794,15795,15796,15797,15798,15799,15800,15801,15802,15805,15808,15809,15810,15811,15812,15813,15814,15815,15816,15817,15818,15819,15820,15821,15822,15823,15824,15825,15826,15829,15832,15833,15834,15951,15952,16600,16601,16602,16606,16607,16608,16612,16613,16754,16755,16756,16757,16758,16759,16760,16761,16762,16763,16764,16765,16848,17490,17491,17492,17493,17494,17495,17496,17497,17498,17499,17500,17501,17505,17506,17507,17508,17509,17510,17511,17512,17513,17514,17515,17516,17517,17521,17548,17549,17550,17551,17552,17553,17554,17555,17556,17559,17560,17563,17564,17605,17608,17628,17630,17644,17645,17646,17647,17648,17649,17650,17654,17655,17656,17657,17658,17659,17660,17797,17798,17799,17800,17801,17802,17807,17808,17809,17810,17811,17812,17813,17820,17821,17824,17914,17915,17916,17917,17980,17981,17982,17983,17984,17985,17986,17987,17988,17989,17990,17991,17992,17993,17994,17995,17996,17997,17998,17999,18000,18001,18002,18003,18004,18005,18006,18007,18008,18009,18010,18011,18012,18013,18014,18015,18055,18056,18057,18058,18059,18060,18061,18062,18063,18064,18065,18066,18067,18068,18069,18070,18071,18072,18073,18074,18075,18076,18077,18078,18079,18080,18081,18082,18083,18084,18085,18086,18087,18088,18089,18090,18091,18092,18093,18094,18095,18096,18097,18098,18099,18100,18101,18102,18103,18104,18105,18106,18107,18108,18109,18110,18111,18112,18197,18198,18199,18200,18201,18202,18204,18205,18206,18207,18208,18209,18210,18211,18212,18213,18215,18216,18217,18218,18219,18220,18221,18222,18223,18224,18225,18226,18227,18228,18229,18239,18241,18242,18243,18244,18245,18246,18247,18248,18249,18250,18251,18311,18317,18318,18319,18320,18322,18324,18329,18330,18331,18332,18333,18334,18335,18336,18337,18338,18339,18340,18341,18345,18347,18349,18351,18352,18353,18354,18355,18356,18357,18358,18359,18360,18361,18407,18409,18414,18416,18428,18429,18430,18431,18432,18433,18434,18435,18436,18437,18438,18441,18450,18451,18452,18453,18454,18455,18456,18457,18458,18459,18460,18744,18745,18746,18747,18748,18749,18750,18751,18752,18753,18754,18755,18756,18783,18784,18785,18786,18787,18788,18789,18790,18791,18792,18793,18794,18795,19062,19063,19064,19065,19066,19067,19068,19069,19070,19071,19072,19073,19074,19075,19076,19077,19078,19082,19083,19084,19085,19086,19087,19088,19089,19090,19091,19092,19093,19094,19095,19096,19097,19098,19099,19100,19101,19102,19103,19104,19108,19109,19110,19111,19112,19113,19141,19142,19143,19144,19145,19146,19147,19148,19149,19150,19160,19161,19162,19163,19164,19165,19166,19167,19168,19169,19170,19189,19190,19227,19228,20075,20076,20077,20078,20079,20080,20081,20082,20083,20084,20085,20086,20087,20165,20166,20167,20168,20169,20170,20171,20172,20173,20174,20175,20176,20177,20241,20242,20243,20244,20245,20246,20247,20248,20249,20250,20251,20252,20757,20758,20759,20760,20761,20762,20763,20764,20765,20766,20767,20768,20769,23130,23131,23132,23133,23134,23135,23136,23137,23138,23139,23140,23141,23142,23272,23273,23274,23275,23276,23277,23278,23279,23280,23281,23282,23283,23284,23414,23415,23416,23417,23418,23419,23420,23421,23422,23423,23424,23425,23426,23556,23557,23558,23559,23560,23561,23562,23563,23564,23565,23566,23567,23568,23698,23699,23700,23701,23702,23703,23704,23705,23706,23707,23708,23709,23710,23814,23815,23816,23817,23818,23819,23820,23821,23822,23823,23824,23825,23826,23827,23828,23829,23830,23835,23836,23837,23838,23839,23840,23841,23842,23843,23844,23845,23846,23847,23848,23849,23850,23851,23852,23853,23854,23855,23856,23861,23862,23863,23864,23865,24683,24684,24685,24686,24687,24688,24746,24747,24748,24749,24750,24751,24752,24974,24975,24976,24977,24978,24979,24980,24981,24982,24983,24984,24985,24986,24995,25003,25153,25154,25155,25156,25157,25158,25159,25160,25161,25162,25163,25190,25191,25192,25193,25194,25195,25196,25197,25198,25199,25200,25434,25435,25436,25437,25438,25439,25440,25441,25442,25443,25444,25445,25446,25530,25531,25532,25533,25534,25535,25536,25537,25538,25539,25540,25575,25576,25577,25578,25579,25580,25581,25582,25583,25584,25585,25658,25659,25660,25661,25662,25663,25664,25665,25666,25667,25668,25693,25694,25695,25696,25697,25698,25699,25700,25701,25702,25703,25728,25729,25730,25731,25732,25733,25734,25735,25736,25737,25738,25772,25773,25774,25775,25776,25777,25778,25779,25780,25781,25782,25849,25850,25851,25852,25853,25854,25855,25856,25857,25858,25859,25882,25883,25884,25886,25887,25888,25889,25890,25891,25892,25915,25916,25917,25918,25919,25920,25921,25922,25923,25924,25925,25959,25960,25961,25962,25963,25964,25965,25966,25967,25968,25969,26036,26037,26038,26039,26040,26041,26042,26044,26045,26046,26069,26070,26071,26072,26074,26075,26076,26077,26078,26079,26413,26414,26415,26416,26417,26418,26419,26420,26421,26422,26423,26424,26425,26865,26866,26867,26868,26869,26870,26871,26872,26873,26874,26875,26876,26877,26914,26915,26916,26917,26918,26919,26920,26921,26922,26923,26924,26925,26926,26963,26964,26965,26966,26967,26968,26969,26970,26971,26972,26973,26974,26975,27012,27015,27017,27018,27019,27020,27022,27023,27024,27061,27066,27068,27069,27070,27071,27073,27115,27118,27119,27120,27122,27164,27167,27168,27169,27171,27213,27216,27217,27218,27265,27266,27314,27810,27811,27812,27813,27814,27815,27816,27817,27818,27819,27820,27821,27822,27823,27824,27825,27826,27827,27828,27829,27830,27831,27832,27833,27834,27835,27839,27842,27844,27845,27846,27847,27848,27859,27861,27872,30979,30980,30981,30982,30983,30984,30985,30986,30987,30988,30989,30990,30991,30992,30993,30994,30995,30996,30999,31000,31001,31002,31003,31004,31005,31006,31007,31008,31009,31010,31011,31012,31013,31014,31015,31016,31017,31018,31019,31020,31021,31022,31025,31026,31027,31028,31029,31030) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/training_data/PreFer_train_data.csv\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/codebooks/PreFer_codebook.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/training_data/PreFer_train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m targets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/training_data/PreFer_train_outcome.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m codebook \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/codebooks/PreFer_codebook.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/codebooks/PreFer_codebook.csv'"
     ]
    }
   ],
   "source": [
    "# read in data and prepare transformations\n",
    "data = pd.read_csv(\"data/training_data/PreFer_train_data.csv\")\n",
    "targets = pd.read_csv('data/training_data/PreFer_train_outcome.csv')\n",
    "codebook = pd.read_csv('data/codebooks/PreFer_codebook.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0077c81",
   "metadata": {},
   "source": [
    "### Select the top 10 most important questions (there's overlap, so there's only gonna be 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.read_csv('features_importance_1000.csv')\n",
    "custom_pairs = importance.iloc[:50].feature.map(lambda x: get_generic_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d165d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    }
   ],
   "source": [
    "# check if sequences have been preprocessed (saves time)\n",
    "if False:# os.path.exists('data/processed_data/sequences.pt'):\n",
    "    sequences = torch.load('data/processed_data/sequences.pt')\n",
    "else:\n",
    "    sequences = encoding_pipeline(data, codebook, custom_pairs=custom_pairs)\n",
    "    #torch.save(sequences, 'data/processed_data/sequences.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddb66e-cba5-4bb9-854d-811d49599b93",
   "metadata": {},
   "source": [
    "# Train the SIMPLE Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9275bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import PretrainingDataset\n",
    "pretrain_dataset = PretrainingDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8544475-54af-4874-9e83-7f39193eb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### Initialization of the Autoencoder \n",
    "HIDDEN_DIM = 128\n",
    "#ENCODING_SIZE = 64\n",
    "BATCH_SIZE = 96\n",
    "num_epochs_autoencoder = 2\n",
    "learning_rate_autoencoder = 5e-2\n",
    "\n",
    "SEQ_LEN = pretrain_dataset.get_seq_len()\n",
    "vocab_size = pretrain_dataset.get_vocab_size()\n",
    "\n",
    "train_dataloader = DataLoader(pretrain_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "autoencoder = SimpleAutoEncoder(vocab_size=vocab_size, embedding_size=HIDDEN_DIM, sequence_len=SEQ_LEN).to(device)\n",
    "\n",
    "#loss_f1 = nn.HuberLoss(delta=1.0)\n",
    "loss_cls = nn.CrossEntropyLoss()\n",
    "#loss_cos = nn.CosineEmbeddingLoss()\n",
    "optimizer = optim.RAdam( autoencoder.parameters(), lr = learning_rate_autoencoder, weight_decay=1e-2, decoupled_weight_decay=True)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = num_epochs_autoencoder, eta_min = 1e-5, last_epoch = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094f791",
   "metadata": {},
   "source": [
    "### (or) Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slows down the training but allows use to detect nan\n",
    "DETECT_ANOMALY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be77146-e5b0-4a06-9d9e-d651c88d32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 468it [00:42, 10.93it/s, mean loss: 0.086]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m loss_epoch_metric\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     25\u001b[0m all_loss\u001b[38;5;241m.\u001b[39mappend(loss_epoch_metric[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m loop_object\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(loss_epoch_metric[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:]))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" INPUT MODEL NAME BELOW (FOR CHECKPOINTS)\"\"\"\n",
    "model_name = \"foo\"\n",
    "\n",
    "autoencoder.train()\n",
    "autoencoder.to(device)\n",
    "loss_metric = []\n",
    "all_loss = []   # for plotting\n",
    "######## ANNOMALY DETECTION\n",
    "torch.autograd.set_detect_anomaly(DETECT_ANOMALY)\n",
    "\n",
    "for epoch in range(num_epochs_autoencoder):\n",
    "    loss_epoch_metric = []\n",
    "    loop_object  = tqdm(enumerate(train_dataloader), desc=f\"Epochs {epoch}\")\n",
    "    for i, (year, seq) in loop_object :\n",
    "        optimizer.zero_grad()\n",
    "        year = year.to(device)\n",
    "        seq = seq.to(device)\n",
    "\n",
    "        x= autoencoder(year, seq)\n",
    "        loss = loss_cls(x.permute(0,2,1), seq.long()) #+ #+ loss_cos(x1.reshape(x1.size(1) * x1.size(0), -1 ), \n",
    "                                                       #         autoencoder.embedding(year, seq).view(x1.size(1) * x1.size(0), -1), \n",
    "                                                        #        torch.ones(seq.size(0) * seq.size(1)).to(device))\n",
    "         #+ 0.7 * loss_f1(x1, autoencoder.embedding(year, seq)) +  \n",
    "        loss_epoch_metric.append(loss.detach().cpu().numpy())\n",
    "        all_loss.append(loss_epoch_metric[-1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop_object.set_postfix_str(\"mean loss: %.3f\"%np.mean(loss_epoch_metric[-100:]))\n",
    "    ## After epoch end\n",
    "    scheduler.step()\n",
    "    loss_metric.append(np.mean(loss_epoch_metric))\n",
    "    print(f'epoch {epoch} \\t Loss: {loss_metric[-1]:.4g} and LR: {scheduler.get_last_lr()[0]:.5g}')\n",
    "    torch.save(autoencoder.state_dict(), f'weights/{model_name}_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f78caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3968c76",
   "metadata": {},
   "source": [
    "### Explroe the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0778109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Embedding has 0 NaNs\n",
      "Year Embedding has 0 NaNs\n"
     ]
    }
   ],
   "source": [
    "### FAST CHECK\n",
    "print(\"Answer Embedding has %s NaNs\" %torch.isnan(autoencoder.embedding.answer_embedding.weight).sum().cpu().numpy())\n",
    "print(\"Year Embedding has %s NaNs\" %torch.isnan(autoencoder.embedding.yearly_embedding.weight).sum().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8118b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5nklEQVR4nO3df5BV1ZXo8XVBaJTQrQjaTdL8CI4/wETxBwpSL4OlUYPGzJtxJj1mQjTxJTpONMxYaF4xxHEM05WpSMo4OlJTzLyoOFZlDFopyYj49JF0B0clM8QYtRWI0GpstC9i0pju+/7oudA098c55+59zlr7fD9VViXQdJ97+t6z115r7b0LpVKpJAAAAA6MyfoCAABAOAgsAACAMwQWAADAGQILAADgDIEFAABwhsACAAA4Q2ABAACcIbAAAADOHJH2DxwaGpLdu3fLpEmTpFAopP3jAQBAAqVSSfbu3SvTpk2TMWOq5yVSDyx2794t7e3taf9YAADgwK9+9Sv5yEc+UvXvUw8sJk2aJCLDF9bc3Jz2jwcAAAkUi0Vpb28/MI5XEzuw2Lt3r6xYsUIefvhheeutt2TevHnyne98R84+++xI/75c/mhubiawAADAmHptDLGbN7/0pS/J448/Lt/73vfkv/7rv+STn/ykXHDBBbJr167EFwkAAMJQiHO66W9+8xuZNGmSrF+/XpYsWXLgz88880y55JJL5G//9m/rfo9isSgtLS3S399PxgIAACOijt+xSiG/+93vZHBwUCZMmHDInx955JGyefPmiv9mYGBABgYGDrkwAAAQplilkEmTJsmCBQvktttuk927d8vg4KDcd9990tXVJb29vRX/zapVq6SlpeXAf6wIAQAgXLFKISIiPT09cvXVV8vTTz8tY8eOlTPOOENOPPFEefbZZ+UXv/jFYV9fKWPR3t5OKQQAAEO8lEJERGbPni1PPfWU7Nu3T4rForS1tcmf/MmfyEc/+tGKX9/U1CRNTU1xfwwAADAo8ZbeEydOlLa2NnnnnXfkRz/6kVx++eUurwsAABgUO2Pxox/9SEqlkpx00knyyiuvyE033SQnn3yyXHXVVT6uDwAAGBI7sOjv75dbbrlFXn/9dZk8ebL84R/+odx+++0ybtw4H9cHpGpwqCRbXtsjb+39rRw3aYLMnzVZxo7hTBsAiCp282aj2McCWm3Y1iu3PvqC9Pb/9sCftbVMkJWXzZGLT21z9nMIXgBY5K15EwjRhm29cu19z8noKPuN/t/Ktfc9J3d/7gwnwUVawQsAZCVx8yYQisGhktz66AuHBRUicuDPbn30BRkcaiy5Vw5eRgYVIgeDlw3bKu8Fo83gUEm6evpk/dZd0tXT1/B9ARAWMhbIvS2v7TlssB+pJCK9/b+VLa/tkQWzj030M+oFLwUZDl4unNOquixCxgVAPWQskHtv7a0eVCT5ukriBC9ahZJxAeAXgQVy77hJE+p/UYyvqySN4MWntMpFAOwjsEDuzZ81WdpaJki1AkRBhtP982dNTvwz0ghefAoh4wIgHQQWyL2xYwqy8rI5IiKHBRfl/7/ysjkN9T6kEbz4ZD3jAiA9BBaAiFx8apvc/bkzpLXl0IxBa8sEJ0tN0whefLKecQGQHlaFAP/t4lPb5MI5rd42ryoHL6NXVbQaWFVRzri80f/bin0WBRl+HVozLgDSw86bQMqs7rxZXhUiIocEF+Urd7WJGACdoo7fBBYAImMfCyC/2NIbgHO+y0UA7COwABDL2DGFxDuQAggfq0IAAIAzBBYAAMAZAgsAAOAMPRYAkBGrS4+BWggsAIUYcMLH0l2EisACUIYBJ3zlzcZGbyJUPoKezcZgGT0WUGFwqCRdPX2yfusu6erpy+3x2+UBZ/RJouUBZ8O23oyuDK5wBD1CR8YCmWOGPqzegFOQ4QHnwjmtlEUMi3MEPfuFwCIyFsgUM/SD4gw4sIsj6BE6AgtkhpTwoRhw/NNQcuMIeoSOUghSUWmVAynhQzHg+KWl5MYR9AgdgQW8q/ZA/9SprZH+fV5m6FYHHAtLYzWtwhg7piArL5sj1973nBSk8hH0Ky+bo+4eAlERWMCrWg/0f/rx9kjfIy8zdIsDjpYsQC0am2IvPrVN7v7cGYfdu1Zl9w5IgsAC3kTpoRhTECmVxNQM3SdLA46mLEAtWktuHEGPUBFYwJt6D3QRkXLvnJUZehosDDgaswDVaG6K5Qh6hIjAAt5EfVBffd5MeWzbG+pn6GnSPuBozQJUQlMskC4CC3gT9UF94ZxW+d9L5qieoeNQmrMAo1ltigWsYh8LeFN+oFcLDwoy3OhXDiIWzD5WLj/9w7Jg9rEEFcpZygKUm2JF5LD3Yp5LboAvBBbwhgd6uOIEjRqUm2JbWw4NdFpbJqhpMgVCUSiVSqluPVcsFqWlpUX6+/ulubk5zR+NjKS5JNHCngqhKK8KEanceKtxwOb9ASQXdfwmsEAq0nigW9hTITTccyA/CCyQK9X2VNA8ew4FWQAgH6KO36wKgXk+9lRgsIxO+9JYAOkisIB5rvdUyGN6n0AKgCsEFjDP5Z4KVrapdimPgRQAf1huCvNc7akQ5WyTWx99QQaHUm1L8qocSI3O+JQDqe9sfFnWb90lXT19Qb1uAP6QsYB5rnZWtLRNtQtRAqk7Nr504M/IYgCIgowFzHO1EZelbapdiHJI3EjlLMaGbb0er8qOwaGSdPX0mcjoWLpW2EfGAkFwcdy4pW2qXYgbIGk7tTRLlvpSLF0rwkBggWA0etx43g6rShIghVYOSsJSg6+la0U4KIUgKI0cZpa3s03qnfdRSyjloLgsNfhaulaEhcACGMHFYVVW6tm1Aql6QikHxRWnwTdrlq4VYaEUAozSSEnFWj27Wm9KNaGVg+Ky1OBr6VoRFgILoIIk21RbrWePDqS2v71P7tj4shSk8qmlIZWD4rLU4GvpWhEWAgvAAR/nlaRpdCB1UuukuitsomwDHtpW4ZYafC1dK8JCYAE4ENrmWvXKQVFKPtbKQlGU+1Kuve859RkdS9eKsNC8GQArzYIhC7GeXW2FTb1twDds6430NVa5aPBNi6VrRTjIWBgX4qzQorzUs6OUfL7xyM9FpGC2LBRFo3umpMnStSIMBBaGWW0WDFFe6tlRSj5vFAdqfg9rZaFqkjT4ZsXStcI+SiFGsfmNLnnZXMtlKcdSWQhAdAQWRrH5jT55qGe7LOVYLwuFjL4tNIJSiFEhNguGIPR6dpSSz/HNTSJSkDeLYZeFQtVo31ZoS4wRH4GFUXlpFrQo5Hp2lCWM3/j0XBERk8sc8z4oNtq3RTM5REQKpVIp1RxXsViUlpYW6e/vl+bm5jR/dFAGh0qyqHNT3WbBzcvPz9WDEekIcR8La9frWvmZUq3EWu+ZUi0oKX9lKOXAKEINUKOO3wQWhpU/yCKVZ4V5+iAjfSHtvMmgKNLV0ycda7rrft26a849LCPXaFASkpAD1KjjN82bhuWhWRB6RTmivpFj7NPCCqthjfRt0Uw+LOSN4eKgx8K40JsFAd9C2449qUb6tmgmt39ekEsEFgEIuVkQ8I1BcVgjm7zRTE6AOhKlEAC5xqA4rJFN3spBSbV5eEGG+wxCXmJMgHoQgQUQAxsHZcPnfWdQPChp31Zedp6thQD1IEohQEQhd3tr5vu+c7z4oZL2bZWDktG/q9acfEbycl5QFCw3BSJgOWI20rzvBI5uWFli7EPoWwCwjwVyzeXDjTX62cjivud5UIQbIQeoUcdvSiEIjusPNt3e2cjivrPCCo1iC4CYzZuDg4OyYsUKmTVrlhx55JEye/Zsue222yTlpEdwaAh0x8cGNXR7Z4P7DqssbAznU6yMRWdnp9x9993yL//yLzJ37lz5j//4D7nqqqukpaVFvvrVr/q6xqCFnDZLm68NavLS7a2tDJCX+w6EJlZg8ZOf/EQuv/xyWbJkiYiIzJw5U9atWydbtmzxcnGha/QkQRzKV+o8D93eGgPcPNx3IESxSiELFy6UJ554Ql566SUREfnZz34mmzdvlksuuaTqvxkYGJBisXjIf+B8Ah98pc5DX6Ov9XyD0O87EKpYgcXNN98sn/3sZ+Xkk0+WcePGybx58+TGG2+UK6+8suq/WbVqlbS0tBz4r729veGLDgGH9rjnM3Ue6oFv2gPcUO87ELJYpZCHHnpI7r//fnnggQdk7ty5snXrVrnxxhtl2rRpsnTp0or/5pZbbpFly5Yd+P/FYpHgQmhM88F36lxbt7eLnggLK1603XdkQ1sPEKqLFVjcdNNNB7IWIiIf+9jHZMeOHbJq1aqqgUVTU5M0NTU1fqWBoTHNvTR2UNSyHNFVT4TPANflQKDlvmuSp4FWYw8QqosVWLz//vsyZsyh1ZOxY8fK0NCQ04vKAxrT/MjDtsIum359BbgMBH7l6f7S5G5PrMDisssuk9tvv12mT58uc+fOleeff16+/e1vy9VXX+3r+oKl9XwCDbOgRq9Ba+rcxb11vaTWR4DLQOBXnu6vryXk8CtWYHHnnXfKihUr5LrrrpO33npLpk2bJl/+8pflr//6r31dX9C0za41zIJcXYO21Lmr1+W6J8J1gMtA4Ffe7q+FHiAcLlZgMWnSJFm9erWsXr3a0+Xkj5bZtYZZkIZr8MHl6/LRE+EywGUg8Ctv95cmd5s4K0SBrGfXGmZBGq7BB9evy1dPhKsAl4HAr7zdX5rcbYq1jwXCpGFPDQ3X4IPr11Xuiag23BdkuMSSpOnXxfkGDAR+Wb6/Sc5E8vl+hz9kLKBiFqThGnxw/bq0Nv2WsdrJL6v3N2mPkfb3OyojY2GQ69NQNcyCNFyDDz5el+bdKNmG2y+L97fRLeM1v99RGRkLY3ys3NAwC9JwDT74el1amn6rXZum1U6hsXR/XfUYaX6/43CFUqmU6iEAxWJRWlpapL+/X5qbm9P80eZVW11Q/mg1Er2Xv7dI5XRjmqtCsrwGH0J9XfVo2BMlZBbub1dPn3Ss6a77deuuOTeIVSyhizp+UwoxwvdhURrSjRquwYdQX1c9LppBUZ2F+xtq7xRqoxRiRBrr1zWkGzVcgw+hvi6gllB7p1AbgYURaUX+We+poeUafAj1deEgC+WJNIXaO4XaCCyMIPJH3lgbpDVsia8Ny0XzicDCCCJ/5Im1QTrU7ehdsLSKBW6wKsSQvK4uQL74XP3kw+BQSRZ1bqraA1UO+jcvPz/XM3NrGSgRm9fsU9Txm4yFIUT+CJ3rs1XSGBjydjBYUtZ6jKxlzTQhsDCG1QUImctBOq2BgSWV4aG01RgCC4OsRf5AVK4G6TQHhjiN1aTW9Qv1pOU0EVgAUMPF6qe0B4aojdXv7Nt/WC8GqXV9KG01jp03G+T6QDAgz1wck+36qPp6ohwM9unT2uTPH0h+EBfSMThUkh+/8nakr6W0VR0ZiwbQ3AO45WLfgyx6Hmo1Vq9Ycorc9sNfkFpXrtLzvBb2DKqOwCIhmnsAPxpd/ZTVZnLVGqvzmFq31ktS7XleCXsG1UdgkQDNPajE2sNUs0ZWP2W5mVylxuq8rRqxlsmt9Twfjd1CoyGwSCCPMxDUZu1hakHS1U/atpHO03b8FjO59Z7nI7FnUDQ0byaQtxkIais/TGnM00PTUfUuGlItqJfJFRnO5GbR4F6ryT7qc/r6xbNl8/LzCSoiIGORgOYZCOn4dO8BZTG9tGwml3YGJatngNZMbr1sYtTn9HknTOUzHBGBRQJaDwQjHZ/+PdD6MMUwLZvJpbUdf5bPAI2Z3CilmQvntKp8nltGKSSBKOvW027uIR2fzT3Q+DBtFHuz+HHxqW2yefn5su6ac+U7nz1d1l1zrtPUetbPAG2Z3KilGRFR9zy3jsAiIU01XM21zbRkdQ+0PUwbtWFbryzq3CQda7rlhge3SseablnUuSkXgWkayhmUy0//sCyYfazT8kfWzwBtvSRxsomanuchCKYUkkVdUUsNl3R8dvdAa1ksCYsd/Rim4RmgbTVO3Gyilud5CIIILLKsK2qo4YaYjo8rq3ug7WGaFE2otml5BqTVSxJFkmyihud5CMwHFsyywkvHJ5HlPdD0ME1Kw4wXyWl6BmiZ+YeUTbTGdGDBLGsYH6Ds74GWh2lSWma8SCbr9/9oGmb+oWQTLTLdvJn2KYZaaVylkjYN98BXY14aNM14EZ+G979GNGVmw3TGglnWQSGk4xvFPUhO24wX8fH+r8x6NtGiQqlUSnUNYrFYlJaWFunv75fm5uaGvldXT590rOmu+3Xrrjk387RcWkavjjlzxjHy7I53cvWBYvfRZMr9SiKV08bM8Gzg/Z+9UH8HUcdv04HF4FBJFnVuqjvL2rz8/CB+qXFZ34kz1A+nZtbfM0DWQv4M5SKwEGGWVU211TJW7kvIH07XXAdgBHRAMtafu/XkJrAQYRAarZzJqdbYqj2TE/qH0yXe+4AO1p+7UUQdv003b5bRnHMoy3sSsIQ4OvZwgQV5yYBZfu66FkRgIaJj3bQWllfL8OGMhgAMFuQpo2b5ueua6X0sUJnlPQny8OF0cXooe7hAu6xPW02b5eeua8FkLHCQ5T0JQv9wuprB5SEAg115zKhZfu66RsYiQJZ34dN29LJLLmdwoQdgsC2PGTXLz13XCCwCZXUr21A/nPVmcCLDM7ioZZGQAzBkr9FyXV4zalafu65RCgmY1dUyIW5N7LoplQOW4IuLcl2eM2pWn7suEVgEzupqmdA+nD5mcCEGYMiWqyXMee83sPrcdYXAAmqF9OH0NYOLGoBZ3kvA8rVb4rLhkoxavhFYACnwOYOrF4Bp30ugVuCg/dpD4rpcR0YtvwgsgBRkNYPTvjtnrcBBRFRfe2h8letCKmkiGgILICVpz+C07yVQL+hpOWqc2mvXLGnpyFe5LoSSJuW4eAgsFOJNHK40Z3Cat0ePsvz23fc/qPrv2dq9skZKR3lvuKyGclx8BBbK8CYOX1ozOM17CdQLeqIKbR+ERjRa9qLh8nDaS4lasUGWInnbW98KF2d7ZEHzXgKuAoIQ90FIwtUGbGzwdJDrTe3yhIyFEtrr4XllOYOkObXdaECQ17R8NS7LXjRcDtNcStSOjIUSedxbXzvrGSTN26NH2ZL8mKPGHfjfo/9OxEZaPq1sl+uyV7lcd/npH5YFs49Vf5990FxK1I6MhRJpv4lpEK0tlAyS1r0EotTzV/3Pj4mIqLv2qNLMdmkue1nFPU2OwEKJNN/E2tL7GoOckNKgWlPbUYMejddeT9pNf5rLXlZxT5MjsFAirTexti5nbUFOWWhpUK17CUQJerReezVZZLtY0eEe9zQ5eiyUSKMerq3LWXMPA2nQ9IRWz8+qX4oVHe5xT5MhY6GI73p43PS+zxKF9h4G0qCHSrNcpbE0FkeW2S6tZS/LuKfxEVgo4/NNHOeB57tEob2HwXca1NLgmWa5SmtpLA7X2a647xVrpSMLuKfxEFgo5OtNHPVBtv3tfbJ648te+zAs9DD4yiBZGjzT7MnR1v+TlMtsl6X3ClBGj0WORNk7oK1lgqzbstN7H4aVHoaLT22TzcvPl3XXnCvf+ezpsu6ac2Xz8vMPPNTj7lOgua9ktDR7crT1/zTCVb+UpfcKMBKBRQRWt3QeLcoD77NnT5c3igNVv4erxrOoQY6GHoZqzYUbtvXKos5N0rGmW254cKt0rOmWRZ2bqj7wrQ2eaTYhhrZBXKNNf9beK/WE8gxFNJRC6ggtFVkvvT/wu6FI36fREoX1pVxJ0vba+0pGS7NcZaE0Flcj/VLW3iu1hPYMRX0EFjVUGzx6+38rX7nvOfmHP50nn/r4tEyuLapKjV+1HnhdPX2Rvq+LEkWau0K6bJZMuqLF2uCZZrnKSmksrqT9UtbeK9WE0jeDeAgsqqg1eJRdv+55+a4U5FMf1/nBqDdTqPTAS3uZZRpLuVzPmJLOJl0NnmmtKEnzvcDy3kOFEGhpX1IOf+ixqKLe4CEiMlQSue4BnU1USRu/sji4yucGST4a4OLOJsv15Tf6fyOTJ45vqK8kbl9HI9J8L2g+MC0LlnqQqgmtbwbREVhUESfFqK2JqtHGr1B2m/PVABdnNjkyEPjaQz+TPfv2V52Ri9QePLNYJZDmeyGU950LIQRaoZRzEB+lkCripBi1NVG5aPwKYbc5Xw1wUdP27+wbkD9/4Pma5bSyen0lWaaV03wvhPC+c0XrybRRhVDOQTKxAouZM2fKjh07Dvvz6667Tu666y5nF6VBefCoVw4p0xR1u5opWN9tzteMKcqKlhVL5shtP6zdozN54jhZcelcaW2uP3hmvUogzfeC9fedS5YDLfpm8itWKeSZZ56R3t7eA/89/vjjIiJyxRVXeLm4LI1MRUahKepmpjDM532ol7Y/ZuL4ukHpnn0fSGvzhEh9JaSV06Vp34VGe5Cyei0hlHOQTKyMxdSpUw/5/3/3d38ns2fPlk984hNOL0qLi09tk3/403ly/brnpdpnUWPUzUxhmO/7UGs2uX7rrkjfI2ogQLCYnpD2Xcj6tVgv5yCZxD0W+/fvl/vuu0+WLVsmhUL1iHNgYEAGBg7u5FgsFpP+yEx86uPT5LtSkOseeO6wv9MadVvffMqVNO5DtbS960CAYDEdIe27oOW1WC7nIJnEq0J+8IMfyLvvvitf+MIXan7dqlWrpKWl5cB/7e3tSX9kZj718Ta553NnSJuhbnU67IdldR9cLxdsJK2sKa2vWUjbaGt7LT6XlEOfQqlUSvTOuuiii2T8+PHy6KOP1vy6ShmL9vZ26e/vl+bm5iQ/OjOWjrous3jNPmRxH8ozRpHK2ZIkgU3c1HbWqXBLunr6pGNNd92vW3fNueqbS0N6LdCjWCxKS0tL3fE7USlkx44dsnHjRvm3f/u3ul/b1NQkTU1NSX6MOha71S1esw9Z3Acf9eU4aWUtqXArQmqQDem1wJ5EgcXatWvluOOOkyVLlri+HkClpBkPH/XlKEES2ynHF1KDbEivBfbEDiyGhoZk7dq1snTpUjniCPbXQvgaLSdkkS3Jet8Li86ccYxMnjhe9uzbX/HvLTXI0uyLLMVu3ty4caPs3LlTrr76ah/XA6iSxTbaLpAKj2fDtl75xLeerBlUiNhZTcUeEshS7MDik5/8pJRKJTnxxBN9XA+ghrbO+jhIhUdXLXgcKckqoqxX47AyDFmhlgFUYbmcMJzWHyd79n1Q8e9JhQ+rFTyWTZ44Tp66abGMPyL6PEzLahz2kEAWON0UqMJqOeFgWr96UCFCKlykfvAoMrz1+rM73on8PbWVz9hDAmkjsACqsFhO8JXWD5Xr4NFy+QxwhVIIUIW1zvooaf1jJ46PndZ3TdOmba6DR8vlM8AVAgugCmtnrkRJ6/ft2y/P7ngns0FNS+9Bmevg0Wr5DHCJUghQg6XOeu2DmrbeAxH3yzItls8A18hYIBOa0uH1WOms1zyoad4J1OXW69bKZ3ln6TlkCYEFUqctHR6FhTNXNA9q2nsPXAWP1spneWbxOWQFpRCkymc6POsNibKmebdF7WUaEXfLMi2Vz7KW1WdWY1muGovPNTIWSI3PdDizj2E+TlR1odEyjbWUtZXyWZay+sxqLsuNZvW5ViiVSqmGP1HPc0d4unr6pGNNd92vW3fNubHS4dWOBy8/EvI4S9Q2EA8OlWRR56a6ZZrNy88/7DqtPlxRXZafWV/PIdc0Pteijt+UQgKnKY3mIx3OhkSVadttMWmZxlLKGtFk/Zm1UJbL+h41isAiYBu29cqizk3SsaZbbnhwq3Ss6ZZFnZsyexj7WLUQpykQ2Yrbe2D94YrKsv7Mal49VZb1PWoUPRaBqpZGK8/0skij+Vi1YGH2gYPi9B5oX0mCZLL+zGpePVWW9T1qFBmLAGmd6blYtTC6tDNlYlOkn82GRHpELdNYf7iisqwzBppXT5VlfY8aRcYiQJpneo2sWqjUxNfaPEGOPmqc9L//gdrZB5Kx/nBFZRoyBlpXT5VpuEeNILAIkPaZXpKleNVKO28WD37w2JAoLNYfrqFxtdJIyyZimpcEa7lHSRFYBMjCTC/OTpZR1p0ffdQ4aTpijLxRHDjwd1pmH0jG+sM1JK6X/GrJGGjeUVfLPUqCfSwUGDkTmDKxSaQg8vZ7A4kj6Eb2DNAo6rrz+790jowpFNTNPtCYUPax0La3SFQ+91Owek/SpOkeRR2/yVhkrNJDc6QkD9DQZnpRSzZvvzcgl5/+Yc9Xg7RpTllHZTU48r1LpeaMgRYW71GuV4VkvXlUtc1/Rkq6EZCW8wpc3GONpZ2s3zt5o23Drzgsb/JlfT8FZCO3GYusZxC1ZgIjNTIryHqm5+oea2viy/q9AzssnUtRifZGcOiUy4yFhhlEvZnASI3MCrKa6bm8x5rWnWt478AO6zN+jdlC6Je7wELL5lFJInwrswIf91hDaUfLeycNlHrcsD7jL2cLq4XsBRnO1rHkFyPlrhSiZfOoJBG+lVmBr3ucdWlHy3vHN0o97lif8YfWCI505C5joWUGUW8mMJK1WYHPe5xlE5+W945PlHrcCmHGn3W2kOyZPbnLWGiZQdSaCYxkcVag5R67FurrKrPeaKhRKDP+rLKFZM9syl3GQtMMotpMYKS0l4e6oOkeuxTq6yqz3mjoW9KZc9YzflfSzhaSPbMrdxkLbTOI0TMBFztvZk3bPXYl1NdVlodST1KNzpyz7g+yhuyZbbnLWIjom0GMnAmc93tT5LwTppjcCGgkbffYlVBfl0j4pZ6kXM2cLW/ylba42TP6MHTJXcaijBmEf6He41Bfl7aNyDRg5ny4NM6uiJM9ow9Dn9wGFiI292C3JtR7HOV1aTo8KIrQSz3V1Po9hb7EOO57NK1BPGpWbPvb+2T1xpcPC/zK2STrWUSrch1YAL5YnUW5PKrZQmBV7/cUct9J3PdotVNOfQziUbNn67bsJJukEMemIxELg0ZWfB4znZZGf78WAqsov6eWI8dLx5ruut9r3TXnmspYxH2PDg6VZFHnpqrZm/JAv3n5+c6eA+VrFKmcPbvxghPljo0v1f0+1n43mnFsOiLTmg61KJSafCMlrDRntklF/T09ddPi4PpOkrxHsygJ1cueDfxuKNL3sZhNso7AIuc0p0MtCr0mX4+VwCrq7+nZHe8E13eS5D2aVUmoVqN0V09fpO+Rt1VMGuRyuSmGxV1Gl6dDuJIKuSZfS3m53x2Pv2Rik604v6fQlhgneY9muRS52jLd0Dess4yMRU5ZSYdak8e9ICplverJOrCK+3sKaYlxkveoxqXIeV3FVIuW3jcyFjmVZPvmvM7G48jbLKpa1querAOrJL+nsWMKMn/WZDlu0gR5a+/wZ8Nidi7pa1952ZwDfz/660WyGcRDyyY1YsO2XlnUuUk61nTLDQ9ulY413bKoc1MmW5+Tscgpa+lQK1zOorTMPqqplfWqRkuzY5LfUyhNy0nfoy6XIrsUUjYpKW29bwQWORVKOlSjC+e0yo0X/J6s/fF2efc3Hxz48zgPYAuDWL2s12ja0tNxBkptD+5GJQ0StA7ioW7EF4XGhukgAgvtMzuNkgQJ1DTrqxQQHH3kOLnqvFly/fknRLo3VgaxuCWvrGe2lUQZKDU+uF1IGiTkeRDXSGPvm/nAwsLMTqPQ0qEaVAsI+n/zgaze+JKc1PqhuvfH0iAWNet1/eLZct4JU9UG/PUGSo0PblcIEuzT2PtmOrCwMrPTKrR0aJZcBQSWBrGoWa+vXXiS6feGxgc3UKax981sYGFpZqcZ6VA3XAUElgaxvJTGND64gTKNvW9ml5smWS6JyqptQIPoXAUE1gaxPCz3y9sSYtiicSmw2YyFpZkdwucqINA4+6gn9NJYXjIzsEtb75vZwMLazA5hcxUQWB3EQi+NaXtwA6NpCvDNHptePsa33oPc5TG+QC31jnmOUxpgtZNOLG1HnkUdv80GFiJuH+SACy4DAgYxAJrkIrAQsTuzY9BIX1r3XMvvVst1AAhDbgILEXsPUKvBkGV5u+d5e70A/MtVYGFJtU29KN/4k7d7nrfXa4G1yQ9QSdTx2+yqEIvY1Ct9ebvneXu9Lvka/MkeIW8ILFJkabvmUOTtnuft9bria/Dn2AHkkdmdNy3K66Zeg0Ml6erpk/Vbd0lXT58MDqVXfcvbPc/b63WhPPiPDsjKg/+Gbb2Jvm+97JHIcPYozc8DkAYyFinK46ZeWaeB83bP8/Z6G+WzdET2CHlFxiJFeTtzwNdMMI683fOor/fMGcdklkXSxOeZQ2SPkFcEFinSeFiML1rSwHm65yLRXu+nT2uTT3zrSelY0y03PLhVOtZ0y6LOTakEetr4HPyjZoW2v/1+7O8N/bIsAWeNwCJleTgNUkTX6bN5uedltV7v//ofs+Tep1/LNIukic/S0fxZk6W1uanu1z34zM5cDTp5sGFbryzq3JTb4J0eiwxoOizGF21p4Dzc85Eqvd4zZxwjn/jWkyxFHcHnabJjxxSkY/50uWPjyzW/jj6LsLASiMAiM6GfBqmxiTD0ez7a6Nfb1dMXTDOhqz0nfJ8mO3PKxEhfR59FGNhHZhiBBbzwORNEMtqySEm5Xmnk80h0jQE2qms0YGUl0DACC3jheyaI+EIY5HylmX2Vygiw7WgkYC0HJI9F7KHQHrw3iuZNeGOhaTJPndvWl976XmlULh1dfvqHZcHsY50EvXlblWRVI0vjRzZq/p+uHZF+nubg3QUyFvCq3kwwy8OZst68K23Ws0hW08w+Sy1oXCN9EdUyaNXkJUNFYKFI1EHW2kmJ1ZomsxzY89q5bXmQs9wjkrdVSZYkDVhrBSSVWAjeXYkdWOzatUuWL18ujz32mLz//vtywgknyNq1a+Wss87ycX25EXWQDWWWneXAnvfObauDXJIeEU1BeN5WJVmRNGCtF5CMZiF4dyVWYPHOO+/IeeedJ4sXL5bHHntMpk6dKi+//LIcc8wxvq4vF6IOsqHMsrMe2K2m1F2yOMjFbYQMJQjXQlOQ5lLSpuaoAcnnF8yQS05tC+Z+RRErsOjs7JT29nZZu3btgT+bNWuW84vKk6iD7PknHx/MLDvrgd1ySj3P4vSIhBKEaxFykJZ05U7UgOSSU9vMBfGNirUq5JFHHpGzzjpLrrjiCjnuuONk3rx5smbNmpr/ZmBgQIrF4iH/4aCog+z3urar2SK7UVkP7Gkuu8zTqpM0RFlppOWcmlBoOEzQp6Qrd6yvsvIpVsbi1VdflbvvvluWLVsmX//61+WZZ56Rr371qzJ+/HhZunRpxX+zatUqufXWW51cbIiiDp7/96VfO/1+Wcp6P4W09hbwPcsLNTVdT70ekawzYiHJumyZliRNzdZXWfkUK7AYGhqSs846S775zW+KiMi8efNk27Ztcs8991QNLG655RZZtmzZgf9fLBalvb29gUsOS9TB8/+9/LbT75elrDcNSuOB4DsVH3JqOopaPSJZZ8RCkqcgLUlTs+VVVj7FCiza2tpkzpw5h/zZKaecIt///ver/pumpiZpaqp/wl9e1Rtko7K0PlpDpO/zgeB7lkf/QG1ZZ8RCkrcgLUlTs9VVVj7FCizOO+88+eUvf3nIn7300ksyY8YMpxeVJ7UG2agspt00RPq+Hgg+Z3l5SU03IuuMWEgI0qKxuMrKp1iBxde+9jVZuHChfPOb35Q//uM/li1btsi9994r9957r6/ry4Vqg2xUVtNuGiJ9Hw8En7O8rFPTFvo6NGTEQkGQhiRiBRZnn322PPzww3LLLbfI3/zN38isWbNk9erVcuWVV/q6vtwYOcg+tq030p7zIayPDjHS9znLyzI1bamvQ0NGLAQEaUgi9s6bl156qVx66aU+riX3Rg6yUQKLPK6PtsDnLC+r1LTFvg4NGbEQEKQhLs4KUYj0o21jxxRkxZJT5LoHnj/s7xqd5WXx3rDc1xFiRiwLBGmIg2PTFeKoZds2bOuV2374i4p/1+iR8Vm8N+L0dSBcPo6VR5gILJSKssMg9Km2S2HZiiWNp47Tfm/kbckhgMZQClGM9KMt9Y5RLojIbT98QS46tfGSQZrvDa1LDi2sUAHyiMBCOWrEdqS9FDSt94bGnh9LK1SAvKEUAjgSaslAW89P6IdiAdYRWACOaC0ZuKCl54eTSwH9KIXAFM11dY0lA5c09PxkvfMootP8WYVfBBYwQ3tdPQ+7FGbd8xNquSkU5WBi4wtvyMNbd8mefR8c+DtNn1X4RSkEJlipq2spGYQq5HKTdRu29cqizk3SsaZb/unH2w8JKkT0fVbhDxkLqGdt50cNJYNQhV5usqralu8jafyswg8yFlDP4s6P7FLoh7YVKqi/f8tIGj+rcI/AAur5qqsPDpWkq6dP1m/dJV09fawkMIJyky71Av9K6IEJG6UQqOejrq69ERS1UW7SI0mQQA9M2AgsoJ7rurrFI8BHYhnfsKxXqGBYnCCBHph8ILCAei6XcVprBB2NTAu0qRf4j0YPTPjosYAJrurqFhtBy6wsuUW+1GqoHamNHpjcIGMBM1zU1a1usGQ90+ILZSEdyoH/6GzasRPHy+WnT5ML57Tyu8kRAgt44+Oh32hd3eoGS2xlfTjKQrrQUIsyAgt4ofWhb3WDJauZFl+sN+CGKq2GWjJVuhFYwDnND32r53lYzbT4QFko37ROWnAQzZtwysKx1hY3WCpnWqoNkwUZfrhqy7T4YLkBF42hgdkGMhZwykovgLV6sNVMiw+UhfKJTJUdZCzglKWHvrXzPCxmWnygLJRPZKrsIGMBp3jo+2Ut0+KD1QZcTSw2P1qatOQdgQWcirIL39FHjeOh34C8b2VNWagxVpsfmbTYQSkETpUf+rVaM999/wN5/IU3UrsmhIeyUDKWmx9pYLaDjAWcu3BOqxx91Dh59/0PKv49TVZwwWJZKMsShPXmRzJVdhBYeGSxjunCltf2VA0qRPSsDIF9lspCWZcgrKzYqqXa1uGtBko5eUJg4UnWD5Es0WSVTF4D0TzQsGlcKJ9Li5mqvCGw8EDDQyRLNFnFl+dANHRaShAhfS4tZaryiOZNxyzsPOkbTVbxZNFQNzhUkq6ePlm/dZd09fQF/X7Mmpb9F/hcIi0EFo5peYhkqdxkJSKHPcRosjpUFoHohm29sqhzk3Ss6ZYbHtwqHWu6ZVHnJtUrAizTUoLgc4m0EFg4puUhkjWWA0aTdiBqebmhVZpKEHE+l2S1kBQ9Fo5peohkLbQmKx/NlWkGolpq/XmjbafQKJ9Len7QCAILx7Q9RLIWSpOVrwdtmoFoCMsNLdK4/0Ktz2Xem8/ROEohjlHHDI/P8kGaDXWU6bJjpTRI8zlcIGPhAZu4hMN3+SDN2SxlumxZKA2S1YILBBaeWHiIoL6oD9ruV/tkTKGQ6HedViDqqkwXykZeWbwO7aVBslpwgcDCI1cPEY0Pco3X5EPUB+if3/+cvPubg9uYx+2/SCMQdZEdCaWpL5TXIeL2s0hWCy4USqVSqsWyYrEoLS0t0t/fL83NzWn+aJM0PgA1XpMvXT190rGmO/a/Kz/WNdXPy5L+/qo19Wl+rZWE8jpE3H8WB4dKsqhzU92s1ubl5wc5kUBtUcdvAgvFND4ANV6TT/UetLVofgjHneWW70O1spDm1zpSKK9DxN9nsfx9RSpntUL7jCO6qOM3q0KU0tidrfGafKu1yqcezbuslst0l5/+YVkw+9i6g2goO8qG8jp8fhatrGCBXvRYKKWxO1vjNSURd7Zerbny6KPG1TweviyERrdQmvpCeR2+P4s0n6MRBBZKaXwAarymuJLWpCs9aIeGSnLlP/207s8ModEtlKa+UF5HGp9F7StYoBeBhVIaH4CNXlPWK0ka3VFw9IN2cKiUm11WQ9lRNpTXEfWzuP3t9z1fCXA4eiyU0njEcSPXlPWJmj5q0nnaZTWU1xrK65g/a7K0NjfV/boHn9kZVM8TbCCwUErjAzDpNWk4UdNX016eGt1Cea0hvI6xYwrSMX963a+z0IiK8FAKUUzj1uBxr0nLiZo+a9J5anQL5bWG8DpmTpkY6es09zwhTAQWyml8AMa5Ji0rSXz3rOSp0c3Xa027B8f670xjHxYgQmBhgsYHYNRr0rKSJJSmvVDlaTdXV3hPQyt6LOCVllmVxp4VDNPQg2MR72loRWABrzStbgmhaS80edzN1SXe09CIUgi8cnGipksae1byTEsPjmW8p6ENgQW807a6RWPPSl5p6cFJKutN38p4T0MTAgukglkVKtHSg5MEDadAZQQWSA2zKoxmdWVDo9vDAyGjeROxDQ6VpKunT9Zv3SVdPX001iExiysbaDgFaiNjgVhI/8I1bT049dBwCtRGYIHISP/CF0s9ONYbTgHfCCwQiZYzP+BXlqscrPTgWG44BdJAYIFISP+GjzJXNFYbToG00LyJSEj/ho1ttaOz2HAKpInAApGQ/g0XqxziYyttoDpKIYiE9G+4KHMlY6nhFEgTgQUi0XbmB9yhzJWclYZTIE2UQhAZ6d8wUeYC4FKsjMU3vvENufXWWw/5s5NOOklefPFFpxcFvUj/hocyFwCXYpdC5s6dKxs3bjz4DY6gmpI3pH/DQpkLgEuxo4IjjjhCWltbfVwLgIxY21Y7NFqOXwdciB1YvPzyyzJt2jSZMGGCLFiwQFatWiXTp0+v+vUDAwMyMDBw4P8Xi8VkVwogtjgDFmWubLAxGUJTKJVKkRenP/bYY/Lee+/JSSedJL29vXLrrbfKrl27ZNu2bTJp0qSK/6ZSX4aISH9/vzQ3Nye/cgA1ZTlgMQOPptr5O+U7RVM0NCkWi9LS0lJ3/I4VWIz27rvvyowZM+Tb3/62fPGLX6z4NZUyFu3t7QQWgEdZDljMwKMZHCrJos5NVfcQKTfNbl5+PkEZVIgaWDS03PToo4+WE088UV555ZWqX9PU1CTNzc2H/AfAnyx30mRr8OjibEwGWNJQYPHee+9JT0+PtLUxCwG0yGrAYmvweNiYDKGKFVj81V/9lTz11FOyfft2+clPfiJ/8Ad/IGPHjpWOjg5f1wcgpqwGLGbg8bAxGUIVa1XI66+/Lh0dHdLX1ydTp06VRYsWSXd3t0ydOtXX9QGIKasBixl4PGxMhlDFCiwefPBBX9cBwJGsBixm4PGwMRlCxVkhQGDKA5bIwQGqzOeAVQ5oqn3XggyvDmEGfhDn7yBEDS03TSLqchUAjcli2Wd5VYhI5Rk4g2Vl7PsBC1LZxyIJAgsgPVkMWOxjAYSJwAJAZpiBA+GJOn5zNCkA5zgBF8gvAgsAmSGzUR/3CNYQWADIBL0Y9XGPYBHLTQGkzteZIoNDJenq6ZP1W3dJV0+f6e3DOXcFVpGxAJCqemeKFGT4TJEL57TGSvmHNLv3dY+ANJCxAJAqH2eKhDa759wVWEZgASBVrs8UCfFUVc5dgWUEFoASIfUH1OL6TJEQZ/ecuwLL6LEAPIi7RDCk/oB6XB+SFuLsnpNPYRkZC8CxDdt6ZVHnJulY0y03PLhVOtZ0y6LOTVXr/KH1B9Tj+pC0EGf3WR0kB7hAYAE4FDdICLE/IAqXp3qGeqoqJ5/CKkohgCNJlgjG6Q8IbYvsi09tkwvntDa8q2R5dn/tfc9JQSqfqmp1du/qHgFpIrAAHEkSJITYHxCHqzNFyrP70X0qrQH0qXDuCqwhsAAcSRIkhNgfkBVm94AOBBaAI0mCBLr/3WJ2D2SP5k3AkSRNhHT/AwgNgQXgSNIgge5/ACEplEqlVNexFYtFaWlpkf7+fmlubk7zRwOpSLrZVdxNtXzRch0AdIk6fhNYAB5YHZzztAMogHgILADEUt7ca/QDoRwOUZYB8i3q+E2PBYDc7gAKwD0CCwBBnhAKIBsEFgByvwMoAHcILACwAygAZwgsAAR7QiiA9BFYAGAHUADOEFgAEBF2AAXgBoeQATiAE0IBNIrAAsAhOCEUQCMohQAAAGcILAAAgDMEFgAAwBkCCwAA4AyBBQAAcIbAAgAAOENgAQAAnCGwAAAAzhBYAAAAZ1LfebNUKomISLFYTPtHAwCAhMrjdnkcryb1wGLv3r0iItLe3p72jwYAAA3au3evtLS0VP37Qqle6OHY0NCQ7N69WyZNmiSFAgcbxVUsFqW9vV1+9atfSXNzc9aXg//G70Unfi868XvRq9bvplQqyd69e2XatGkyZkz1TorUMxZjxoyRj3zkI2n/2OA0NzfzgVSI34tO/F504veiV7XfTa1MRRnNmwAAwBkCCwAA4AyBhTFNTU2ycuVKaWpqyvpSMAK/F534vejE70UvF7+b1Js3AQBAuMhYAAAAZwgsAACAMwQWAADAGQILAADgDIGFYZ/+9Kdl+vTpMmHCBGlra5M/+7M/k927d2d9Wbm2fft2+eIXvyizZs2SI488UmbPni0rV66U/fv3Z31puXf77bfLwoUL5aijjpKjjz4668vJtbvuuktmzpwpEyZMkHPOOUe2bNmS9SXl3tNPPy2XXXaZTJs2TQqFgvzgBz9I/L0ILAxbvHixPPTQQ/LLX/5Svv/970tPT4/80R/9UdaXlWsvvviiDA0NyT/+4z/Kz3/+c7njjjvknnvuka9//etZX1ru7d+/X6644gq59tprs76UXPvXf/1XWbZsmaxcuVKee+45Oe200+Siiy6St956K+tLy7V9+/bJaaedJnfddVfD34vlpgF55JFH5DOf+YwMDAzIuHHjsr4c/Ldvfetbcvfdd8urr76a9aVARP75n/9ZbrzxRnn33XezvpRcOuecc+Tss8+W7373uyIyfH5Ue3u7/MVf/IXcfPPNGV8dREQKhYI8/PDD8pnPfCbRvydjEYg9e/bI/fffLwsXLiSoUKa/v18mT56c9WUAmdu/f788++yzcsEFFxz4szFjxsgFF1wgXV1dGV4ZXCKwMG758uUyceJEOfbYY2Xnzp2yfv36rC8JI7zyyity5513ype//OWsLwXI3Ntvvy2Dg4Ny/PHHH/Lnxx9/vLzxxhsZXRVcI7BQ5uabb5ZCoVDzvxdffPHA1990003y/PPPy7//+7/L2LFj5fOf/7xQ3XIv7u9FRGTXrl1y8cUXyxVXXCHXXHNNRlcetiS/FwB+pX5sOmr7y7/8S/nCF75Q82s++tGPHvjfU6ZMkSlTpsiJJ54op5xyirS3t0t3d7csWLDA85XmS9zfy+7du2Xx4sWycOFCuffeez1fXX7F/b0gW1OmTJGxY8fKm2++ecifv/nmm9La2prRVcE1Agtlpk6dKlOnTk30b4eGhkREZGBgwOUlQeL9Xnbt2iWLFy+WM888U9auXStjxpAY9KWRzwvSN378eDnzzDPliSeeONAYODQ0JE888YRcf/312V4cnCGwMOqnP/2pPPPMM7Jo0SI55phjpKenR1asWCGzZ88mW5GhXbt2ye///u/LjBkz5O///u/l17/+9YG/Y0aWrZ07d8qePXtk586dMjg4KFu3bhURkRNOOEE+9KEPZXtxObJs2TJZunSpnHXWWTJ//nxZvXq17Nu3T6666qqsLy3X3nvvPXnllVcO/P/XXntNtm7dKpMnT5bp06fH+2YlmPSf//mfpcWLF5cmT55campqKs2cObP0la98pfT6669nfWm5tnbt2pKIVPwP2Vq6dGnF38uTTz6Z9aXlzp133lmaPn16afz48aX58+eXuru7s76k3HvyyScrfj6WLl0a+3uxjwUAAHCG4i8AAHCGwAIAADhDYAEAAJwhsAAAAM4QWAAAAGcILAAAgDMEFgAAwBkCCwAA4AyBBQAAcIbAAgAAOENgAQAAnCGwAAAAzvx/zm0gFwulrc0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "w = autoencoder.embedding.answer_embedding.weight.detach().cpu().numpy()\n",
    "projector = umap.UMAP(n_components=2)\n",
    "wp = projector.fit_transform(w)\n",
    "plt.scatter(wp[:,0], wp[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8018b-7ebc-4db4-aadf-191b214b1470",
   "metadata": {},
   "source": [
    "# Train the RNN\n",
    "\n",
    "First we need to create Dataset class that can hold both the target (stored in a pd.DataFrame) and the sequences.\n",
    "\n",
    "The sequences will be of dimension 14 x encoding_dimension, because we have 14 years of surveys.\n",
    "\n",
    "I have created some code for getting the data into the right format, but it might not be useful.\n",
    "\n",
    "## Regarding masks\n",
    "Right now the masking is done already in the encoding. I haven't found exactly where Mikkel implemented this.\n",
    "So for now, assume that nothing is padded, and then we'll figure it out with Mikkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1786da-d2b5-4e1f-81f6-1db7bca5515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its not everyone we have a target for, so we do restrict the data to \n",
    "# the ones with known outcomes\n",
    "targets = targets[targets.new_child.notna()]\n",
    "train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754d624a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m rnn_data \u001b[38;5;241m=\u001b[39m {person_id: (\n\u001b[1;32m      2\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor([year\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2007\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year, _ \u001b[38;5;129;01min\u001b[39;00m wave_responses\u001b[38;5;241m.\u001b[39mitems()])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m      3\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor([ wave_response \u001b[38;5;28;01mfor\u001b[39;00m _, wave_response \u001b[38;5;129;01min\u001b[39;00m wave_responses\u001b[38;5;241m.\u001b[39mitems()])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m         )\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m person_id, wave_responses \u001b[38;5;129;01min\u001b[39;00m \u001b[43msequences\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      6\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "rnn_data = {person_id: (\n",
    "        torch.tensor([year-2007 for year, _ in wave_responses.items()]).to(device),\n",
    "        torch.tensor([ wave_response for _, wave_response in wave_responses.items()]).to(device)\n",
    "        )\n",
    "        for person_id, wave_responses in sequences.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaadc01-1e81-4727-b7f4-f14823463fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on the splits made for the target\n",
    "train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85edc9-8457-439f-8fe9-fbd94eb9b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataset import FinetuningDataset\n",
    "train_dataset = FinetuningDataset(train_data, targets = targets)\n",
    "test_dataset = FinetuningDataset(test_data, targets = targets)\n",
    "\n",
    "rnn_batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=rnn_batch_size, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=rnn_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caf49964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is going to set all input MASK to None\n",
      "Ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# ft - fine-tuning\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "ENCODING_SIZE = 64\n",
    "\n",
    "num_epochs_ft = 40\n",
    "learning_rate_ft = 5e-3\n",
    "\n",
    "aggregator = nn.Sequential(\n",
    "    nn.LazyInstanceNorm1d(),\n",
    "    nn.LazyLinear(ENCODING_SIZE),\n",
    "    nn.LazyBatchNorm1d()).to(device)\n",
    "\n",
    "rnn_model = GRUDecoder(\n",
    "    input_size=ENCODING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    max_seq_len=14\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer for RNN\n",
    "ft_loss = torch.nn.BCELoss()\n",
    "ft_optimizer = torch.optim.RAdam(list(rnn_model.parameters()) + list(autoencoder.parameters()) + list(aggregator.parameters()) , lr=learning_rate_ft, weight_decay=1e-3, decoupled_weight_decay=True)\n",
    "ft_scheduler = optim.lr_scheduler.CosineAnnealingLR(ft_optimizer, T_max = num_epochs_ft, eta_min = 1e-6, last_epoch = -1)\n",
    "\n",
    "# Training loop\n",
    "rnn_model.train()\n",
    "autoencoder.train()\n",
    "aggregator.train()\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ffe77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82cf1777-49e7-462d-ae51-549ea6c8305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 50it [00:35,  1.41it/s, mean loss: 0.580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.5802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1: 50it [00:33,  1.48it/s, mean loss: 0.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Loss: 0.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 2: 42it [00:29,  1.40it/s, mean loss: 0.514]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     loop_object\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(loss_per_step[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:]))\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#loss.backward(retain_graph=True)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     ft_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# On epoch end\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_per_epoch = []\n",
    "for epoch in range(num_epochs_ft):\n",
    "    # print(epoch)\n",
    "    loss_per_step = []\n",
    "    loop_object  = tqdm(enumerate(train_dataloader), desc=f\"Epochs {epoch}\")\n",
    "    for i, batch in loop_object :        \n",
    "        ft_optimizer.zero_grad() \n",
    "        inputs, labels = batch\n",
    "        labels = labels.to(torch.float).to(device)\n",
    "\n",
    "        input_year, input_seq = inputs\n",
    "        bs, ss = labels.size(0), 14\n",
    "        input_year = input_year.reshape(-1).to(device)\n",
    "        input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "        encodings = autoencoder.get_encoding(input_year, input_seq).view(bs,ss, -1)\n",
    "        survey_emb = aggregator(encodings)\n",
    "        mask = ~((input_seq == 101).sum(-1) == NUM_COLS).view(bs,ss).detach()\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        xx = rnn_model(survey_emb, mask)\n",
    "        outputs = torch.nn.functional.sigmoid(xx)\n",
    "\n",
    "        loss = ft_loss(torch.flatten(outputs), labels)  \n",
    "        loss_per_step.append(loss.detach().cpu().numpy())\n",
    "        loop_object.set_postfix_str(\"mean loss: %.3f\"%np.mean(loss_per_step[-100:]))\n",
    "\n",
    "        #loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        ft_optimizer.step()\n",
    "    # On epoch end\n",
    "    loss_per_epoch.append(np.mean(loss_per_step))\n",
    "    ft_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_ft}, Loss: {loss_per_epoch[-1]:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5ad6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "649bc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "val_loss = []\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "## Set both models into the eval mode.=\n",
    "rnn_model.eval()\n",
    "autoencoder.eval()\n",
    "for batch in test_dataloader:\n",
    "    inputs, labels = batch\n",
    "    labels = labels.to(torch.float).to(device)\n",
    "\n",
    "    input_year, input_seq = inputs\n",
    "    bs, ss = labels.size(0), 14\n",
    "    input_year = input_year.reshape(-1).to(device)\n",
    "    input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "    encodings = autoencoder.get_encoding(input_year, input_seq).view(bs,ss, -1)\n",
    "    survey_emb = aggregator(encodings)\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    xx = rnn_model(survey_emb)\n",
    "    outputs = torch.nn.functional.sigmoid(xx).flatten()\n",
    "    loss = ft_loss(outputs, labels)  \n",
    "    val_loss.append(loss.detach().cpu().numpy())\n",
    "    preds.extend(outputs.detach().cpu().numpy().tolist())\n",
    "    targets.extend(labels.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbdb333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 396.7141, -271.1413,  186.5809,  ...,  140.8089, -335.6460,\n",
       "            -4.6883],\n",
       "         [ 360.4650, -246.9991,  170.8218,  ...,  127.9039, -305.7834,\n",
       "            -4.8385],\n",
       "         [ 348.2091, -238.4744,  164.7740,  ...,  123.5789, -295.2355,\n",
       "            -4.5558],\n",
       "         ...,\n",
       "         [ 352.5689, -240.1433,  164.3805,  ...,  125.3269, -297.3981,\n",
       "            -3.4081],\n",
       "         [ 386.8688, -262.6257,  181.6237,  ...,  136.0513, -329.1053,\n",
       "            -5.2761],\n",
       "         [ 372.2779, -252.5528,  171.7637,  ...,  132.5087, -312.9012,\n",
       "            -2.6895]],\n",
       "\n",
       "        [[ 396.7141, -271.1413,  186.5809,  ...,  140.8089, -335.6460,\n",
       "            -4.6883],\n",
       "         [ 360.5259, -247.0432,  170.8580,  ...,  127.9231, -305.8476,\n",
       "            -4.8444],\n",
       "         [ 348.2689, -238.5186,  164.8111,  ...,  123.5977, -295.3000,\n",
       "            -4.5622],\n",
       "         ...,\n",
       "         [ 352.7458, -240.2361,  164.4105,  ...,  125.3825, -297.5185,\n",
       "            -3.4000],\n",
       "         [ 384.2577, -260.9254,  179.8834,  ...,  135.6895, -326.0070,\n",
       "            -4.5439],\n",
       "         [ 372.2779, -252.5528,  171.7637,  ...,  132.5087, -312.9012,\n",
       "            -2.6895]],\n",
       "\n",
       "        [[ 396.8515, -271.2491,  186.6770,  ...,  140.8534, -335.8031,\n",
       "            -4.7092],\n",
       "         [ 360.5259, -247.0432,  170.8580,  ...,  127.9231, -305.8476,\n",
       "            -4.8444],\n",
       "         [ 348.2689, -238.5186,  164.8111,  ...,  123.5977, -295.3000,\n",
       "            -4.5622],\n",
       "         ...,\n",
       "         [ 352.7473, -240.2533,  164.4380,  ...,  125.3817, -297.5378,\n",
       "            -3.4121],\n",
       "         [ 381.7377, -258.9284,  177.7663,  ...,  134.3098, -322.9394,\n",
       "            -4.0275],\n",
       "         [ 372.2782, -252.5524,  171.7628,  ...,  132.5084, -312.9003,\n",
       "            -2.6891]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 396.8515, -271.2491,  186.6770,  ...,  140.8534, -335.8031,\n",
       "            -4.7092],\n",
       "         [ 360.5259, -247.0432,  170.8580,  ...,  127.9231, -305.8476,\n",
       "            -4.8444],\n",
       "         [ 348.2689, -238.5186,  164.8111,  ...,  123.5977, -295.3000,\n",
       "            -4.5622],\n",
       "         ...,\n",
       "         [ 352.9886, -240.3471,  164.4006,  ...,  125.4622, -297.6244,\n",
       "            -3.3704],\n",
       "         [ 386.4492, -262.7343,  180.0902,  ...,  137.0214, -326.7105,\n",
       "            -4.1121],\n",
       "         [ 372.2779, -252.5528,  171.7637,  ...,  132.5087, -312.9012,\n",
       "            -2.6895]],\n",
       "\n",
       "        [[ 396.7141, -271.1413,  186.5809,  ...,  140.8089, -335.6460,\n",
       "            -4.6883],\n",
       "         [ 360.4650, -246.9991,  170.8218,  ...,  127.9039, -305.7834,\n",
       "            -4.8385],\n",
       "         [ 348.2091, -238.4744,  164.7740,  ...,  123.5789, -295.2355,\n",
       "            -4.5558],\n",
       "         ...,\n",
       "         [ 352.7822, -240.2548,  164.4092,  ...,  125.3925, -297.5321,\n",
       "            -3.3958],\n",
       "         [ 386.3191, -262.3886,  179.5609,  ...,  137.0185, -326.4250,\n",
       "            -3.9695],\n",
       "         [ 372.2779, -252.5528,  171.7637,  ...,  132.5087, -312.9012,\n",
       "            -2.6895]],\n",
       "\n",
       "        [[ 396.7141, -271.1413,  186.5809,  ...,  140.8089, -335.6460,\n",
       "            -4.6883],\n",
       "         [ 360.4650, -246.9991,  170.8218,  ...,  127.9039, -305.7834,\n",
       "            -4.8385],\n",
       "         [ 348.2091, -238.4744,  164.7740,  ...,  123.5789, -295.2355,\n",
       "            -4.5558],\n",
       "         ...,\n",
       "         [ 352.8372, -240.2659,  164.3809,  ...,  125.4085, -297.5310,\n",
       "            -3.3810],\n",
       "         [ 386.4536, -262.7127,  180.0749,  ...,  136.7187, -326.5837,\n",
       "            -4.4814],\n",
       "         [ 372.2779, -252.5528,  171.7637,  ...,  132.5087, -312.9012,\n",
       "            -2.6895]]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0d2fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1364\n",
      "Recall: 0.0600\n",
      "F1 Score: 0.0833\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the batches\n",
    "predictions = (torch.tensor(preds) > 0.5).float()\n",
    "actuals = torch.tensor(targets).flatten()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(actuals.cpu().numpy(), predictions.cpu().numpy(), average='binary')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c675d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
       "          [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0]],\n",
       "         device='mps:0'),\n",
       "  tensor([[[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [  0,  27,  34,  ..., 171,  76,  73],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [  0,  72, 101,  ..., 177,  30,  32],\n",
       "           [  0, 101, 101,  ..., 177,  91,  97],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 177,  24, 101],\n",
       "           [  0, 101, 101,  ..., 177,   0,   0],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [  0, 101,   3,  ..., 177,  86,  90],\n",
       "           [  0, 101,   3,  ..., 177,  83,  88],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           [101, 101, 101,  ..., 101, 101, 101],\n",
       "           ...,\n",
       "           [101, 101, 101,  ..., 170,  60,  59],\n",
       "           [  0, 101, 101,  ..., 170,  56,  53],\n",
       "           [101, 101, 101,  ..., 101, 101, 101]],\n",
       "  \n",
       "          [[101, 101, 101,  ..., 181,   0,   0],\n",
       "           [101, 101, 101,  ..., 181,   0,   0],\n",
       "           [101, 101, 101,  ..., 181,   0,   0],\n",
       "           ...,\n",
       "           [  0, 101, 101,  ..., 170,  48,  55],\n",
       "           [  0, 101, 101,  ..., 170,  50,  53],\n",
       "           [101, 101, 101,  ..., 181, 101, 101]]], device='mps:0')],\n",
       " tensor([0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207f1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
