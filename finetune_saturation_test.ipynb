{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9914262-7a3e-4e3a-9e07-043d40efd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data packages\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from model.rnn import GRUDecoder\n",
    "from model.encoders import CustomExcelFormer\n",
    "from data_processing.pipeline import encoding_pipeline, get_generic_name\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from model.utils import get_device\n",
    "from model.dataset import PretrainingDataset\n",
    "from model.dataset import FinetuningDataset\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0d9e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18aee1dd-7884-40e7-be05-db070f1a452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass:\n",
    "    def __init__(self,\n",
    "                 data_path: str = \"data/training_data/PreFer_train_data.csv\",\n",
    "                 targets_path: str = 'data/training_data/PreFer_train_outcome.csv',\n",
    "                 codebook_path: str = 'data/codebooks/PreFer_codebook.csv',\n",
    "                 importance_path: str = 'features_importance_all.csv') -> None:\n",
    "        self.data = pd.read_csv(data_path, low_memory=False)\n",
    "        self.targets = pd.read_csv(targets_path)\n",
    "        self.codebook = pd.read_csv(codebook_path)\n",
    "        self.col_importance = pd.read_csv(importance_path)\n",
    "    def make_sequences(self, n_cols: int, use_codebook: bool = True):\n",
    "        custom_pairs = self.col_importance.feature.map(lambda x: get_generic_name(x)).unique()[:n_cols]\n",
    "        self.sequences = encoding_pipeline(self.data, self.codebook, \n",
    "                                           custom_pairs=custom_pairs, \n",
    "                                           importance=self.col_importance, \n",
    "                                           use_codebook=use_codebook)\n",
    "    def make_pretraining(self):\n",
    "        self.pretrain_dataset = PretrainingDataset(self.sequences)\n",
    "        self.seq_len = self.pretrain_dataset.get_seq_len()\n",
    "        self.vocab_size = self.pretrain_dataset.get_vocab_size()\n",
    "    def make_finetuning(self, batch_size, test_size: float = 0.2, val_size: float = 0.2):\n",
    "        targets = self.targets[self.targets.new_child.notna()]\n",
    "        train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=test_size, random_state=42)\n",
    "        train_person_ids, val_person_ids = train_test_split(train_person_ids, test_size=val_size, random_state=42)\n",
    "        rnn_data = {person_id: (\n",
    "                torch.tensor([year-2007 for year, _ in wave_responses.items()]).to(device),\n",
    "                torch.tensor([ wave_response for _, wave_response in wave_responses.items()]).to(device)\n",
    "                )\n",
    "                for person_id, wave_responses in self.sequences.items()\n",
    "                }\n",
    "\n",
    "        # split data based on the splits made for the target\n",
    "        train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "        val_data = {person_id: rnn_data[person_id] for person_id in val_person_ids}\n",
    "        test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}\n",
    "\n",
    "        self.train_dataset = FinetuningDataset(train_data, targets = targets)\n",
    "        self.val_dataset = FinetuningDataset(val_data, targets = targets)\n",
    "        self.test_dataset = FinetuningDataset(test_data, targets = targets)\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader  = DataLoader(self.test_dataset,  batch_size=batch_size)\n",
    "\n",
    "    def make_finetuning_cv(self, batch_size: int, split_id: int, n_splits: int = 5, test_size: float = 0.2):\n",
    "        \"\"\"\n",
    "        Stupid Imolementation of the K-fold CV\n",
    "\n",
    "        \"\"\"\n",
    "        assert split_id >= 0\n",
    "        assert split_id < n_splits\n",
    "        targets = self.targets[self.targets.new_child.notna()]\n",
    "\n",
    "\n",
    "        train_person_ids, test_person_ids = train_test_split(targets['nomem_encr'], test_size=test_size, random_state=42)\n",
    "        \n",
    "        val_person_ids = [idx for i, idx in enumerate(train_person_ids) if i%n_splits == split_id]\n",
    "        train_person_ids = [idx for i, idx in enumerate(train_person_ids) if i%n_splits != split_id]\n",
    "\n",
    "        rnn_data = {person_id: (\n",
    "                torch.tensor([year-2007 for year, _ in wave_responses.items()]).to(device),\n",
    "                torch.tensor([ wave_response for _, wave_response in wave_responses.items()]).to(device)\n",
    "                )\n",
    "                for person_id, wave_responses in self.sequences.items()\n",
    "                }\n",
    "\n",
    "        # split data based on the splits made for the target\n",
    "        train_data = {person_id: rnn_data[person_id] for person_id in train_person_ids}\n",
    "        val_data = {person_id: rnn_data[person_id] for person_id in val_person_ids}\n",
    "        test_data = {person_id: rnn_data[person_id] for person_id in test_person_ids}\n",
    "\n",
    "        self.train_dataset = FinetuningDataset(train_data, targets = targets)\n",
    "        self.val_dataset = FinetuningDataset(val_data, targets = targets)\n",
    "        self.test_dataset = FinetuningDataset(test_data, targets = targets)\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader  = DataLoader(self.test_dataset,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a65b0",
   "metadata": {},
   "source": [
    "# What is the effect of increasing the number of questions?\n",
    "\n",
    "## Pretraining\n",
    "I pretrain on all the data. Currently, I only use the Attn-based autoencoder as it seems to train the fastest.\n",
    "\n",
    "## Finetuning\n",
    "We perform 5-fold cross validation for the FT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf25b90",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce5674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for the PT\n",
    "#ENCODING_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_SIZE = 64\n",
    "ENCODING_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "NUM_EPOCHS = 10\n",
    "DETECT_ANOMALY = False\n",
    "assert HIDDEN_SIZE % NUM_HEADS == 0, \"Check that the hidden size is divisible\"\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "n_questions = [25, 50, 100, 150, 250, 500, 1000, 5000]#, 1000, 2000, 4000, 8000, 16000, 27000]\n",
    "MODEL_PATH = model_name = f\"saturation_test_ENC_nquestions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f42560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreFerPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size: int, seq_len: int, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = CustomExcelFormer(vocab_size=vocab_size, \n",
    "                            hidden_size=HIDDEN_SIZE, \n",
    "                            out_size=ENCODING_SIZE,\n",
    "                            n_years=14,\n",
    "                            num_heads=NUM_HEADS,\n",
    "                            num_layers=NUM_LAYERS, \n",
    "                            num_classes=2,\n",
    "                            sequence_len=seq_len, \n",
    "                            aium_dropout=0.3,\n",
    "                            diam_dropout=0.2,\n",
    "                            residual_dropout=0.2,\n",
    "                            embedding_dropout=0.3,\n",
    "                            mixup=None,\n",
    "                            beta=0.2)\n",
    "        self.decoder = GRUDecoder(\n",
    "            input_size=ENCODING_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=3,\n",
    "            max_seq_len=14,\n",
    "            dropout=0.3,\n",
    "            bidirectional=True,\n",
    "            with_attention = True\n",
    "        )\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, input_year, input_seq, labels):\n",
    "        bs, ss = labels.size(0), 14\n",
    "        input_year = input_year.reshape(-1).to(device)\n",
    "        input_seq = input_seq.reshape(bs * ss, -1).to(device)\n",
    "\n",
    "        encodings, _ = self.encoder(input_year, input_seq)#, y=labels.unsqueeze(-1).expand(-1, 14).reshape(-1), mixup_encoded=True)\n",
    "        encodings = encodings.view(bs,ss, -1)\n",
    "        mask = ~((input_seq == 101).sum(-1) == self.seq_len).view(bs,ss).detach()\n",
    "\n",
    "        # Forward pass\n",
    "        out = self.decoder(encodings, mask=mask).flatten()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310ee27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/carlomarx/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Epochs 0: 79it [00:12,  6.15it/s, mean loss: 0.824]\n",
      "Epochs 1: 79it [00:11,  6.93it/s, mean loss: 0.690]\n",
      "Epochs 2: 79it [00:11,  7.07it/s, mean loss: 0.519]\n",
      "Epochs 3: 79it [00:11,  7.12it/s, mean loss: 0.448]\n",
      "Epochs 4: 79it [00:11,  7.11it/s, mean loss: 0.406]\n",
      "Epochs 5: 79it [00:11,  7.14it/s, mean loss: 0.370]\n",
      "Epochs 6: 79it [00:11,  6.91it/s, mean loss: 0.323]\n",
      "Epochs 7: 79it [00:11,  6.80it/s, mean loss: 0.311]\n",
      "Epochs 8: 79it [00:11,  6.94it/s, mean loss: 0.307]\n",
      "Epochs 9: 79it [00:11,  6.93it/s, mean loss: 0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6153846153846154], 'mAP': [0.6598409534445158], 'precision': [0.5714285714285714], 'recall': [0.6666666666666666]}\n",
      "-- 25 mAP Score: 0.6598 -- median f1-score: 0.615\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.87it/s, mean loss: 0.790]\n",
      "Epochs 1: 79it [00:11,  6.82it/s, mean loss: 0.715]\n",
      "Epochs 2: 79it [00:11,  6.97it/s, mean loss: 0.578]\n",
      "Epochs 3: 79it [00:11,  7.06it/s, mean loss: 0.494]\n",
      "Epochs 4: 79it [00:11,  6.79it/s, mean loss: 0.417]\n",
      "Epochs 5: 79it [00:11,  6.96it/s, mean loss: 0.379]\n",
      "Epochs 6: 79it [00:11,  6.89it/s, mean loss: 0.323]\n",
      "Epochs 7: 79it [00:11,  6.83it/s, mean loss: 0.292]\n",
      "Epochs 8: 79it [00:11,  7.11it/s, mean loss: 0.321]\n",
      "Epochs 9: 79it [00:11,  7.09it/s, mean loss: 0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6153846153846154, 0.6388888888888888], 'mAP': [0.6598409534445158, 0.7154568925496199], 'precision': [0.5714285714285714, 0.6388888888888888], 'recall': [0.6666666666666666, 0.6388888888888888]}\n",
      "-- 25 mAP Score: 0.6876 -- median f1-score: 0.627\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  7.13it/s, mean loss: 0.889]\n",
      "Epochs 1: 79it [00:11,  7.14it/s, mean loss: 0.789]\n",
      "Epochs 2: 79it [00:11,  7.12it/s, mean loss: 0.787]\n",
      "Epochs 3: 79it [00:11,  7.14it/s, mean loss: 0.583]\n",
      "Epochs 4: 79it [00:11,  7.17it/s, mean loss: 0.476]\n",
      "Epochs 5: 79it [00:11,  7.16it/s, mean loss: 0.398]\n",
      "Epochs 6: 79it [00:11,  7.10it/s, mean loss: 0.382]\n",
      "Epochs 7: 79it [00:11,  7.15it/s, mean loss: 0.319]\n",
      "Epochs 8: 79it [00:11,  7.10it/s, mean loss: 0.297]\n",
      "Epochs 9: 79it [00:11,  7.07it/s, mean loss: 0.305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6153846153846154, 0.6388888888888888, 0.7058823529411765], 'mAP': [0.6598409534445158, 0.7154568925496199, 0.7662289820232286], 'precision': [0.5714285714285714, 0.6388888888888888, 0.6666666666666666], 'recall': [0.6666666666666666, 0.6388888888888888, 0.75]}\n",
      "-- 25 mAP Score: 0.7155 -- median f1-score: 0.639\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  7.15it/s, mean loss: 0.786]\n",
      "Epochs 1: 79it [00:11,  7.08it/s, mean loss: 0.653]\n",
      "Epochs 2: 79it [00:11,  6.76it/s, mean loss: 0.570]\n",
      "Epochs 3: 79it [00:11,  6.69it/s, mean loss: 0.533]\n",
      "Epochs 4: 79it [00:11,  6.75it/s, mean loss: 0.457]\n",
      "Epochs 5: 79it [00:11,  6.82it/s, mean loss: 0.454]\n",
      "Epochs 6: 79it [00:12,  6.46it/s, mean loss: 0.396]\n",
      "Epochs 7: 79it [00:11,  6.92it/s, mean loss: 0.355]\n",
      "Epochs 8: 79it [00:11,  6.93it/s, mean loss: 0.327]\n",
      "Epochs 9: 79it [00:11,  6.95it/s, mean loss: 0.314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6153846153846154, 0.6388888888888888, 0.7058823529411765, 0.8333333333333334], 'mAP': [0.6598409534445158, 0.7154568925496199, 0.7662289820232286, 0.9016191333671753], 'precision': [0.5714285714285714, 0.6388888888888888, 0.6666666666666666, 0.8620689655172413], 'recall': [0.6666666666666666, 0.6388888888888888, 0.75, 0.8064516129032258]}\n",
      "-- 25 mAP Score: 0.7408 -- median f1-score: 0.672\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.93it/s, mean loss: 0.819]\n",
      "Epochs 1: 79it [00:11,  6.82it/s, mean loss: 0.686]\n",
      "Epochs 2: 79it [00:11,  6.60it/s, mean loss: 0.577]\n",
      "Epochs 3: 79it [00:11,  6.85it/s, mean loss: 0.553]\n",
      "Epochs 4: 79it [00:11,  6.66it/s, mean loss: 0.447]\n",
      "Epochs 5: 79it [00:11,  6.70it/s, mean loss: 0.480]\n",
      "Epochs 6: 79it [00:11,  6.97it/s, mean loss: 0.401]\n",
      "Epochs 7: 79it [00:11,  6.80it/s, mean loss: 0.363]\n",
      "Epochs 8: 79it [00:11,  6.94it/s, mean loss: 0.334]\n",
      "Epochs 9: 79it [00:11,  6.93it/s, mean loss: 0.315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6153846153846154, 0.6388888888888888, 0.7058823529411765, 0.8333333333333334, 0.7088607594936709], 'mAP': [0.6598409534445158, 0.7154568925496199, 0.7662289820232286, 0.9016191333671753, 0.7911048036888001], 'precision': [0.5714285714285714, 0.6388888888888888, 0.6666666666666666, 0.8620689655172413, 0.7368421052631579], 'recall': [0.6666666666666666, 0.6388888888888888, 0.75, 0.8064516129032258, 0.6829268292682927]}\n",
      "-- 25 mAP Score: 0.7662 -- median f1-score: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.72it/s, mean loss: 0.857]\n",
      "Epochs 1: 79it [00:11,  6.85it/s, mean loss: 0.686]\n",
      "Epochs 2: 79it [00:11,  6.62it/s, mean loss: 0.537]\n",
      "Epochs 3: 79it [00:11,  6.92it/s, mean loss: 0.451]\n",
      "Epochs 4: 79it [00:11,  6.70it/s, mean loss: 0.385]\n",
      "Epochs 5: 79it [00:11,  6.83it/s, mean loss: 0.340]\n",
      "Epochs 6: 79it [00:11,  7.09it/s, mean loss: 0.313]\n",
      "Epochs 7: 79it [00:11,  7.07it/s, mean loss: 0.275]\n",
      "Epochs 8: 79it [00:11,  7.02it/s, mean loss: 0.236]\n",
      "Epochs 9: 79it [00:11,  6.98it/s, mean loss: 0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6376811594202898], 'mAP': [0.6911932313559199], 'precision': [0.5641025641025641], 'recall': [0.7333333333333333]}\n",
      "-- 50 mAP Score: 0.6912 -- median f1-score: 0.638\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.73it/s, mean loss: 0.861]\n",
      "Epochs 1: 79it [00:11,  6.65it/s, mean loss: 0.755]\n",
      "Epochs 2: 79it [00:12,  6.57it/s, mean loss: 0.609]\n",
      "Epochs 3: 79it [00:12,  6.58it/s, mean loss: 0.547]\n",
      "Epochs 4: 79it [00:12,  6.57it/s, mean loss: 0.461]\n",
      "Epochs 5: 79it [00:12,  6.47it/s, mean loss: 0.450]\n",
      "Epochs 6: 79it [00:12,  6.30it/s, mean loss: 0.387]\n",
      "Epochs 7: 79it [00:12,  6.50it/s, mean loss: 0.342]\n",
      "Epochs 8: 79it [00:11,  6.63it/s, mean loss: 0.347]\n",
      "Epochs 9: 79it [00:11,  6.61it/s, mean loss: 0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6376811594202898, 0.6197183098591549], 'mAP': [0.6911932313559199, 0.7001591121202198], 'precision': [0.5641025641025641, 0.6285714285714286], 'recall': [0.7333333333333333, 0.6111111111111112]}\n",
      "-- 50 mAP Score: 0.6957 -- median f1-score: 0.629\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.60it/s, mean loss: 0.902]\n",
      "Epochs 1: 79it [00:12,  6.58it/s, mean loss: 0.701]\n",
      "Epochs 2: 79it [00:11,  6.60it/s, mean loss: 0.561]\n",
      "Epochs 3: 79it [00:11,  6.65it/s, mean loss: 0.582]\n",
      "Epochs 4: 79it [00:11,  6.68it/s, mean loss: 0.467]\n",
      "Epochs 5: 79it [00:12,  6.42it/s, mean loss: 0.402]\n",
      "Epochs 6: 79it [00:12,  6.52it/s, mean loss: 0.371]\n",
      "Epochs 7: 79it [00:12,  6.58it/s, mean loss: 0.339]\n",
      "Epochs 8: 79it [00:12,  6.50it/s, mean loss: 0.287]\n",
      "Epochs 9: 79it [00:12,  6.50it/s, mean loss: 0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6376811594202898, 0.6197183098591549, 0.72], 'mAP': [0.6911932313559199, 0.7001591121202198, 0.7128425572675756], 'precision': [0.5641025641025641, 0.6285714285714286, 0.6923076923076923], 'recall': [0.7333333333333333, 0.6111111111111112, 0.75]}\n",
      "-- 50 mAP Score: 0.7002 -- median f1-score: 0.638\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.62it/s, mean loss: 0.821]\n",
      "Epochs 1: 79it [00:11,  6.66it/s, mean loss: 0.702]\n",
      "Epochs 2: 79it [00:11,  6.66it/s, mean loss: 0.601]\n",
      "Epochs 3: 79it [00:11,  6.63it/s, mean loss: 0.513]\n",
      "Epochs 4: 79it [00:11,  6.68it/s, mean loss: 0.479]\n",
      "Epochs 5: 79it [00:11,  6.70it/s, mean loss: 0.400]\n",
      "Epochs 6: 79it [00:11,  6.88it/s, mean loss: 0.358]\n",
      "Epochs 7: 79it [00:11,  6.89it/s, mean loss: 0.307]\n",
      "Epochs 8: 79it [00:11,  6.98it/s, mean loss: 0.308]\n",
      "Epochs 9: 79it [00:11,  7.01it/s, mean loss: 0.290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6376811594202898, 0.6197183098591549, 0.72, 0.7936507936507936], 'mAP': [0.6911932313559199, 0.7001591121202198, 0.7128425572675756, 0.8479936867942981], 'precision': [0.5641025641025641, 0.6285714285714286, 0.6923076923076923, 0.78125], 'recall': [0.7333333333333333, 0.6111111111111112, 0.75, 0.8064516129032258]}\n",
      "-- 50 mAP Score: 0.7065 -- median f1-score: 0.679\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:11,  6.90it/s, mean loss: 0.799]\n",
      "Epochs 1: 79it [00:11,  6.70it/s, mean loss: 0.628]\n",
      "Epochs 2: 79it [00:11,  6.74it/s, mean loss: 0.520]\n",
      "Epochs 3: 79it [00:12,  6.50it/s, mean loss: 0.446]\n",
      "Epochs 4: 79it [00:12,  6.41it/s, mean loss: 0.408]\n",
      "Epochs 5: 79it [00:12,  6.39it/s, mean loss: 0.358]\n",
      "Epochs 6: 79it [00:12,  6.29it/s, mean loss: 0.282]\n",
      "Epochs 7: 79it [00:12,  6.29it/s, mean loss: 0.322]\n",
      "Epochs 8: 79it [00:12,  6.30it/s, mean loss: 0.261]\n",
      "Epochs 9: 79it [00:12,  6.34it/s, mean loss: 0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6376811594202898, 0.6197183098591549, 0.72, 0.7936507936507936, 0.7123287671232876], 'mAP': [0.6911932313559199, 0.7001591121202198, 0.7128425572675756, 0.8479936867942981, 0.8472546867941809], 'precision': [0.5641025641025641, 0.6285714285714286, 0.6923076923076923, 0.78125, 0.8125], 'recall': [0.7333333333333333, 0.6111111111111112, 0.75, 0.8064516129032258, 0.6341463414634146]}\n",
      "-- 50 mAP Score: 0.7128 -- median f1-score: 0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:14,  5.41it/s, mean loss: 0.879]\n",
      "Epochs 1: 79it [00:13,  5.70it/s, mean loss: 0.783]\n",
      "Epochs 2: 79it [00:13,  5.68it/s, mean loss: 0.703]\n",
      "Epochs 3: 79it [00:14,  5.61it/s, mean loss: 0.506]\n",
      "Epochs 4: 79it [00:13,  5.68it/s, mean loss: 0.422]\n",
      "Epochs 5: 79it [00:13,  5.69it/s, mean loss: 0.336]\n",
      "Epochs 6: 79it [00:13,  5.72it/s, mean loss: 0.280]\n",
      "Epochs 7: 79it [00:13,  5.69it/s, mean loss: 0.249]\n",
      "Epochs 8: 79it [00:13,  5.65it/s, mean loss: 0.194]\n",
      "Epochs 9: 79it [00:13,  5.68it/s, mean loss: 0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7272727272727273], 'mAP': [0.7766055090030056], 'precision': [0.6666666666666666], 'recall': [0.8]}\n",
      "-- 100 mAP Score: 0.7766 -- median f1-score: 0.727\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:13,  5.81it/s, mean loss: 0.814]\n",
      "Epochs 1: 79it [00:12,  6.31it/s, mean loss: 0.692]\n",
      "Epochs 2: 79it [00:12,  6.43it/s, mean loss: 0.597]\n",
      "Epochs 3: 79it [00:12,  6.51it/s, mean loss: 0.477]\n",
      "Epochs 4: 79it [00:12,  6.47it/s, mean loss: 0.361]\n",
      "Epochs 5: 79it [00:12,  6.54it/s, mean loss: 0.350]\n",
      "Epochs 6: 79it [00:12,  6.38it/s, mean loss: 0.284]\n",
      "Epochs 7: 79it [00:12,  6.47it/s, mean loss: 0.204]\n",
      "Epochs 8: 79it [00:12,  6.39it/s, mean loss: 0.205]\n",
      "Epochs 9: 79it [00:12,  6.37it/s, mean loss: 0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7272727272727273, 0.6268656716417911], 'mAP': [0.7766055090030056, 0.727910500110748], 'precision': [0.6666666666666666, 0.6774193548387096], 'recall': [0.8, 0.5833333333333334]}\n",
      "-- 100 mAP Score: 0.7523 -- median f1-score: 0.677\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:12,  6.48it/s, mean loss: 0.940]\n",
      "Epochs 1: 79it [00:11,  6.59it/s, mean loss: 0.727]\n",
      "Epochs 2: 79it [00:12,  6.41it/s, mean loss: 0.585]\n",
      "Epochs 3: 79it [00:12,  6.53it/s, mean loss: 0.527]\n",
      "Epochs 4: 79it [00:12,  6.54it/s, mean loss: 0.420]\n",
      "Epochs 5: 79it [00:12,  6.47it/s, mean loss: 0.340]\n",
      "Epochs 6: 79it [00:11,  6.65it/s, mean loss: 0.296]\n",
      "Epochs 7: 79it [00:11,  6.62it/s, mean loss: 0.271]\n",
      "Epochs 8: 79it [00:11,  6.61it/s, mean loss: 0.254]\n",
      "Epochs 9: 79it [00:11,  6.59it/s, mean loss: 0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7272727272727273, 0.6268656716417911, 0.7307692307692307], 'mAP': [0.7766055090030056, 0.727910500110748, 0.7619197370423592], 'precision': [0.6666666666666666, 0.6774193548387096, 0.6785714285714286], 'recall': [0.8, 0.5833333333333334, 0.7916666666666666]}\n",
      "-- 100 mAP Score: 0.7619 -- median f1-score: 0.727\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:12,  6.39it/s, mean loss: 0.879]\n",
      "Epochs 1: 79it [00:12,  6.44it/s, mean loss: 0.816]\n",
      "Epochs 2: 79it [00:11,  6.72it/s, mean loss: 0.714]\n",
      "Epochs 3: 79it [00:12,  6.47it/s, mean loss: 0.560]\n",
      "Epochs 4: 79it [00:12,  6.48it/s, mean loss: 0.449]\n",
      "Epochs 5: 79it [00:12,  6.23it/s, mean loss: 0.391]\n",
      "Epochs 6: 79it [00:12,  6.21it/s, mean loss: 0.311]\n",
      "Epochs 7: 79it [00:12,  6.51it/s, mean loss: 0.287]\n",
      "Epochs 8: 79it [00:12,  6.47it/s, mean loss: 0.263]\n",
      "Epochs 9: 79it [00:14,  5.58it/s, mean loss: 0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7272727272727273, 0.6268656716417911, 0.7307692307692307, 0.7741935483870968], 'mAP': [0.7766055090030056, 0.727910500110748, 0.7619197370423592, 0.878670937928726], 'precision': [0.6666666666666666, 0.6774193548387096, 0.6785714285714286, 0.7741935483870968], 'recall': [0.8, 0.5833333333333334, 0.7916666666666666, 0.7741935483870968]}\n",
      "-- 100 mAP Score: 0.7693 -- median f1-score: 0.729\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:14,  5.51it/s, mean loss: 0.864]\n",
      "Epochs 1: 79it [00:14,  5.60it/s, mean loss: 0.726]\n",
      "Epochs 2: 79it [00:14,  5.54it/s, mean loss: 0.581]\n",
      "Epochs 3: 79it [00:14,  5.52it/s, mean loss: 0.533]\n",
      "Epochs 4: 79it [00:14,  5.51it/s, mean loss: 0.457]\n",
      "Epochs 5: 79it [00:14,  5.59it/s, mean loss: 0.387]\n",
      "Epochs 6: 79it [00:14,  5.55it/s, mean loss: 0.328]\n",
      "Epochs 7: 79it [00:14,  5.63it/s, mean loss: 0.282]\n",
      "Epochs 8: 79it [00:14,  5.55it/s, mean loss: 0.221]\n",
      "Epochs 9: 79it [00:14,  5.53it/s, mean loss: 0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7272727272727273, 0.6268656716417911, 0.7307692307692307, 0.7741935483870968, 0.7368421052631579], 'mAP': [0.7766055090030056, 0.727910500110748, 0.7619197370423592, 0.878670937928726, 0.8269561209090185], 'precision': [0.6666666666666666, 0.6774193548387096, 0.6785714285714286, 0.7741935483870968, 0.8], 'recall': [0.8, 0.5833333333333334, 0.7916666666666666, 0.7741935483870968, 0.6829268292682927]}\n",
      "-- 100 mAP Score: 0.7766 -- median f1-score: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:18,  4.21it/s, mean loss: 0.837]\n",
      "Epochs 1: 79it [00:18,  4.30it/s, mean loss: 0.740]\n",
      "Epochs 2: 79it [00:14,  5.60it/s, mean loss: 0.634]\n",
      "Epochs 3: 79it [00:14,  5.48it/s, mean loss: 0.525]\n",
      "Epochs 4: 79it [00:14,  5.54it/s, mean loss: 0.419]\n",
      "Epochs 5: 79it [00:14,  5.61it/s, mean loss: 0.410]\n",
      "Epochs 6: 79it [00:14,  5.57it/s, mean loss: 0.257]\n",
      "Epochs 7: 79it [00:14,  5.51it/s, mean loss: 0.203]\n",
      "Epochs 8: 79it [00:14,  5.57it/s, mean loss: 0.191]\n",
      "Epochs 9: 79it [00:14,  5.61it/s, mean loss: 0.180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.65625], 'mAP': [0.754896276443619], 'precision': [0.6176470588235294], 'recall': [0.7]}\n",
      "-- 150 mAP Score: 0.7549 -- median f1-score: 0.656\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:14,  5.49it/s, mean loss: 0.862]\n",
      "Epochs 1: 79it [00:14,  5.52it/s, mean loss: 0.725]\n",
      "Epochs 2: 79it [00:14,  5.53it/s, mean loss: 0.599]\n",
      "Epochs 3: 79it [00:14,  5.50it/s, mean loss: 0.499]\n",
      "Epochs 4: 79it [00:14,  5.53it/s, mean loss: 0.335]\n",
      "Epochs 5: 79it [00:13,  5.64it/s, mean loss: 0.268]\n",
      "Epochs 6: 79it [00:14,  5.61it/s, mean loss: 0.228]\n",
      "Epochs 7: 79it [00:14,  5.61it/s, mean loss: 0.132]\n",
      "Epochs 8: 79it [00:14,  5.61it/s, mean loss: 0.119]\n",
      "Epochs 9: 79it [00:14,  5.59it/s, mean loss: 0.089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.65625, 0.5970149253731343], 'mAP': [0.754896276443619, 0.6712966503675969], 'precision': [0.6176470588235294, 0.6451612903225806], 'recall': [0.7, 0.5555555555555556]}\n",
      "-- 150 mAP Score: 0.7131 -- median f1-score: 0.627\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:14,  5.51it/s, mean loss: 0.876]\n",
      "Epochs 1: 79it [00:14,  5.55it/s, mean loss: 0.751]\n",
      "Epochs 2: 79it [00:14,  5.58it/s, mean loss: 0.621]\n",
      "Epochs 3: 79it [00:13,  5.67it/s, mean loss: 0.489]\n",
      "Epochs 4: 79it [00:13,  5.67it/s, mean loss: 0.404]\n",
      "Epochs 5: 79it [00:14,  5.57it/s, mean loss: 0.269]\n",
      "Epochs 6: 79it [00:14,  5.61it/s, mean loss: 0.248]\n",
      "Epochs 7: 79it [00:14,  5.52it/s, mean loss: 0.212]\n",
      "Epochs 8: 79it [00:14,  5.54it/s, mean loss: 0.167]\n",
      "Epochs 9: 79it [00:14,  5.54it/s, mean loss: 0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.65625, 0.5970149253731343, 0.6274509803921569], 'mAP': [0.754896276443619, 0.6712966503675969, 0.6550828794512107], 'precision': [0.6176470588235294, 0.6451612903225806, 0.5925925925925926], 'recall': [0.7, 0.5555555555555556, 0.6666666666666666]}\n",
      "-- 150 mAP Score: 0.6713 -- median f1-score: 0.627\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:17,  4.56it/s, mean loss: 0.826]\n",
      "Epochs 1: 79it [00:18,  4.35it/s, mean loss: 0.716]\n",
      "Epochs 2: 79it [00:18,  4.27it/s, mean loss: 0.653]\n",
      "Epochs 3: 79it [00:17,  4.49it/s, mean loss: 0.509]\n",
      "Epochs 4: 79it [00:17,  4.45it/s, mean loss: 0.388]\n",
      "Epochs 5: 79it [00:17,  4.51it/s, mean loss: 0.341]\n",
      "Epochs 6: 79it [00:17,  4.49it/s, mean loss: 0.263]\n",
      "Epochs 7: 79it [00:17,  4.61it/s, mean loss: 0.215]\n",
      "Epochs 8: 79it [00:17,  4.46it/s, mean loss: 0.215]\n",
      "Epochs 9: 79it [00:17,  4.64it/s, mean loss: 0.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.65625, 0.5970149253731343, 0.6274509803921569, 0.7647058823529411], 'mAP': [0.754896276443619, 0.6712966503675969, 0.6550828794512107, 0.8829093115240799], 'precision': [0.6176470588235294, 0.6451612903225806, 0.5925925925925926, 0.7027027027027027], 'recall': [0.7, 0.5555555555555556, 0.6666666666666666, 0.8387096774193549]}\n",
      "-- 150 mAP Score: 0.7131 -- median f1-score: 0.642\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:17,  4.59it/s, mean loss: 0.778]\n",
      "Epochs 1: 79it [00:14,  5.60it/s, mean loss: 0.681]\n",
      "Epochs 2: 79it [00:13,  5.68it/s, mean loss: 0.568]\n",
      "Epochs 3: 79it [00:14,  5.57it/s, mean loss: 0.503]\n",
      "Epochs 4: 79it [00:14,  5.52it/s, mean loss: 0.419]\n",
      "Epochs 5: 79it [00:14,  5.51it/s, mean loss: 0.332]\n",
      "Epochs 6: 79it [00:14,  5.55it/s, mean loss: 0.256]\n",
      "Epochs 7: 79it [00:14,  5.53it/s, mean loss: 0.223]\n",
      "Epochs 8: 79it [00:14,  5.38it/s, mean loss: 0.215]\n",
      "Epochs 9: 79it [00:14,  5.48it/s, mean loss: 0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.65625, 0.5970149253731343, 0.6274509803921569, 0.7647058823529411, 0.6493506493506493], 'mAP': [0.754896276443619, 0.6712966503675969, 0.6550828794512107, 0.8829093115240799, 0.7304182366496149], 'precision': [0.6176470588235294, 0.6451612903225806, 0.5925925925925926, 0.7027027027027027, 0.6944444444444444], 'recall': [0.7, 0.5555555555555556, 0.6666666666666666, 0.8387096774193549, 0.6097560975609756]}\n",
      "-- 150 mAP Score: 0.7304 -- median f1-score: 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:28,  2.73it/s, mean loss: 0.833]\n",
      "Epochs 1: 79it [00:28,  2.75it/s, mean loss: 0.664]\n",
      "Epochs 2: 79it [00:28,  2.76it/s, mean loss: 0.489]\n",
      "Epochs 3: 79it [00:28,  2.77it/s, mean loss: 0.420]\n",
      "Epochs 4: 79it [00:28,  2.73it/s, mean loss: 0.328]\n",
      "Epochs 5: 79it [00:25,  3.13it/s, mean loss: 0.198]\n",
      "Epochs 6: 79it [00:22,  3.58it/s, mean loss: 0.152]\n",
      "Epochs 7: 79it [00:22,  3.59it/s, mean loss: 0.116]\n",
      "Epochs 8: 79it [00:22,  3.47it/s, mean loss: 0.080]\n",
      "Epochs 9: 79it [00:28,  2.76it/s, mean loss: 0.075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6551724137931034], 'mAP': [0.7187616213704126], 'precision': [0.6785714285714286], 'recall': [0.6333333333333333]}\n",
      "-- 250 mAP Score: 0.7188 -- median f1-score: 0.655\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:28,  2.75it/s, mean loss: 0.830]\n",
      "Epochs 1: 79it [00:29,  2.69it/s, mean loss: 0.787]\n",
      "Epochs 2: 79it [00:29,  2.72it/s, mean loss: 0.676]\n",
      "Epochs 3: 79it [00:29,  2.72it/s, mean loss: 0.545]\n",
      "Epochs 4: 79it [00:27,  2.83it/s, mean loss: 0.374]\n",
      "Epochs 5: 79it [00:22,  3.54it/s, mean loss: 0.275]\n",
      "Epochs 6: 79it [00:22,  3.54it/s, mean loss: 0.225]\n",
      "Epochs 7: 79it [00:22,  3.56it/s, mean loss: 0.154]\n",
      "Epochs 8: 79it [00:25,  3.04it/s, mean loss: 0.116]\n",
      "Epochs 9: 79it [00:27,  2.86it/s, mean loss: 0.091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6551724137931034, 0.6363636363636364], 'mAP': [0.7187616213704126, 0.6807470211372789], 'precision': [0.6785714285714286, 0.7], 'recall': [0.6333333333333333, 0.5833333333333334]}\n",
      "-- 250 mAP Score: 0.6998 -- median f1-score: 0.646\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:28,  2.80it/s, mean loss: 0.883]\n",
      "Epochs 1: 79it [00:29,  2.69it/s, mean loss: 0.745]\n",
      "Epochs 2: 79it [00:29,  2.69it/s, mean loss: 0.667]\n",
      "Epochs 3: 79it [00:29,  2.69it/s, mean loss: 0.523]\n",
      "Epochs 4: 79it [00:29,  2.65it/s, mean loss: 0.347]\n",
      "Epochs 5: 79it [00:29,  2.70it/s, mean loss: 0.297]\n",
      "Epochs 6: 79it [00:29,  2.69it/s, mean loss: 0.188]\n",
      "Epochs 7: 79it [00:29,  2.72it/s, mean loss: 0.208]\n",
      "Epochs 8: 79it [00:29,  2.69it/s, mean loss: 0.140]\n",
      "Epochs 9: 79it [00:29,  2.69it/s, mean loss: 0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6551724137931034, 0.6363636363636364, 0.6415094339622641], 'mAP': [0.7187616213704126, 0.6807470211372789, 0.6643326427599043], 'precision': [0.6785714285714286, 0.7, 0.5862068965517241], 'recall': [0.6333333333333333, 0.5833333333333334, 0.7083333333333334]}\n",
      "-- 250 mAP Score: 0.6807 -- median f1-score: 0.642\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:23,  3.35it/s, mean loss: 0.812]\n",
      "Epochs 1: 79it [00:22,  3.57it/s, mean loss: 0.803]\n",
      "Epochs 2: 79it [00:22,  3.54it/s, mean loss: 0.674]\n",
      "Epochs 3: 79it [00:22,  3.57it/s, mean loss: 0.535]\n",
      "Epochs 4: 79it [00:22,  3.55it/s, mean loss: 0.456]\n",
      "Epochs 5: 79it [00:27,  2.90it/s, mean loss: 0.318]\n",
      "Epochs 6: 79it [00:29,  2.69it/s, mean loss: 0.253]\n",
      "Epochs 7: 79it [00:25,  3.15it/s, mean loss: 0.169]\n",
      "Epochs 8: 79it [00:29,  2.71it/s, mean loss: 0.134]\n",
      "Epochs 9: 79it [00:28,  2.73it/s, mean loss: 0.099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6551724137931034, 0.6363636363636364, 0.6415094339622641, 0.7575757575757576], 'mAP': [0.7187616213704126, 0.6807470211372789, 0.6643326427599043, 0.8751764225911535], 'precision': [0.6785714285714286, 0.7, 0.5862068965517241, 0.7142857142857143], 'recall': [0.6333333333333333, 0.5833333333333334, 0.7083333333333334, 0.8064516129032258]}\n",
      "-- 250 mAP Score: 0.6998 -- median f1-score: 0.648\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:28,  2.76it/s, mean loss: 0.837]\n",
      "Epochs 1: 79it [00:23,  3.32it/s, mean loss: 0.721]\n",
      "Epochs 2: 79it [00:29,  2.72it/s, mean loss: 0.609]\n",
      "Epochs 3: 79it [00:28,  2.81it/s, mean loss: 0.516]\n",
      "Epochs 4: 79it [00:26,  2.97it/s, mean loss: 0.410]\n",
      "Epochs 5: 79it [00:28,  2.75it/s, mean loss: 0.335]\n",
      "Epochs 6: 79it [00:29,  2.71it/s, mean loss: 0.260]\n",
      "Epochs 7: 79it [00:28,  2.75it/s, mean loss: 0.231]\n",
      "Epochs 8: 79it [00:28,  2.74it/s, mean loss: 0.184]\n",
      "Epochs 9: 79it [00:28,  2.74it/s, mean loss: 0.164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.6551724137931034, 0.6363636363636364, 0.6415094339622641, 0.7575757575757576, 0.6388888888888888], 'mAP': [0.7187616213704126, 0.6807470211372789, 0.6643326427599043, 0.8751764225911535, 0.7462221303701444], 'precision': [0.6785714285714286, 0.7, 0.5862068965517241, 0.7142857142857143, 0.7419354838709677], 'recall': [0.6333333333333333, 0.5833333333333334, 0.7083333333333334, 0.8064516129032258, 0.5609756097560976]}\n",
      "-- 250 mAP Score: 0.7188 -- median f1-score: 0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/Documents/GitHub/fertility-prediction-challenge/data_processing/pipeline.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  codebook[\"pairs\"] = codebook['var_name'].apply(get_generic_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [01:17,  1.02it/s, mean loss: 0.815]\n",
      "Epochs 1: 79it [00:59,  1.33it/s, mean loss: 0.736]\n",
      "Epochs 2: 79it [01:10,  1.11it/s, mean loss: 0.657]\n",
      "Epochs 3: 79it [01:01,  1.29it/s, mean loss: 0.501]\n",
      "Epochs 4: 79it [01:13,  1.07it/s, mean loss: 0.307]\n",
      "Epochs 5: 79it [01:21,  1.04s/it, mean loss: 0.202]\n",
      "Epochs 6: 79it [01:17,  1.02it/s, mean loss: 0.136]\n",
      "Epochs 7: 79it [01:22,  1.05s/it, mean loss: 0.083]\n",
      "Epochs 8: 79it [01:32,  1.17s/it, mean loss: 0.056]\n",
      "Epochs 9: 79it [01:15,  1.05it/s, mean loss: 0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.7096774193548387], 'mAP': [0.7709002526845291], 'precision': [0.6875], 'recall': [0.7333333333333333]}\n",
      "-- 500 mAP Score: 0.7709 -- median f1-score: 0.710\n",
      "Embedding Layer with the Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 0: 79it [00:58,  1.35it/s, mean loss: 0.837]\n",
      "Epochs 1: 79it [00:59,  1.34it/s, mean loss: 0.687]\n",
      "Epochs 2: 79it [01:13,  1.07it/s, mean loss: 0.593]\n",
      "Epochs 3: 79it [01:31,  1.16s/it, mean loss: 0.418]\n",
      "Epochs 4: 79it [01:29,  1.14s/it, mean loss: 0.308]\n",
      "Epochs 5: 79it [01:24,  1.07s/it, mean loss: 0.191]\n",
      "Epochs 6: 15it [00:12,  1.32it/s, mean loss: 0.140]"
     ]
    }
   ],
   "source": [
    "all_train_loss = []   # for plotting\n",
    "n_cols_list = []\n",
    "metric_per_run = {}\n",
    "data = DataClass()\n",
    "for n_quest in n_questions:\n",
    "    model_name = MODEL_PATH + '-' + str(n_quest)\n",
    "    data.make_sequences(n_cols=n_quest)\n",
    "    data.make_pretraining()\n",
    "    metric_per_run[n_quest] = {\n",
    "        \"f1\": list(),\n",
    "        \"mAP\": list(),\n",
    "        \"precision\": list(),\n",
    "        \"recall\":list()\n",
    "    }\n",
    "    \n",
    "    NUM_FOLDS = 5\n",
    "    for fold_id in range(NUM_FOLDS):\n",
    "\n",
    "        data.make_finetuning_cv(batch_size=BATCH_SIZE, split_id=fold_id, n_splits=NUM_FOLDS )\n",
    "\n",
    "\n",
    "        SEQ_LEN = data.seq_len\n",
    "        VOCAB_SIZE = data.vocab_size\n",
    "    \n",
    "        model = PreFerPredictor(vocab_size=VOCAB_SIZE, seq_len=SEQ_LEN).to(device)\n",
    "\n",
    "        # Define loss function and optimizer for RNN\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1/0.5]).to(device))\n",
    "        optimizer = torch.optim.RAdam(model.parameters(), lr=LEARNING_RATE,\n",
    "                                     weight_decay=1e-2, decoupled_weight_decay=True)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = NUM_EPOCHS,\n",
    "                                                        eta_min = 1e-5, last_epoch = -1)\n",
    "\n",
    "    \n",
    "        loss_per_epoch = []\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # print(epoch)\n",
    "            loss_per_step = []\n",
    "            loop_object  = tqdm(enumerate(data.train_dataloader), desc=f\"Epochs {epoch}\")\n",
    "            for i, batch in loop_object:        \n",
    "                optimizer.zero_grad() \n",
    "                inputs, labels = batch\n",
    "                labels = labels.to(torch.float).to(device)\n",
    "                input_year, input_seq = inputs\n",
    "                ### Model\n",
    "                output = model(input_year=input_year, input_seq=input_seq, labels=labels)\n",
    "                probs = F.sigmoid(output).flatten()\n",
    "                ### Loss\n",
    "                loss = loss_fn(output, labels)  \n",
    "                loss_per_step.append(loss.detach().cpu().numpy())\n",
    "                loop_object.set_postfix_str(\"mean loss: %.3f\"%np.mean(loss_per_step[-100:]))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # On epoch end\n",
    "            scheduler.step()\n",
    "            loss_per_epoch.append(np.mean(loss_per_step))\n",
    "        #### Validation\n",
    "        val_loss = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        model.eval()\n",
    "        for batch in data.val_dataloader:\n",
    "            inputs, labels = batch\n",
    "            labels = labels.to(torch.float).to(device)\n",
    "            input_year, input_seq = inputs\n",
    "            output = model(input_year=input_year, input_seq=input_seq, labels=labels)\n",
    "            probs = F.sigmoid(output).flatten()\n",
    "            loss = loss_fn(output, labels)  \n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "            preds.extend(probs.detach().cpu().numpy().tolist())\n",
    "            targets.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "        # Concatenate all the batches\n",
    "        yhat = torch.tensor(preds).flatten().detach().cpu().numpy()\n",
    "        ytrue = torch.tensor(targets).flatten().cpu().numpy()\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(ytrue, yhat > 0.5, average='binary')\n",
    "        map_roc = average_precision_score(ytrue, yhat)\n",
    "        metric_per_run[n_quest][\"f1\"].append(f1)\n",
    "        metric_per_run[n_quest][\"precision\"].append(precision)\n",
    "        metric_per_run[n_quest][\"recall\"].append(recall)\n",
    "        metric_per_run[n_quest][\"mAP\"].append(map_roc)\n",
    "        print(metric_per_run[n_quest])\n",
    "        _f1 = np.median(metric_per_run[n_quest][\"f1\"])\n",
    "        _map_roc = np.median(metric_per_run[n_quest][\"mAP\"])\n",
    "        print(f\"-- {n_quest} mAP Score: {_map_roc:.4f} -- median f1-score: {_f1:.3f}\")\n",
    "\n",
    "        with open(\"metric_%s.pkl\" %n_quest, \"wb\") as f:\n",
    "            pickle.dump(metric_per_run, f)\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb37c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PreFer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
